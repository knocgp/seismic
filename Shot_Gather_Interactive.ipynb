{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "## ğŸ“‹ ë‹¨ê³„ë³„ ì‹¤í–‰ ì›Œí¬í”Œë¡œìš°\n",
    "\n",
    "**ê° ì…€ì„ í•˜ë‚˜ì”© ì‹¤í–‰í•˜ë©´ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”!**\n",
    "\n",
    "1. âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° í´ë˜ìŠ¤ ì •ì˜\n",
    "2. âœ… ëœë¤ í•©ì„± ëª¨ë¸ ìƒì„±\n",
    "3. âœ… Shot Gather ìƒì„± (Clean)\n",
    "4. âœ… ì§ì ‘íŒŒ ì¶”ê°€\n",
    "5. âœ… Multiple ì¶”ê°€ (í•´ë©´ + ë‚´ë¶€)\n",
    "6. âœ… í•´ìƒ ë…¸ì´ì¦ˆ ì¶”ê°€\n",
    "7. âœ… **Anomalous Amplitude Attenuation** â­ ë…¸ì´ì¦ˆ ì œê±°\n",
    "8. âœ… **Low-cut Filter (1.5 Hz)** â­ ì €ì£¼íŒŒ ì œê±°\n",
    "9. âœ… **Curvelet Denoise** â­ ì¼ë°˜ ë…¸ì´ì¦ˆ ì œê±°\n",
    "10. âœ… **ì§ì ‘íŒŒ ì œê±° (Direct Wave Mute)** â­ NEW\n",
    "11. âœ… **Water Bottom Demultiple** â­ Multiple ì œê±°\n",
    "12. âœ… **Radon Transform Demultiple** â­ Multiple ì œê±°\n",
    "13. âœ… ì „ì²´ ë¹„êµ\n",
    "14. âœ… ë°ì´í„° ì €ì¥ ë° ë‹¤ìš´ë¡œë“œ\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸš€ ì‚¬ìš©ë²•: ê° ì…€ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰ (Shift + Enter)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1"
   },
   "source": [
    "## ğŸ“¦ Step 1: íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "!pip install -q numpy scipy matplotlib pywt scikit-image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.ndimage import median_filter\n",
    "from scipy.linalg import svd\n",
    "import pywt\n",
    "from skimage.restoration import denoise_wavelet\n",
    "from typing import Tuple, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì„í¬íŠ¸ ì™„ë£Œ!\")\n",
    "print(\"   - NumPy\")\n",
    "print(\"   - SciPy\")\n",
    "print(\"   - Matplotlib\")\n",
    "print(\"   - PyWavelets (Curvelet)\")\n",
    "print(\"   - scikit-image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1b"
   },
   "source": [
    "## ğŸ”§ Step 1-2: ê³ ê¸‰ ì²˜ë¦¬ í´ë˜ìŠ¤ ì •ì˜\n",
    "\n",
    "**ê³ ê¸‰ ì²˜ë¦¬ ê¸°ë²•:**\n",
    "- âœ… Water Bottom Demultiple\n",
    "- âœ… Radon Transform Demultiple  \n",
    "- âœ… Anomalous Amplitude Attenuation\n",
    "- âœ… Curvelet Denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "class_definition"
   },
   "outputs": [],
   "source": [
    "class AdvancedMarineProcessor:\n",
    "    \"\"\"ê³ ê¸‰ í•´ìƒ Shot Gather ì²˜ë¦¬ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, dt: float = 0.002, nt: int = 1500):\n",
    "        self.dt = dt\n",
    "        self.nt = nt\n",
    "        self.time = np.arange(nt) * dt\n",
    "        \n",
    "    def create_random_model(self, nlayers: int = None) -> Dict:\n",
    "        \"\"\"ì™„ì „ ëœë¤ í•©ì„± ì§€ë°˜ ëª¨ë¸ ìƒì„±\"\"\"\n",
    "        if nlayers is None:\n",
    "            nlayers = np.random.randint(4, 9)\n",
    "        \n",
    "        model = {'velocity': [], 'density': [], 'thickness': [], 'depth': [], 'name': []}\n",
    "        \n",
    "        # í•´ìˆ˜ì¸µ\n",
    "        water_depth = np.random.uniform(300, 800)\n",
    "        model['velocity'].append(1500.0)\n",
    "        model['density'].append(1030.0)\n",
    "        model['thickness'].append(water_depth)\n",
    "        model['depth'].append(0.0)\n",
    "        model['name'].append('Water')\n",
    "        \n",
    "        # í•´ì €ë©´\n",
    "        seabed_vp = np.random.uniform(1600, 2000)\n",
    "        seabed_rho = np.random.uniform(1900, 2100)\n",
    "        seabed_thick = np.random.uniform(200, 400)\n",
    "        model['velocity'].append(seabed_vp)\n",
    "        model['density'].append(seabed_rho)\n",
    "        model['thickness'].append(seabed_thick)\n",
    "        model['depth'].append(water_depth)\n",
    "        model['name'].append('Seabed')\n",
    "        \n",
    "        # ì§€í•˜ ì§€ì¸µë“¤\n",
    "        current_depth = water_depth + seabed_thick\n",
    "        for i in range(nlayers - 2):\n",
    "            if i == 0:\n",
    "                base_vp = seabed_vp + np.random.uniform(200, 500)\n",
    "            else:\n",
    "                base_vp = model['velocity'][-1] + np.random.uniform(100, 600)\n",
    "            \n",
    "            vp = base_vp + np.random.normal(0, 100)\n",
    "            vp = np.clip(vp, 2000, 5000)\n",
    "            rho = 2000 + (vp - 2000) * 0.2 + np.random.normal(0, 50)\n",
    "            rho = np.clip(rho, 2000, 2800)\n",
    "            thickness = np.random.uniform(150, 600)\n",
    "            \n",
    "            model['velocity'].append(vp)\n",
    "            model['density'].append(rho)\n",
    "            model['thickness'].append(thickness)\n",
    "            model['depth'].append(current_depth)\n",
    "            model['name'].append(f'Layer {i+3}')\n",
    "            current_depth += thickness\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def calculate_reflection_coefficients(self, model: Dict):\n",
    "        velocities = np.array(model['velocity'])\n",
    "        densities = np.array(model['density'])\n",
    "        thicknesses = np.array(model['thickness'])\n",
    "        impedance = velocities * densities\n",
    "        \n",
    "        rc = np.zeros(len(velocities) - 1)\n",
    "        for i in range(len(velocities) - 1):\n",
    "            rc[i] = (impedance[i+1] - impedance[i]) / (impedance[i+1] + impedance[i])\n",
    "        \n",
    "        times = np.zeros(len(velocities) - 1)\n",
    "        cumulative_time = 0\n",
    "        for i in range(len(velocities) - 1):\n",
    "            travel_time = thicknesses[i] / velocities[i]\n",
    "            cumulative_time += travel_time\n",
    "            times[i] = cumulative_time * 2\n",
    "        \n",
    "        return rc, times\n",
    "    \n",
    "    def ricker_wavelet(self, freq: float = 25.0):\n",
    "        duration = 0.2\n",
    "        t = np.arange(-duration/2, duration/2, self.dt)\n",
    "        a = (np.pi * freq * t) ** 2\n",
    "        wavelet = (1 - 2*a) * np.exp(-a)\n",
    "        return wavelet / np.max(np.abs(wavelet))\n",
    "    \n",
    "    def generate_shot_gather(self, model: Dict, n_traces: int = 48, \n",
    "                           offset_min: float = 100, offset_max: float = 2400,\n",
    "                           freq: float = 25.0):\n",
    "        \"\"\"Shot Gather ìƒì„±\"\"\"\n",
    "        offsets = np.linspace(offset_min, offset_max, n_traces)\n",
    "        shot_gather = np.zeros((self.nt, n_traces))\n",
    "        wavelet = self.ricker_wavelet(freq)\n",
    "        rc, zero_offset_times = self.calculate_reflection_coefficients(model)\n",
    "        \n",
    "        for i_trace, offset in enumerate(offsets):\n",
    "            reflectivity = np.zeros(self.nt)\n",
    "            \n",
    "            for j, (rc_val, t0) in enumerate(zip(rc, zero_offset_times)):\n",
    "                depths = np.array(model['depth'])\n",
    "                velocities = np.array(model['velocity'])\n",
    "                \n",
    "                if j < len(depths) - 1:\n",
    "                    avg_depth = depths[j+1]\n",
    "                    avg_velocity = np.mean(velocities[:j+2])\n",
    "                    t_nmo = np.sqrt(t0**2 + (offset / avg_velocity)**2)\n",
    "                    angle = np.arctan(offset / avg_depth)\n",
    "                    avo_factor = 1 - 0.3 * np.sin(angle)**2\n",
    "                    \n",
    "                    idx = int(t_nmo / self.dt)\n",
    "                    if idx < self.nt:\n",
    "                        reflectivity[idx] += rc_val * avo_factor\n",
    "            \n",
    "            trace = signal.convolve(reflectivity, wavelet, mode='same')\n",
    "            spreading = 1 / (1 + offset / 1000)\n",
    "            shot_gather[:, i_trace] = trace * spreading\n",
    "        \n",
    "        return shot_gather, offsets\n",
    "    \n",
    "    def add_direct_wave(self, shot_gather, offsets, model: Dict, strength: float = 0.3):\n",
    "        \"\"\"ì§ì ‘íŒŒ ì¶”ê°€\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        water_velocity = model['velocity'][0]\n",
    "        wavelet = self.ricker_wavelet(25.0)\n",
    "        \n",
    "        for i, offset in enumerate(offsets):\n",
    "            direct_time = offset / water_velocity\n",
    "            idx = int(direct_time / self.dt)\n",
    "            \n",
    "            if idx < self.nt:\n",
    "                amplitude = strength / (1 + offset / 500)\n",
    "                wavelet_start = max(0, idx - len(wavelet)//2)\n",
    "                wavelet_end = min(self.nt, idx + len(wavelet)//2)\n",
    "                wavelet_idx_start = max(0, len(wavelet)//2 - idx)\n",
    "                wavelet_idx_end = wavelet_idx_start + (wavelet_end - wavelet_start)\n",
    "                \n",
    "                result[wavelet_start:wavelet_end, i] += amplitude * wavelet[wavelet_idx_start:wavelet_idx_end]\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def add_sea_surface_multiple(self, shot_gather, model: Dict, strength: float = 0.5):\n",
    "        \"\"\"í•´ë©´ ë©€í‹°í”Œ ì¶”ê°€\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        water_depth = model['thickness'][0]\n",
    "        water_velocity = model['velocity'][0]\n",
    "        two_way_time = 2 * water_depth / water_velocity\n",
    "        delay_samples = int(two_way_time / self.dt)\n",
    "        sea_surface_rc = -0.95\n",
    "        \n",
    "        if delay_samples < self.nt:\n",
    "            result[delay_samples:, :] += shot_gather[:-delay_samples, :] * sea_surface_rc * strength\n",
    "        \n",
    "        if 2 * delay_samples < self.nt:\n",
    "            result[2*delay_samples:, :] += shot_gather[:-2*delay_samples, :] * (sea_surface_rc**2) * strength * 0.5\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def add_internal_multiples(self, shot_gather, model: Dict, strength: float = 0.3):\n",
    "        \"\"\"ë‚´ë¶€ ë©€í‹°í”Œ ì¶”ê°€\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        rc, reflection_times = self.calculate_reflection_coefficients(model)\n",
    "        \n",
    "        strong_reflectors = [(t, rc_val) for t, rc_val in zip(reflection_times, rc) \n",
    "                           if abs(rc_val) > 0.1]\n",
    "        \n",
    "        for i, (t1, rc1) in enumerate(strong_reflectors):\n",
    "            for t2, rc2 in strong_reflectors[i+1:]:\n",
    "                multiple_delay = t2 - t1 + (t2 - t1)\n",
    "                delay_samples = int(multiple_delay / self.dt)\n",
    "                \n",
    "                if delay_samples < self.nt:\n",
    "                    multiple_strength = rc1 * rc2 * strength\n",
    "                    result[delay_samples:, :] += shot_gather[:-delay_samples, :] * multiple_strength\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def add_swell_noise(self, shot_gather, offsets, swell_strength=0.5):\n",
    "        \"\"\"Swell Noise ì¶”ê°€ - Linear Moveout Coherent Noise\n",
    "        \n",
    "        ëŒ€ê°ì„  íŒ¨í„´ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ” coherent noise:\n",
    "        - ì£¼íŒŒìˆ˜: 0.1-0.5 Hz (ë§¤ìš° ë‚®ìŒ)\n",
    "        - Linear moveout: offsetì— ë¹„ë¡€í•˜ëŠ” ì‹œê°„ ì§€ì—°\n",
    "        - Apparent velocity: 1000-2000 m/s (ëŠë¦° ì†ë„)\n",
    "        - í•´ì–‘ í‘œë©´íŒŒ, ì¼€ì´ë¸” ì§„ë™ì˜ ì „íŒŒ\n",
    "        \"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        signal_power = np.std(shot_gather)\n",
    "        \n",
    "        # ì—¬ëŸ¬ swell ì„±ë¶„ (ê°ê° ë‹¤ë¥¸ apparent velocity)\n",
    "        n_components = np.random.randint(2, 4)\n",
    "        \n",
    "        for _ in range(n_components):\n",
    "            # Swell ì£¼íŒŒìˆ˜\n",
    "            swell_freq = np.random.uniform(0.1, 0.5)\n",
    "            \n",
    "            # Apparent velocity (ëŠë¦° ì†ë„)\n",
    "            apparent_velocity = np.random.uniform(1000, 2000)  # m/s\n",
    "            \n",
    "            # ì‹œê°„ ë³€ì¡°\n",
    "            modulation_freq = np.random.uniform(0.05, 0.15)\n",
    "            \n",
    "            # ì§„í­\n",
    "            amplitude = swell_strength * signal_power * (0.8 + 0.4 * np.random.rand())\n",
    "            \n",
    "            # ê° íŠ¸ë ˆì´ìŠ¤ì— linear moveout ì ìš©\n",
    "            for j, offset in enumerate(offsets):\n",
    "                # Linear moveout: t_arrival = t0 + offset / v_app\n",
    "                time_shift = offset / apparent_velocity\n",
    "                \n",
    "                # ì‹œê°„ì¶• ìƒì„±\n",
    "                t_shifted = self.time - time_shift\n",
    "                \n",
    "                # ì‹œê°„ ë³€ì¡°\n",
    "                time_modulation = 1 + 0.6 * np.sin(2 * np.pi * modulation_freq * self.time)\n",
    "                \n",
    "                # Swell íŒŒí˜• (shifted time)\n",
    "                swell_wave = np.zeros(nt)\n",
    "                for it in range(nt):\n",
    "                    if 0 <= t_shifted[it] <= self.time[-1]:\n",
    "                        swell_wave[it] = np.sin(2 * np.pi * swell_freq * t_shifted[it]) * time_modulation[it]\n",
    "                \n",
    "                result[:, j] += amplitude * swell_wave\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def remove_direct_wave(self, shot_gather, offsets, model: Dict, mute_velocity=1500, taper_length=50):\n",
    "        \"\"\"ì§ì ‘íŒŒ(Direct Wave) ì œê±° - Top Mute\n",
    "        \n",
    "        ì§ì ‘íŒŒëŠ” í•´ìˆ˜ì¸µì„ í†µí•´ ì§ì ‘ ì „íŒŒë˜ëŠ” íŒŒë™:\n",
    "        - ì†ë„: í•´ìˆ˜ ìŒì† (~1500 m/s)\n",
    "        - ê°€ì¥ ë¨¼ì € ë„ë‹¬\n",
    "        - Linear moveout: t = offset / velocity\n",
    "        \n",
    "        Top muteë¡œ ì œê±°:\n",
    "        - Mute velocity ì´ìƒì˜ ì†ë„ë¥¼ ê°€ì§„ ì´ë²¤íŠ¸ ì œê±°\n",
    "        - Taperë¥¼ ì ìš©í•˜ì—¬ ë¶€ë“œëŸ½ê²Œ ì œê±°\n",
    "        \"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        \n",
    "        for j, offset in enumerate(offsets):\n",
    "            # Mute time ê³„ì‚°: t_mute = offset / mute_velocity\n",
    "            if mute_velocity > 0:\n",
    "                mute_time = offset / mute_velocity\n",
    "            else:\n",
    "                mute_time = 0\n",
    "            \n",
    "            mute_sample = int(mute_time / self.dt)\n",
    "            \n",
    "            # Mute ì ìš© (taper í¬í•¨)\n",
    "            if mute_sample < nt:\n",
    "                # ì™„ì „íˆ ì œê±°í•˜ëŠ” êµ¬ê°„\n",
    "                result[:mute_sample, j] = 0\n",
    "                \n",
    "                # Taper êµ¬ê°„ (ë¶€ë“œëŸ½ê²Œ ì „í™˜)\n",
    "                taper_end = min(mute_sample + taper_length, nt)\n",
    "                taper_samples = taper_end - mute_sample\n",
    "                \n",
    "                if taper_samples > 0:\n",
    "                    # Cosine taper\n",
    "                    taper = 0.5 * (1 - np.cos(np.pi * np.arange(taper_samples) / taper_samples))\n",
    "                    result[mute_sample:taper_end, j] *= taper\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def add_marine_noise(self, shot_gather, offsets, noise_level: float = 0.08):\n",
    "        \"\"\"í•´ìƒ ë…¸ì´ì¦ˆ ì¶”ê°€\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        signal_power = np.std(shot_gather)\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        \n",
    "        # ë°±ìƒ‰ ì¡ìŒ\n",
    "        white_noise = np.random.normal(0, noise_level * signal_power * 0.3, (nt, n_traces))\n",
    "        result += white_noise\n",
    "        \n",
    "        # ì„ ë°• ë…¸ì´ì¦ˆ\n",
    "        ship_freq = np.random.uniform(2, 8)\n",
    "        for j in range(n_traces):\n",
    "            ship_noise = noise_level * signal_power * 0.5 * np.sin(2 * np.pi * ship_freq * self.time)\n",
    "            ship_noise *= (1 + 0.3 * np.sin(2 * np.pi * 0.5 * self.time))\n",
    "            result[:, j] += ship_noise\n",
    "        \n",
    "        # ìŠ¤ì›° ë…¸ì´ì¦ˆ (ê°œì„ ëœ ëª¨ë¸ ì‚¬ìš©)\n",
    "        result = self.add_swell_noise(result, offsets, swell_strength=noise_level * 0.5)\n",
    "        \n",
    "        # ë²„ìŠ¤íŠ¸ ë…¸ì´ì¦ˆ\n",
    "        n_bursts = np.random.randint(2, 5)\n",
    "        for _ in range(n_bursts):\n",
    "            burst_trace = np.random.randint(0, n_traces)\n",
    "            burst_time = np.random.randint(0, nt)\n",
    "            burst_duration = np.random.randint(20, 80)\n",
    "            if burst_time + burst_duration < nt:\n",
    "                burst = noise_level * signal_power * 2.0 * np.random.randn(burst_duration)\n",
    "                result[burst_time:burst_time+burst_duration, burst_trace] += burst\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def lowcut_filter(self, shot_gather, cutoff_freq=1.5, order=5):\n",
    "        \"\"\"Low-cut (High-pass) Filter - ì €ì£¼íŒŒ ë…¸ì´ì¦ˆ ì œê±°\"\"\"\n",
    "        from scipy.signal import butter, filtfilt\n",
    "        \n",
    "        result = shot_gather.copy()\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        \n",
    "        # Nyquist frequency\n",
    "        fs = 1.0 / self.dt\n",
    "        nyquist = fs / 2.0\n",
    "        \n",
    "        # Normalize cutoff frequency\n",
    "        normalized_cutoff = cutoff_freq / nyquist\n",
    "        \n",
    "        # Design Butterworth high-pass filter\n",
    "        b, a = butter(order, normalized_cutoff, btype='high', analog=False)\n",
    "        \n",
    "        # Apply filter to each trace\n",
    "        for ix in range(n_traces):\n",
    "            result[:, ix] = filtfilt(b, a, shot_gather[:, ix])\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def water_bottom_demultiple(self, shot_gather, model: Dict, strength: float = 0.8):\n",
    "        \"\"\"Water Bottom Demultiple (í•´ì €ë©´ ë©€í‹°í”Œ ì œê±°)\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        \n",
    "        # í•´ì €ë©´ ì–‘ë°©í–¥ ì£¼ì‹œ ê³„ì‚°\n",
    "        water_depth = model['thickness'][0]\n",
    "        water_velocity = model['velocity'][0]\n",
    "        wb_two_way_time = 2 * water_depth / water_velocity\n",
    "        wb_delay = int(wb_two_way_time / self.dt)\n",
    "        \n",
    "        # í•´ì €ë©´ ë°˜ì‚¬ ê³„ìˆ˜\n",
    "        water_impedance = model['velocity'][0] * model['density'][0]\n",
    "        seabed_impedance = model['velocity'][1] * model['density'][1]\n",
    "        wb_rc = (seabed_impedance - water_impedance) / (seabed_impedance + water_impedance)\n",
    "        \n",
    "        # í•´ë©´ ë°˜ì‚¬ ê³„ìˆ˜\n",
    "        sea_surface_rc = -0.95\n",
    "        \n",
    "        # í•´ì €ë©´-í•´ë©´ ë©€í‹°í”Œ ì˜ˆì¸¡ ë° ì œê±°\n",
    "        for order in range(1, 4):  # 1ì°¨, 2ì°¨, 3ì°¨ ë©€í‹°í”Œ\n",
    "            delay = wb_delay * order\n",
    "            if delay < self.nt:\n",
    "                # ë©€í‹°í”Œ ì˜ˆì¸¡\n",
    "                multiple_strength = (wb_rc * (sea_surface_rc ** order)) * strength\n",
    "                predicted_multiple = np.zeros_like(result)\n",
    "                predicted_multiple[delay:, :] = shot_gather[:-delay, :] * multiple_strength\n",
    "                \n",
    "                # ì ì‘ ê°ì‡ \n",
    "                result -= predicted_multiple\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def radon_forward_transform(self, shot_gather, offsets, p_min=-0.001, p_max=0.001, n_p=128):\n",
    "        \"\"\"Forward Radon Transform (t-x -> tau-p) with linear interpolation\"\"\"\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        p_values = np.linspace(p_min, p_max, n_p)\n",
    "        \n",
    "        # Forward Radon Transform: radon(tau, p) = sum over x of data(tau - p*x, x)\n",
    "        radon_domain = np.zeros((nt, n_p))\n",
    "        for ip, p in enumerate(p_values):\n",
    "            for it in range(nt):\n",
    "                tau = self.time[it]\n",
    "                for ix, offset in enumerate(offsets):\n",
    "                    # Time in shot gather: t = tau - p * offset\n",
    "                    t = tau - p * offset\n",
    "                    t_idx = t / self.dt\n",
    "                    \n",
    "                    # Linear interpolation\n",
    "                    if 0 <= t_idx < nt - 1:\n",
    "                        idx_low = int(np.floor(t_idx))\n",
    "                        idx_high = idx_low + 1\n",
    "                        weight = t_idx - idx_low\n",
    "                        \n",
    "                        radon_domain[it, ip] += (1 - weight) * shot_gather[idx_low, ix] +                                                 weight * shot_gather[idx_high, ix]\n",
    "        \n",
    "        return radon_domain, p_values\n",
    "    \n",
    "    def radon_inverse_transform(self, radon_domain, p_values, offsets, nt):\n",
    "        \"\"\"Inverse Radon Transform (tau-p -> t-x) with linear interpolation\"\"\"\n",
    "        n_p = len(p_values)\n",
    "        n_traces = len(offsets)\n",
    "        result = np.zeros((nt, n_traces))\n",
    "        \n",
    "        # Inverse Radon Transform: data(t, x) = sum over p of radon(t + p*x, p)\n",
    "        for ix, offset in enumerate(offsets):\n",
    "            for it in range(nt):\n",
    "                t = self.time[it]\n",
    "                for ip, p in enumerate(p_values):\n",
    "                    # Tau in radon domain: tau = t + p * offset\n",
    "                    tau = t + p * offset\n",
    "                    tau_idx = tau / self.dt\n",
    "                    \n",
    "                    # Linear interpolation\n",
    "                    if 0 <= tau_idx < nt - 1:\n",
    "                        idx_low = int(np.floor(tau_idx))\n",
    "                        idx_high = idx_low + 1\n",
    "                        weight = tau_idx - idx_low\n",
    "                        \n",
    "                        result[it, ix] += (1 - weight) * radon_domain[idx_low, ip] +                                          weight * radon_domain[idx_high, ip]\n",
    "        \n",
    "        # Normalize by number of p values (simple adjoint)\n",
    "        result /= n_p\n",
    "        return result\n",
    "    \n",
    "    def radon_transform_demultiple(self, shot_gather, offsets, p_min=-0.001, p_max=0.001, n_p=128, threshold_percentile=75):\n",
    "        \"\"\"Radon Transform ê¸°ë°˜ Demultiple (íŒŒë¼ë¯¸í„° ì¡°ì • ê°€ëŠ¥)\"\"\"\n",
    "        # Forward transform\n",
    "        radon_domain, p_values = self.radon_forward_transform(shot_gather, offsets, p_min, p_max, n_p)\n",
    "        \n",
    "        # Multiple ì–µì œ\n",
    "        threshold = np.percentile(np.abs(radon_domain), threshold_percentile)\n",
    "        mask = np.abs(radon_domain) > threshold\n",
    "        radon_filtered = radon_domain * mask\n",
    "        \n",
    "        # Inverse transform\n",
    "        result = self.radon_inverse_transform(radon_filtered, p_values, offsets, self.nt)\n",
    "        \n",
    "        return result, radon_domain, radon_filtered, p_values\n",
    "    \n",
    "    def anomalous_amplitude_attenuation(self, shot_gather, window_size=50, threshold_factor=3.0):\n",
    "        \"\"\"Anomalous Amplitude Attenuation (ì´ìƒ ì§„í­ ê°ì‡ )\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        \n",
    "        # ê° íŠ¸ë ˆì´ìŠ¤ì— ëŒ€í•´\n",
    "        for ix in range(n_traces):\n",
    "            trace = shot_gather[:, ix]\n",
    "            \n",
    "            # ì´ë™ ìœˆë„ìš°ë¡œ ë¡œì»¬ í†µê³„ ê³„ì‚°\n",
    "            for it in range(0, nt, window_size//2):\n",
    "                window_start = max(0, it - window_size//2)\n",
    "                window_end = min(nt, it + window_size//2)\n",
    "                window = trace[window_start:window_end]\n",
    "                \n",
    "                # ë¡œì»¬ í‰ê·  ë° í‘œì¤€í¸ì°¨\n",
    "                local_mean = np.mean(window)\n",
    "                local_std = np.std(window)\n",
    "                \n",
    "                # ì´ìƒ ì§„í­ íƒì§€ ë° ê°ì‡ \n",
    "                for i in range(window_start, window_end):\n",
    "                    if abs(trace[i] - local_mean) > threshold_factor * local_std:\n",
    "                        # ì´ìƒ ì§„í­ì„ ë¡œì»¬ í‰ê· ìœ¼ë¡œ ëŒ€ì²´ (ë¶€ë“œëŸ½ê²Œ)\n",
    "                        excess = trace[i] - local_mean\n",
    "                        attenuation = np.exp(-abs(excess) / (threshold_factor * local_std))\n",
    "                        result[i, ix] = local_mean + excess * attenuation\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def curvelet_denoise(self, shot_gather, wavelet='db4', level=None, threshold_scale=1.5, return_coeffs=False):\n",
    "        \"\"\"Curvelet ê¸°ë°˜ ë…¸ì´ì¦ˆ ì œê±° (Wavelet ê·¼ì‚¬) - íŒŒë¼ë¯¸í„° ì¡°ì • ê°€ëŠ¥\"\"\"\n",
    "        result = np.zeros_like(shot_gather)\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        \n",
    "        # ê° íŠ¸ë ˆì´ìŠ¤ì— Wavelet Denoising ì ìš©\n",
    "        for ix in range(n_traces):\n",
    "            trace = shot_gather[:, ix]\n",
    "            \n",
    "            # Wavelet decomposition\n",
    "            if level is None:\n",
    "                level = pywt.dwt_max_level(len(trace), wavelet)\n",
    "            \n",
    "            coeffs = pywt.wavedec(trace, wavelet, level=level)\n",
    "            \n",
    "            # Threshold estimation (Donoho)\n",
    "            sigma = np.median(np.abs(coeffs[-1])) / 0.6745\n",
    "            threshold = threshold_scale * sigma * np.sqrt(2 * np.log(len(trace)))\n",
    "            \n",
    "            # Soft thresholding\n",
    "            coeffs_thresh = [coeffs[0]]  # approximation coefficients\n",
    "            for i in range(1, len(coeffs)):\n",
    "                coeffs_thresh.append(pywt.threshold(coeffs[i], threshold, mode='soft'))\n",
    "            \n",
    "            # Reconstruction\n",
    "            result[:, ix] = pywt.waverec(coeffs_thresh, wavelet)[:nt]\n",
    "        \n",
    "        # 2D Wavelet denoising (ë°©í–¥ì„± ê³ ë ¤)\n",
    "        coeffs2d_original = None\n",
    "        coeffs2d_thresh = None\n",
    "        threshold2d = 0.0  # Default value in case 2D transform fails\n",
    "        \n",
    "        try:\n",
    "            # 2D stationary wavelet transform\n",
    "            coeffs2d_original = pywt.swt2(shot_gather, wavelet, level=3)\n",
    "            \n",
    "            # Threshold\n",
    "            sigma2d = np.median(np.abs(coeffs2d_original[-1][1])) / 0.6745\n",
    "            threshold2d = threshold_scale * sigma2d * np.sqrt(2 * np.log(nt * n_traces))\n",
    "            \n",
    "            # Apply thresholding\n",
    "            coeffs2d_thresh = []\n",
    "            for c in coeffs2d_original:\n",
    "                cA = c[0]\n",
    "                cH = pywt.threshold(c[1][0], threshold2d, mode='soft')\n",
    "                cV = pywt.threshold(c[1][1], threshold2d, mode='soft')\n",
    "                cD = pywt.threshold(c[1][2], threshold2d, mode='soft')\n",
    "                coeffs2d_thresh.append((cA, (cH, cV, cD)))\n",
    "            \n",
    "            # Reconstruction\n",
    "            result = pywt.iswt2(coeffs2d_thresh, wavelet)[:nt, :n_traces]\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: 2D wavelet transform failed ({str(e)}), using 1D result\")\n",
    "        \n",
    "        if return_coeffs:\n",
    "            return result, coeffs2d_original, coeffs2d_thresh, threshold2d\n",
    "        else:\n",
    "            return result\n",
    "    \n",
    "    def plot_model(self, model: Dict):\n",
    "        \"\"\"ì§€ì¸µ ëª¨ë¸ ì‹œê°í™”\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 8))\n",
    "        \n",
    "        depths = model['depth']\n",
    "        velocities = model['velocity']\n",
    "        densities = model['density']\n",
    "        \n",
    "        for i in range(len(depths)):\n",
    "            depth_top = depths[i]\n",
    "            depth_bottom = depths[i] + model['thickness'][i]\n",
    "            \n",
    "            ax1.fill_between([velocities[i]-100, velocities[i]+100],\n",
    "                            depth_top, depth_bottom,\n",
    "                            alpha=0.4, label=model['name'][i] if i < 5 else None)\n",
    "            ax1.plot([velocities[i], velocities[i]], [depth_top, depth_bottom],\n",
    "                    'b-', linewidth=2.5)\n",
    "            \n",
    "            ax2.fill_between([densities[i]-50, densities[i]+50],\n",
    "                            depth_top, depth_bottom,\n",
    "                            alpha=0.4)\n",
    "            ax2.plot([densities[i], densities[i]], [depth_top, depth_bottom],\n",
    "                    'r-', linewidth=2.5)\n",
    "        \n",
    "        ax1.set_xlabel('Velocity (m/s)', fontsize=13, fontweight='bold')\n",
    "        ax1.set_ylabel('Depth (m)', fontsize=13, fontweight='bold')\n",
    "        ax1.set_title('Velocity Model', fontsize=15, fontweight='bold')\n",
    "        ax1.invert_yaxis()\n",
    "        ax1.grid(True, alpha=0.4)\n",
    "        ax1.legend(fontsize=10)\n",
    "        \n",
    "        ax2.set_xlabel('Density (kg/mÂ³)', fontsize=13, fontweight='bold')\n",
    "        ax2.set_ylabel('Depth (m)', fontsize=13, fontweight='bold')\n",
    "        ax2.set_title('Density Model', fontsize=15, fontweight='bold')\n",
    "        ax2.invert_yaxis()\n",
    "        ax2.grid(True, alpha=0.4)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_shot_gather(self, shot_gather, offsets, title: str = \"Shot Gather\", clip_percentile: float = 99):\n",
    "        \"\"\"Shot Gather ì‹œê°í™”\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(14, 10))\n",
    "        vmax = np.percentile(np.abs(shot_gather), clip_percentile)\n",
    "        \n",
    "        for i, offset in enumerate(offsets):\n",
    "            trace = shot_gather[:, i]\n",
    "            trace_scaled = trace / vmax * 30\n",
    "            ax.plot(offset + trace_scaled, self.time, 'k-', linewidth=0.3)\n",
    "            ax.fill_betweenx(self.time, offset, offset + trace_scaled,\n",
    "                            where=(trace_scaled > 0), color='black', alpha=0.6)\n",
    "        \n",
    "        ax.set_xlabel('Offset (m)', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Time (s)', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(title, fontsize=15, fontweight='bold')\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax.set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_comparison_5(self, data1, data2, data3, data4, data5, offsets, titles):\n",
    "        \"\"\"5ê°œ ë¹„êµ\"\"\"\n",
    "        fig, axes = plt.subplots(1, 5, figsize=(28, 10))\n",
    "        data_list = [data1, data2, data3, data4, data5]\n",
    "        vmax = np.percentile(np.abs(data1), 99)\n",
    "        \n",
    "        for ax, data, title in zip(axes, data_list, titles):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                trace = data[:, i]\n",
    "                trace_scaled = trace / vmax * 30\n",
    "                ax.plot(offset + trace_scaled, self.time, 'k-', linewidth=0.3)\n",
    "                ax.fill_betweenx(self.time, offset, offset + trace_scaled,\n",
    "                                where=(trace_scaled > 0), color='black', alpha=0.6)\n",
    "            \n",
    "            ax.set_xlabel('Offset (m)', fontsize=10, fontweight='bold')\n",
    "            ax.set_ylabel('Time (s)', fontsize=10, fontweight='bold')\n",
    "            ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "            ax.invert_yaxis()\n",
    "            ax.grid(True, alpha=0.3, linestyle='--')\n",
    "            ax.set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"âœ… AdvancedMarineProcessor í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ!\")\n",
    "print(\"\\nâ­ ê³ ê¸‰ ì²˜ë¦¬ ê¸°ë²•:\")\n",
    "print(\"  1. Water Bottom Demultiple\")\n",
    "print(\"  2. Radon Transform Demultiple\")\n",
    "print(\"  3. Anomalous Amplitude Attenuation\")\n",
    "print(\"  4. Curvelet Denoise\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step2"
   },
   "source": [
    "## ğŸŒ Step 2: ëœë¤ í•©ì„± ëª¨ë¸ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_model"
   },
   "outputs": [],
   "source": [
    "processor = AdvancedMarineProcessor(dt=0.002, nt=1500)\n",
    "print(\"âœ… ê³ ê¸‰ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "print(f\"   - ìƒ˜í”Œë§ ê°„ê²©: {processor.dt*1000:.1f} ms\")\n",
    "print(f\"   - ì‹œê°„ ìƒ˜í”Œ: {processor.nt}ê°œ\")\n",
    "print(f\"   - ì´ ì‹œê°„: {processor.time[-1]:.2f} s\")\n",
    "print()\n",
    "\n",
    "print(\"ğŸŒ ëœë¤ í•©ì„± ì§€ë°˜ ëª¨ë¸ ìƒì„± ì¤‘...\")\n",
    "model = processor.create_random_model(nlayers=6)\n",
    "print(\"âœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ!\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ“Š ìƒì„±ëœ ì§€ì¸µ ì •ë³´\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Layer':<15} {'Depth (m)':<12} {'Thickness (m)':<15} {'Velocity (m/s)':<15} {'Density (kg/mÂ³)'}\")\n",
    "print(\"-\"*80)\n",
    "for i in range(len(model['name'])):\n",
    "    print(f\"{model['name'][i]:<15} {model['depth'][i]:<12.1f} {model['thickness'][i]:<15.1f} \"\n",
    "          f\"{model['velocity'][i]:<15.1f} {model['density'][i]:<15.1f}\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "processor.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step3"
   },
   "source": [
    "## ğŸ¯ Step 3-6: ë°ì´í„° ìƒì„± (Clean â†’ Direct â†’ Multiples â†’ Noise)\n",
    "\n",
    "**í•œ ë²ˆì— ì‹¤í–‰í•˜ì—¬ ê¸°ë³¸ ë°ì´í„° ìƒì„±**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate_data"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ¯ Shot Gather ìƒì„± íŒŒì´í”„ë¼ì¸...\")\n",
    "print()\n",
    "\n",
    "# ê¸°ë³¸ íŒŒë¼ë¯¸í„°\n",
    "n_traces = 48\n",
    "offset_min = 100\n",
    "offset_max = 2400\n",
    "freq = 25.0\n",
    "\n",
    "# Step 3: Clean Shot Gather\n",
    "print(\"[1/4] Clean Shot Gather ìƒì„±...\")\n",
    "clean_shot, offsets = processor.generate_shot_gather(model, n_traces=n_traces, \n",
    "                                                      offset_min=offset_min, \n",
    "                                                      offset_max=offset_max, freq=freq)\n",
    "print(f\"   âœ… RMS: {np.sqrt(np.mean(clean_shot**2)):.6f}\")\n",
    "\n",
    "# Step 4: ì§ì ‘íŒŒ ì¶”ê°€\n",
    "print(\"[2/4] ì§ì ‘íŒŒ ì¶”ê°€...\")\n",
    "with_direct = processor.add_direct_wave(clean_shot, offsets, model, strength=0.3)\n",
    "print(f\"   âœ… RMS: {np.sqrt(np.mean(with_direct**2)):.6f}\")\n",
    "\n",
    "# Step 5: Multiple ì¶”ê°€\n",
    "print(\"[3/4] Multiple ì¶”ê°€ (í•´ë©´ + ë‚´ë¶€)...\")\n",
    "with_sea_mult = processor.add_sea_surface_multiple(with_direct, model, strength=0.5)\n",
    "with_multiples = processor.add_internal_multiples(with_sea_mult, model, strength=0.3)\n",
    "print(f\"   âœ… RMS: {np.sqrt(np.mean(with_multiples**2)):.6f}\")\n",
    "\n",
    "# Step 6: í•´ìƒ ë…¸ì´ì¦ˆ ì¶”ê°€\n",
    "print(\"[4/4] í•´ìƒ ë…¸ì´ì¦ˆ ì¶”ê°€...\")\n",
    "noisy_shot = processor.add_marine_noise(with_multiples, offsets, noise_level=0.10)\n",
    "print(f\"   âœ… RMS: {np.sqrt(np.mean(noisy_shot**2)):.6f}\")\n",
    "print()\n",
    "\n",
    "# í†µê³„\n",
    "noise = noisy_shot - with_multiples\n",
    "snr_initial = 20 * np.log10(np.std(with_multiples) / np.std(noise))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ“Š ì´ˆê¸° ë°ì´í„° í†µê³„\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Signal RMS (Multiples):  {np.sqrt(np.mean(with_multiples**2)):.6f}\")\n",
    "print(f\"Noisy RMS:               {np.sqrt(np.mean(noisy_shot**2)):.6f}\")\n",
    "print(f\"SNR:                     {snr_initial:.2f} dB\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# ì‹œê°í™”\n",
    "print(\"ğŸ“ˆ ë…¸ì´ì¦ˆê°€ ì¶”ê°€ëœ Shot Gather ì‹œê°í™”...\")\n",
    "processor.plot_shot_gather(noisy_shot, offsets, \"ğŸ“¢ Noisy Shot Gather (Input)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step9"
   },
   "source": [
    "## âš¡ Step 7: Anomalous Amplitude Attenuation\n",
    "\n",
    "**ì´ ì…€ì„ ì‹¤í–‰í•˜ë©´:**\n",
    "- ì´ë™ ìœˆë„ìš°ë¡œ ë¡œì»¬ í†µê³„ ê³„ì‚°\n",
    "- ì´ìƒ ì§„í­ íƒì§€ (ì„ê³„ê°’ ì´ˆê³¼)\n",
    "- ì§€ìˆ˜ ê°ì‡ ë¡œ ë¶€ë“œëŸ½ê²Œ ì–µì œ\n",
    "- ì¦‰ì‹œ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aaa"
   },
   "outputs": [],
   "source": [
    "print(\"âš¡ Anomalous Amplitude Attenuation ì ìš© ì¤‘...\")\n",
    "print()\n",
    "print(\"ì²˜ë¦¬ ë°©ë²•:\")\n",
    "print(\"   - ì´ë™ ìœˆë„ìš° í†µê³„ (í‰ê· , í‘œì¤€í¸ì°¨)\")\n",
    "print(\"   - ì´ìƒ ì§„í­ íƒì§€ (> 3Ïƒ)\")\n",
    "print(\"   - ì§€ìˆ˜ ê°ì‡  ì ìš©\")\n",
    "print()\n",
    "\n",
    "# Anomalous Amplitude Attenuation\n",
    "after_aaa = processor.anomalous_amplitude_attenuation(noisy_shot, \n",
    "                                                       window_size=50, \n",
    "                                                       threshold_factor=3.0)\n",
    "\n",
    "print(\"âœ… Anomalous Amplitude Attenuation ì™„ë£Œ!\")\n",
    "print()\n",
    "\n",
    "# í†µê³„\n",
    "removed_anom = noisy_shot - after_aaa\n",
    "\n",
    "print(\"ğŸ“ˆ í†µê³„:\")\n",
    "print(f\"   - Before AAA RMS: {np.sqrt(np.mean(noisy_shot**2)):.6f}\")\n",
    "print(f\"   - After AAA RMS:  {np.sqrt(np.mean(after_aaa**2)):.6f}\")\n",
    "print(f\"   - Attenuated RMS: {np.sqrt(np.mean(removed_anom**2)):.6f}\")\n",
    "print(f\"   - Anomaly Reduction: {(np.sqrt(np.mean(removed_anom**2))/np.sqrt(np.mean(noisy_shot**2)))*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# ì‹œê°í™”\n",
    "print(\"ğŸ“ˆ Anomalous Amplitude Attenuation ê²°ê³¼ ì‹œê°í™”...\")\n",
    "processor.plot_shot_gather(after_aaa, offsets, \"âš¡ After Anomalous Amplitude Attenuation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step8"
   },
   "source": [
    "## ğŸ”Š Step 8: Low-cut Filter (1.5 Hz)\n",
    "\n",
    "**ì´ ì…€ì„ ì‹¤í–‰í•˜ë©´:**\n",
    "- High-pass (Low-cut) í•„í„° ì ìš©\n",
    "- 1.5 Hz ì´í•˜ ì €ì£¼íŒŒ ë…¸ì´ì¦ˆ ì œê±°\n",
    "- Swell noise, Ship noise ì €ì£¼íŒŒ ì„±ë¶„ ì œê±°\n",
    "- **íŒŒë¼ë¯¸í„° ì¡°ì •**: `cutoff_freq`, `filter_order`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lowcut"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ”Š Low-cut Filter ì ìš© ì¤‘...\")\n",
    "print()\n",
    "print(\"ì²˜ë¦¬ ë°©ë²•:\")\n",
    "print(\"   - Butterworth High-pass Filter\")\n",
    "print(\"   - ì €ì£¼íŒŒ ë…¸ì´ì¦ˆ ì œê±° (Swell, Ship)\")\n",
    "print(\"   - Zero-phase filtering (filtfilt)\")\n",
    "print()\n",
    "print(\"âš™ï¸ íŒŒë¼ë¯¸í„° ì¡°ì • ê°€ëŠ¥:\")\n",
    "print(\"   - cutoff_freq: Cutoff ì£¼íŒŒìˆ˜ (ê¸°ë³¸ 1.5 Hz)\")\n",
    "print(\"   - filter_order: í•„í„° ì°¨ìˆ˜ (ê¸°ë³¸ 5)\")\n",
    "print()\n",
    "\n",
    "# ğŸ”§ ì—¬ê¸°ì„œ íŒŒë¼ë¯¸í„° ì¡°ì •!\n",
    "cutoff_freq = 1.5  # Hz, ì´ ì£¼íŒŒìˆ˜ ì´í•˜ë¥¼ ì œê±° (ì˜ˆ: 1.0, 1.5, 2.0, 3.0)\n",
    "filter_order = 5   # í•„í„° ì°¨ìˆ˜, ë†’ì„ìˆ˜ë¡ sharp (ì˜ˆ: 3, 5, 7)\n",
    "\n",
    "print(f\"\\nğŸ“Œ í˜„ì¬ íŒŒë¼ë¯¸í„°:\")\n",
    "print(f\"   - Cutoff Frequency: {cutoff_freq} Hz\")\n",
    "print(f\"   - Filter Order: {filter_order}\")\n",
    "print()\n",
    "\n",
    "# Low-cut Filter\n",
    "after_lowcut = processor.lowcut_filter(after_aaa, cutoff_freq=cutoff_freq, order=filter_order)\n",
    "\n",
    "print(\"âœ… Low-cut Filter ì™„ë£Œ!\")\n",
    "print()\n",
    "\n",
    "# í†µê³„\n",
    "removed_lowfreq = after_aaa - after_lowcut\n",
    "\n",
    "print(\"ğŸ“ˆ í†µê³„:\")\n",
    "print(f\"   - Before Lowcut RMS: {np.sqrt(np.mean(after_aaa**2)):.6f}\")\n",
    "print(f\"   - After Lowcut RMS:  {np.sqrt(np.mean(after_lowcut**2)):.6f}\")\n",
    "print(f\"   - Removed Low-freq RMS: {np.sqrt(np.mean(removed_lowfreq**2)):.6f}\")\n",
    "print(f\"   - Energy Reduction: {(np.sqrt(np.mean(removed_lowfreq**2))/np.sqrt(np.mean(after_aaa**2)))*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# ì£¼íŒŒìˆ˜ ìŠ¤í™íŠ¸ëŸ¼ ë¹„êµ\n",
    "print(\"ğŸ“Š ì£¼íŒŒìˆ˜ ìŠ¤í™íŠ¸ëŸ¼ ë¹„êµ...\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Before lowcut - frequency spectrum\n",
    "trace_before = after_aaa[:, after_aaa.shape[1]//2]  # Middle trace\n",
    "fft_before = np.fft.rfft(trace_before)\n",
    "freq = np.fft.rfftfreq(len(trace_before), processor.dt)\n",
    "power_before = np.abs(fft_before)**2\n",
    "\n",
    "# After lowcut - frequency spectrum\n",
    "trace_after = after_lowcut[:, after_lowcut.shape[1]//2]\n",
    "fft_after = np.fft.rfft(trace_after)\n",
    "power_after = np.abs(fft_after)**2\n",
    "\n",
    "axes[0].semilogy(freq, power_before, \"b-\", label=\"Before Lowcut\", linewidth=1.5, alpha=0.7)\n",
    "axes[0].semilogy(freq, power_after, \"r-\", label=\"After Lowcut\", linewidth=1.5, alpha=0.7)\n",
    "axes[0].axvline(cutoff_freq, color=\"green\", linestyle=\"--\", linewidth=2, label=f\"Cutoff ({cutoff_freq} Hz)\")\n",
    "axes[0].set_xlabel(\"Frequency (Hz)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0].set_ylabel(\"Power\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0].set_title(\"Frequency Spectrum (ì¤‘ì•™ íŠ¸ë ˆì´ìŠ¤)\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0].set_xlim([0, 100])\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend(fontsize=11)\n",
    "\n",
    "# Shot gather comparison\n",
    "for i, offset in enumerate(offsets):\n",
    "    trace = after_lowcut[:, i]\n",
    "    vmax = np.percentile(np.abs(after_lowcut), 99)\n",
    "    trace_scaled = trace / vmax * 30\n",
    "    axes[1].plot(offset + trace_scaled, processor.time, \"k-\", linewidth=0.3)\n",
    "    axes[1].fill_betweenx(processor.time, offset, offset + trace_scaled,\n",
    "                         where=(trace_scaled > 0), color=\"black\", alpha=0.6)\n",
    "\n",
    "axes[1].set_xlabel(\"Offset (m)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1].set_ylabel(\"Time (s)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1].set_title(\"After Low-cut Filter\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(True, alpha=0.3, linestyle=\"--\")\n",
    "axes[1].set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"ğŸ’¡ í•´ì„:\")\n",
    "print(\"   - ì¢Œì¸¡: 1.5 Hz ì´í•˜ ì €ì£¼íŒŒê°€ ì œê±°ë˜ì—ˆìŒì„ í™•ì¸\")\n",
    "print(\"   - ìš°ì¸¡: Swell noise, Ship noise ì €ì£¼íŒŒ ì„±ë¶„ ê°ì†Œ\")\n",
    "print()\n",
    "print(\"ğŸ”§ íŒŒë¼ë¯¸í„° ì¡°ì • ë°©ë²•:\")\n",
    "print(\"   - cutoff_freq â†‘ â†’ ë” ë§ì€ ì €ì£¼íŒŒ ì œê±° (ë‹¨, ì‹ í˜¸ ì €ì£¼íŒŒë„ ì†ì‹¤)\")\n",
    "print(\"   - cutoff_freq â†“ â†’ ì‹ í˜¸ ë³´ì¡´ ìš°ì„  (ì €ì£¼íŒŒ ë…¸ì´ì¦ˆ ì”ì¡´)\")\n",
    "print(\"   - ê¶Œì¥ê°’: 1.0 ~ 3.0 Hz ë²”ìœ„\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step10"
   },
   "source": [
    "## ğŸŒ€ Step 9: Curvelet Denoise (ì¸í„°ë™í‹°ë¸Œ)\n",
    "\n",
    "**ì´ ì…€ì„ ì‹¤í–‰í•˜ë©´:**\n",
    "- 1D Wavelet ë¶„í•´ (ê° íŠ¸ë ˆì´ìŠ¤)\n",
    "- 2D Stationary Wavelet Transform (ë°©í–¥ì„± ê³ ë ¤)\n",
    "- **Wavelet ê³„ìˆ˜ ì‹œê°í™”** (ì›ë³¸ + Thresholding)\n",
    "- Soft thresholding\n",
    "- Wavelet ì¬êµ¬ì„±\n",
    "- **íŒŒë¼ë¯¸í„° ì¡°ì •**: `threshold_scale`, `wavelet`, `level`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "curvelet"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸŒ€ Curvelet Denoise ì ìš© ì¤‘...\")\n",
    "print()\n",
    "print(\"ì²˜ë¦¬ ë°©ë²•:\")\n",
    "print(\"   - 1D Wavelet ë¶„í•´ (ê° íŠ¸ë ˆì´ìŠ¤)\")\n",
    "print(\"   - 2D Stationary Wavelet Transform\")\n",
    "print(\"   - Soft thresholding (Donoho)\")\n",
    "print(\"   - Wavelet ì¬êµ¬ì„±\")\n",
    "print()\n",
    "print(\"âš™ï¸ íŒŒë¼ë¯¸í„° ì¡°ì • ê°€ëŠ¥:\")\n",
    "print(\"   - threshold_scale: Threshold ìŠ¤ì¼€ì¼ë§ (ê¸°ë³¸ 1.5)\")\n",
    "print(\"   - wavelet: Wavelet ì¢…ë¥˜ (db4, sym4, coif2 ë“±)\")\n",
    "print(\"   - level: ë¶„í•´ ë ˆë²¨ (None=ìë™)\")\n",
    "print()\n",
    "print(\"â³ ì²˜ë¦¬ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\")\n",
    "\n",
    "# ğŸ”§ ì—¬ê¸°ì„œ íŒŒë¼ë¯¸í„° ì¡°ì •!\n",
    "threshold_scale = 1.5  # ë‚®ì¶”ë©´ ë” ë§ì´ ì œê±° (ì˜ˆ: 0.5, 1.0, 1.5, 2.0, 2.5)\n",
    "wavelet_type = 'db4'   # 'db4', 'sym4', 'coif2', 'bior2.2' ë“±\n",
    "level = None           # None=ìë™, ë˜ëŠ” ì •ìˆ˜ (ì˜ˆ: 3, 4, 5)\n",
    "\n",
    "print(f\"\\nğŸ“Œ í˜„ì¬ íŒŒë¼ë¯¸í„°:\")\n",
    "print(f\"   - Threshold Scale: {threshold_scale}\")\n",
    "print(f\"   - Wavelet Type: {wavelet_type}\")\n",
    "print(f\"   - Decomposition Level: {level if level else 'Auto'}\")\n",
    "print()\n",
    "\n",
    "# Curvelet Denoise (ê³„ìˆ˜ ë°˜í™˜)\n",
    "final_shot, coeffs_original, coeffs_thresh, threshold_value = processor.curvelet_denoise(\n",
    "    after_lowcut, \n",
    "    wavelet=wavelet_type, \n",
    "    level=level, \n",
    "    threshold_scale=threshold_scale,\n",
    "    return_coeffs=True\n",
    ")\n",
    "\n",
    "print(\"âœ… Curvelet Denoise ì™„ë£Œ!\")\n",
    "print()\n",
    "\n",
    "# ìµœì¢… í†µê³„\n",
    "removed_noise = after_lowcut - final_shot\n",
    "final_residual = final_shot - with_direct\n",
    "snr_final = 20 * np.log10(np.std(with_direct) / np.std(final_residual))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ“Š ìµœì¢… ê²°ê³¼\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Before Curvelet RMS:    {np.sqrt(np.mean(after_lowcut**2)):.6f}\")\n",
    "print(f\"Final RMS:              {np.sqrt(np.mean(final_shot**2)):.6f}\")\n",
    "print(f\"Removed Noise RMS:      {np.sqrt(np.mean(removed_noise**2)):.6f}\")\n",
    "print(f\"Threshold Value:        {threshold_value:.6f}\")\n",
    "print()\n",
    "print(f\"SNR (ì´ˆê¸°):              {snr_initial:.2f} dB\")\n",
    "print(f\"SNR (ìµœì¢…):              {snr_final:.2f} dB\")\n",
    "print(f\"SNR ê°œì„ :                {snr_final - snr_initial:.2f} dB  â¬†ï¸â¬†ï¸â¬†ï¸\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# ğŸ¨ Wavelet ê³„ìˆ˜ ì‹œê°í™”\n",
    "if coeffs_original is not None and coeffs_thresh is not None:\n",
    "    print(\"ğŸ“Š Wavelet ê³„ìˆ˜ ì‹œê°í™” (Level 3, Horizontal/Vertical/Diagonal)...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Level 3 ê³„ìˆ˜ ì¶”ì¶œ\n",
    "    level_idx = -1  # ë§ˆì§€ë§‰ ë ˆë²¨\n",
    "    cH_orig = coeffs_original[level_idx][1][0]  # Horizontal\n",
    "    cV_orig = coeffs_original[level_idx][1][1]  # Vertical\n",
    "    cD_orig = coeffs_original[level_idx][1][2]  # Diagonal\n",
    "    \n",
    "    cH_thresh = coeffs_thresh[level_idx][1][0]\n",
    "    cV_thresh = coeffs_thresh[level_idx][1][1]\n",
    "    cD_thresh = coeffs_thresh[level_idx][1][2]\n",
    "    \n",
    "    vmax = np.percentile(np.abs(cH_orig), 99)\n",
    "    \n",
    "    # Original coefficients\n",
    "    im1 = axes[0, 0].imshow(cH_orig, aspect='auto', cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    axes[0, 0].set_title('Original - Horizontal (cH)', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Time', fontsize=11)\n",
    "    axes[0, 0].set_xlabel('Trace', fontsize=11)\n",
    "    plt.colorbar(im1, ax=axes[0, 0])\n",
    "    \n",
    "    im2 = axes[0, 1].imshow(cV_orig, aspect='auto', cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    axes[0, 1].set_title('Original - Vertical (cV)', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Time', fontsize=11)\n",
    "    axes[0, 1].set_xlabel('Trace', fontsize=11)\n",
    "    plt.colorbar(im2, ax=axes[0, 1])\n",
    "    \n",
    "    im3 = axes[0, 2].imshow(cD_orig, aspect='auto', cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    axes[0, 2].set_title('Original - Diagonal (cD)', fontsize=12, fontweight='bold')\n",
    "    axes[0, 2].set_ylabel('Time', fontsize=11)\n",
    "    axes[0, 2].set_xlabel('Trace', fontsize=11)\n",
    "    plt.colorbar(im3, ax=axes[0, 2])\n",
    "    \n",
    "    # Thresholded coefficients\n",
    "    im4 = axes[1, 0].imshow(cH_thresh, aspect='auto', cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    axes[1, 0].set_title(f'Thresholded - Horizontal (scale={threshold_scale})', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('Time', fontsize=11)\n",
    "    axes[1, 0].set_xlabel('Trace', fontsize=11)\n",
    "    plt.colorbar(im4, ax=axes[1, 0])\n",
    "    \n",
    "    im5 = axes[1, 1].imshow(cV_thresh, aspect='auto', cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    axes[1, 1].set_title(f'Thresholded - Vertical (scale={threshold_scale})', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('Time', fontsize=11)\n",
    "    axes[1, 1].set_xlabel('Trace', fontsize=11)\n",
    "    plt.colorbar(im5, ax=axes[1, 1])\n",
    "    \n",
    "    im6 = axes[1, 2].imshow(cD_thresh, aspect='auto', cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    axes[1, 2].set_title(f'Thresholded - Diagonal (scale={threshold_scale})', fontsize=12, fontweight='bold')\n",
    "    axes[1, 2].set_ylabel('Time', fontsize=11)\n",
    "    axes[1, 2].set_xlabel('Trace', fontsize=11)\n",
    "    plt.colorbar(im6, ax=axes[1, 2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print()\n",
    "    print(\"ğŸ’¡ Wavelet ê³„ìˆ˜ í•´ì„:\")\n",
    "    print(\"   - Horizontal (cH): ìˆ˜í‰ ë°©í–¥ ê³ ì£¼íŒŒ (ì¸µê²½ê³„)\")\n",
    "    print(\"   - Vertical (cV): ìˆ˜ì§ ë°©í–¥ ê³ ì£¼íŒŒ (íŠ¸ë ˆì´ìŠ¤ ê°„ ë³€í™”)\")\n",
    "    print(\"   - Diagonal (cD): ëŒ€ê°ì„  ë°©í–¥ ê³ ì£¼íŒŒ (ë³µí•© ë…¸ì´ì¦ˆ)\")\n",
    "    print(\"   - Thresholding í›„: ì•½í•œ ê³„ìˆ˜ ì œê±° â†’ ë…¸ì´ì¦ˆ ê°ì†Œ\")\n",
    "    print()\n",
    "    print(\"ğŸ”§ íŒŒë¼ë¯¸í„° ì¡°ì • ë°©ë²•:\")\n",
    "    print(\"   - threshold_scale â†“ â†’ ë” ë§ì€ ë…¸ì´ì¦ˆ ì œê±° (ë‹¨, ì‹ í˜¸ ì†ì‹¤ ì£¼ì˜)\")\n",
    "    print(\"   - threshold_scale â†‘ â†’ ì‹ í˜¸ ë³´ì¡´ ìš°ì„  (ë…¸ì´ì¦ˆ ì”ì¡´ ê°€ëŠ¥)\")\n",
    "    print(\"   - ê¶Œì¥ê°’: 0.5 ~ 2.5 ë²”ìœ„ì—ì„œ ì¡°ì •\")\n",
    "    print()\n",
    "\n",
    "# ì‹œê°í™”\n",
    "print(\"ğŸ“ˆ ìµœì¢… ê²°ê³¼ ì‹œê°í™”...\")\n",
    "processor.plot_shot_gather(final_shot, offsets, \"ğŸŒ€ Final: After Curvelet Denoise\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step10"
   },
   "source": [
    "## ğŸ¯ Step 10: ì§ì ‘íŒŒ ì œê±° (Direct Wave Mute)\n",
    "\n",
    "**ì´ ì…€ì„ ì‹¤í–‰í•˜ë©´:**\n",
    "- Top Mute ì ìš©í•˜ì—¬ ì§ì ‘íŒŒ ì œê±°\n",
    "- Mute velocity ì´ìƒì˜ ì´ë²¤íŠ¸ ì œê±° (ì¼ë°˜ì ìœ¼ë¡œ ~1500 m/s)\n",
    "- Cosine taperë¡œ ë¶€ë“œëŸ¬ìš´ ì „í™˜\n",
    "- **íŒŒë¼ë¯¸í„° ì¡°ì •**: `mute_velocity`, `taper_length`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "direct_wave_mute"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ¯ ì§ì ‘íŒŒ ì œê±° (Direct Wave Mute) ì ìš© ì¤‘...\")\n",
    "print()\n",
    "print(\"ì²˜ë¦¬ ë°©ë²•:\")\n",
    "print(\"   - Top Mute: ì§ì ‘íŒŒ ë„ë‹¬ ì‹œê°„ ì´ì „ ì œê±°\")\n",
    "print(\"   - Mute line: t_mute = offset / mute_velocity\")\n",
    "print(\"   - Cosine taperë¡œ ë¶€ë“œëŸ¬ìš´ ì „í™˜\")\n",
    "print()\n",
    "print(\"âš™ï¸ íŒŒë¼ë¯¸í„° ì¡°ì • ê°€ëŠ¥:\")\n",
    "print(\"   - mute_velocity: Mute ì†ë„ (ê¸°ë³¸ 1500 m/s)\")\n",
    "print(\"   - taper_length: Taper ê¸¸ì´ (ìƒ˜í”Œ ìˆ˜, ê¸°ë³¸ 50)\")\n",
    "print()\n",
    "\n",
    "# ğŸ”§ ì—¬ê¸°ì„œ íŒŒë¼ë¯¸í„° ì¡°ì •!\n",
    "mute_velocity = 1500  # m/s, ì´ ì†ë„ ì´ìƒì„ ì œê±° (ì˜ˆ: 1400, 1500, 1600)\n",
    "taper_length = 50     # samples, taper êµ¬ê°„ ê¸¸ì´ (ì˜ˆ: 30, 50, 100)\n",
    "\n",
    "print(f\"\\nğŸ“Œ í˜„ì¬ íŒŒë¼ë¯¸í„°:\")\n",
    "print(f\"   - Mute Velocity: {mute_velocity} m/s\")\n",
    "print(f\"   - Taper Length: {taper_length} samples ({taper_length * processor.dt:.3f} s)\")\n",
    "print()\n",
    "\n",
    "# Direct Wave Removal\n",
    "after_direct_mute = processor.remove_direct_wave(final_shot, offsets, model, \n",
    "                                                   mute_velocity=mute_velocity, \n",
    "                                                   taper_length=taper_length)\n",
    "\n",
    "print(\"âœ… ì§ì ‘íŒŒ ì œê±° ì™„ë£Œ!\")\n",
    "print()\n",
    "\n",
    "# í†µê³„\n",
    "removed_direct = final_shot - after_direct_mute\n",
    "\n",
    "print(\"ğŸ“ˆ í†µê³„:\")\n",
    "print(f\"   - Before Direct Mute RMS: {np.sqrt(np.mean(final_shot**2)):.6f}\")\n",
    "print(f\"   - After Direct Mute RMS:  {np.sqrt(np.mean(after_direct_mute**2)):.6f}\")\n",
    "print(f\"   - Removed Direct Wave RMS: {np.sqrt(np.mean(removed_direct**2)):.6f}\")\n",
    "print(f\"   - Energy Reduction: {(np.sqrt(np.mean(removed_direct**2))/np.sqrt(np.mean(final_shot**2)))*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# ì‹œê°í™” - Before/After ë¹„êµ\n",
    "print(\"ğŸ“Š ì§ì ‘íŒŒ ì œê±° ì „í›„ ë¹„êµ...\")\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "vmax = np.percentile(np.abs(final_shot), 99)\n",
    "\n",
    "# Before\n",
    "for i, offset in enumerate(offsets):\n",
    "    trace = final_shot[:, i]\n",
    "    trace_scaled = trace / vmax * 30\n",
    "    axes[0].plot(offset + trace_scaled, processor.time, \"k-\", linewidth=0.3)\n",
    "    axes[0].fill_betweenx(processor.time, offset, offset + trace_scaled,\n",
    "                         where=(trace_scaled > 0), color=\"black\", alpha=0.6)\n",
    "    # Mute line\n",
    "    mute_time = offset / mute_velocity\n",
    "    axes[0].plot([offset-30, offset+30], [mute_time, mute_time], \"r-\", linewidth=2, alpha=0.7)\n",
    "\n",
    "axes[0].set_xlabel(\"Offset (m)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0].set_ylabel(\"Time (s)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0].set_title(\"Before Direct Wave Mute\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(True, alpha=0.3, linestyle=\"--\")\n",
    "axes[0].set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "\n",
    "# After\n",
    "for i, offset in enumerate(offsets):\n",
    "    trace = after_direct_mute[:, i]\n",
    "    trace_scaled = trace / vmax * 30\n",
    "    axes[1].plot(offset + trace_scaled, processor.time, \"k-\", linewidth=0.3)\n",
    "    axes[1].fill_betweenx(processor.time, offset, offset + trace_scaled,\n",
    "                         where=(trace_scaled > 0), color=\"black\", alpha=0.6)\n",
    "\n",
    "axes[1].set_xlabel(\"Offset (m)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1].set_ylabel(\"Time (s)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1].set_title(\"After Direct Wave Mute\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(True, alpha=0.3, linestyle=\"--\")\n",
    "axes[1].set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "\n",
    "# Removed\n",
    "for i, offset in enumerate(offsets):\n",
    "    trace = removed_direct[:, i]\n",
    "    trace_scaled = trace / vmax * 30\n",
    "    axes[2].plot(offset + trace_scaled, processor.time, \"k-\", linewidth=0.3)\n",
    "    axes[2].fill_betweenx(processor.time, offset, offset + trace_scaled,\n",
    "                         where=(trace_scaled > 0), color=\"black\", alpha=0.6)\n",
    "\n",
    "axes[2].set_xlabel(\"Offset (m)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[2].set_ylabel(\"Time (s)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[2].set_title(\"Removed Direct Wave\", fontsize=14, fontweight=\"bold\")\n",
    "axes[2].invert_yaxis()\n",
    "axes[2].grid(True, alpha=0.3, linestyle=\"--\")\n",
    "axes[2].set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"ğŸ’¡ í•´ì„:\")\n",
    "print(\"   - ì¢Œì¸¡: ì§ì ‘íŒŒê°€ ì„ í˜• moveoutìœ¼ë¡œ ë³´ì„ (ë¹¨ê°„ ì„ ì´ mute line)\")\n",
    "print(\"   - ì¤‘ì•™: ì§ì ‘íŒŒê°€ ì œê±°ë˜ê³  ë°˜ì‚¬íŒŒë§Œ ë‚¨ìŒ\")\n",
    "print(\"   - ìš°ì¸¡: ì œê±°ëœ ì§ì ‘íŒŒ í™•ì¸\")\n",
    "print()\n",
    "print(\"ğŸ”§ íŒŒë¼ë¯¸í„° ì¡°ì • ë°©ë²•:\")\n",
    "print(\"   - mute_velocity â†“ â†’ ë” ë§ì´ ì œê±° (ë‹¨, ì–•ì€ ë°˜ì‚¬íŒŒ ì†ì‹¤ ì£¼ì˜)\")\n",
    "print(\"   - mute_velocity â†‘ â†’ ë³´ìˆ˜ì  ì œê±° (ì§ì ‘íŒŒ ì”ì¡´ ê°€ëŠ¥)\")\n",
    "print(\"   - taper_length â†‘ â†’ ë¶€ë“œëŸ¬ìš´ ì „í™˜ (artifacts ê°ì†Œ)\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step7"
   },
   "source": [
    "## ğŸŒŠ Step 11: Water Bottom Demultiple\n",
    "\n",
    "**ì´ ì…€ì„ ì‹¤í–‰í•˜ë©´:**\n",
    "- í•´ì €ë©´-í•´ë©´ ë©€í‹°í”Œ ì œê±°\n",
    "- 1ì°¨, 2ì°¨, 3ì°¨ ë©€í‹°í”Œ ì˜ˆì¸¡ ë° ê°ì‡ \n",
    "- ì¦‰ì‹œ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wb_demult"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸŒŠ Water Bottom Demultiple ì ìš© ì¤‘...\")\n",
    "print()\n",
    "print(\"ì²˜ë¦¬ ë°©ë²•:\")\n",
    "print(\"   - í•´ì €ë©´ ì–‘ë°©í–¥ ì£¼ì‹œ ê³„ì‚°\")\n",
    "print(\"   - í•´ì €ë©´-í•´ë©´ ë©€í‹°í”Œ ì˜ˆì¸¡\")\n",
    "print(\"   - 1ì°¨, 2ì°¨, 3ì°¨ ë©€í‹°í”Œ ì œê±°\")\n",
    "print()\n",
    "\n",
    "# Water Bottom Demultiple\n",
    "wb_demult_strength = 0.8\n",
    "after_wb = processor.water_bottom_demultiple(after_direct_mute, model, strength=wb_demult_strength)\n",
    "\n",
    "print(\"âœ… Water Bottom Demultiple ì™„ë£Œ!\")\n",
    "print()\n",
    "\n",
    "# í†µê³„\n",
    "removed_wb_mult = after_direct_mute - after_wb\n",
    "\n",
    "print(\"ğŸ“ˆ í†µê³„:\")\n",
    "print(f\"   - Before WB Demult RMS: {np.sqrt(np.mean(after_direct_mute**2)):.6f}\")\n",
    "print(f\"   - After WB Demult RMS:  {np.sqrt(np.mean(after_wb**2)):.6f}\")\n",
    "print(f\"   - Removed Multiples RMS: {np.sqrt(np.mean(removed_wb_mult**2)):.6f}\")\n",
    "print(f\"   - Reduction: {(1 - np.sqrt(np.mean(after_wb**2))/np.sqrt(np.mean(after_direct_mute**2)))*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# ì‹œê°í™”\n",
    "print(\"ğŸ“ˆ Water Bottom Demultiple ê²°ê³¼ ì‹œê°í™”...\")\n",
    "processor.plot_shot_gather(after_wb, offsets, \"ğŸŒŠ After Water Bottom Demultiple\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step8"
   },
   "source": [
    "## ğŸ”„ Step 12: Radon Transform Demultiple (ì¸í„°ë™í‹°ë¸Œ)\n",
    "\n",
    "**ì´ ì…€ì„ ì‹¤í–‰í•˜ë©´:**\n",
    "- Radon ë³€í™˜ìœ¼ë¡œ t-x â†’ Ï„-p ë„ë©”ì¸ ë³€í™˜\n",
    "- **Ï„-p ë„ë©”ì¸ ì‹œê°í™”** (ì›ë³¸ + í•„í„°ë§)\n",
    "- Multiple ì„±ë¶„ ì–µì œ (ë‚®ì€ ray parameter)\n",
    "- ì—­ë³€í™˜ìœ¼ë¡œ ë³µì›\n",
    "- **íŒŒë¼ë¯¸í„° ì¡°ì •**: `threshold_percentile`, `p_min`, `p_max`, `n_p`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "radon_demult"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ”„ Radon Transform Demultiple ì ìš© ì¤‘...\")\n",
    "print()\n",
    "print(\"ì²˜ë¦¬ ë°©ë²•:\")\n",
    "print(\"   - Forward Radon Transform (t-x â†’ Ï„-p)\")\n",
    "print(\"   - Multiple ì„±ë¶„ ì–µì œ (ë‚®ì€ ray parameter)\")\n",
    "print(\"   - Inverse Radon Transform (Ï„-p â†’ t-x)\")\n",
    "print()\n",
    "print(\"âš™ï¸ íŒŒë¼ë¯¸í„° ì¡°ì • ê°€ëŠ¥:\")\n",
    "print(\"   - threshold_percentile: Multiple ì œê±° ì„ê³„ê°’ (ê¸°ë³¸ 75)\")\n",
    "print(\"   - p_min, p_max: Ray parameter ë²”ìœ„\")\n",
    "print(\"   - n_p: Ray parameter ìƒ˜í”Œ ìˆ˜\")\n",
    "print()\n",
    "print(\"â³ ì²˜ë¦¬ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\")\n",
    "\n",
    "# ğŸ”§ ì—¬ê¸°ì„œ íŒŒë¼ë¯¸í„° ì¡°ì •!\n",
    "threshold_percentile = 75  # ë‚®ì¶”ë©´ ë” ë§ì´ ì œê±° (ì˜ˆ: 50, 60, 70, 75, 80, 90)\n",
    "p_min = -0.001  # Ray parameter ìµœì†Œê°’\n",
    "p_max = 0.001   # Ray parameter ìµœëŒ€ê°’\n",
    "n_p = 64        # Ray parameter ìƒ˜í”Œ ìˆ˜\n",
    "\n",
    "print(f\"\\nğŸ“Œ í˜„ì¬ íŒŒë¼ë¯¸í„°:\")\n",
    "print(f\"   - Threshold Percentile: {threshold_percentile}\")\n",
    "print(f\"   - Ray Parameter Range: [{p_min}, {p_max}]\")\n",
    "print(f\"   - Number of Ray Parameters: {n_p}\")\n",
    "print()\n",
    "\n",
    "\n",
    "# ğŸ“˜ Radon Transform ìˆ˜ì‹:\n",
    "#   Forward:  R(Ï„, p) = Î£_x D(Ï„ - pÂ·x, x)  [t-x â†’ Ï„-p]\n",
    "#   Inverse:  D(t, x) = Î£_p R(t + pÂ·x, p)  [Ï„-p â†’ t-x]\n",
    "# \n",
    "#   Ï„ (tau): Intercept time (ìˆ˜ì§ ì£¼ì‹œ)\n",
    "#   p: Ray parameter (slowness, 1/velocity)\n",
    "#   x: Offset (ì†¡ìˆ˜ì‹ ê¸° ê±°ë¦¬)\n",
    "#   Primary reflection: ë†’ì€ ì†ë„ (p â‰ˆ 0)\n",
    "#   Multiple: ë‚®ì€ ì†ë„ (p ê°’ì´ í¬ê±°ë‚˜ ì‘ìŒ)\n",
    "\n",
    "# Radon Transform Demultiple (ë°˜í™˜ê°’ í™•ì¥)\n",
    "after_radon, radon_original, radon_filtered, p_values = processor.radon_transform_demultiple(\n",
    "    after_wb, offsets, \n",
    "    p_min=p_min, p_max=p_max, n_p=n_p, \n",
    "    threshold_percentile=threshold_percentile\n",
    ")\n",
    "\n",
    "print(\"âœ… Radon Transform Demultiple ì™„ë£Œ!\")\n",
    "print()\n",
    "\n",
    "# í†µê³„\n",
    "removed_radon_mult = after_wb - after_radon\n",
    "\n",
    "print(\"ğŸ“ˆ í†µê³„:\")\n",
    "print(f\"   - Before Radon RMS: {np.sqrt(np.mean(after_wb**2)):.6f}\")\n",
    "print(f\"   - After Radon RMS:  {np.sqrt(np.mean(after_radon**2)):.6f}\")\n",
    "print(f\"   - Removed Multiples RMS: {np.sqrt(np.mean(removed_radon_mult**2)):.6f}\")\n",
    "print(f\"   - Additional Reduction: {(1 - np.sqrt(np.mean(after_radon**2))/np.sqrt(np.mean(after_wb**2)))*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# ğŸ¨ Ï„-p ë„ë©”ì¸ ì‹œê°í™” (ì›ë³¸ vs í•„í„°ë§)\n",
    "print(\"ğŸ“Š Ï„-p ë„ë©”ì¸ ì‹œê°í™”...\")\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "# ì›ë³¸ Radon ë„ë©”ì¸\n",
    "vmax_radon = np.percentile(np.abs(radon_original), 99)\n",
    "axes[0].imshow(radon_original, aspect='auto', cmap='seismic', \n",
    "               vmin=-vmax_radon, vmax=vmax_radon, \n",
    "               extent=[p_values[0]*1000, p_values[-1]*1000, processor.time[-1], processor.time[0]])\n",
    "axes[0].set_xlabel('Ray Parameter p (Ã—10â»Â³ s/m)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Intercept Time Ï„ (s)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Original Radon Domain (Ï„-p)', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# í•„í„°ë§ëœ Radon ë„ë©”ì¸\n",
    "axes[1].imshow(radon_filtered, aspect='auto', cmap='seismic', \n",
    "               vmin=-vmax_radon, vmax=vmax_radon, \n",
    "               extent=[p_values[0]*1000, p_values[-1]*1000, processor.time[-1], processor.time[0]])\n",
    "axes[1].set_xlabel('Ray Parameter p (Ã—10â»Â³ s/m)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Intercept Time Ï„ (s)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title(f'Filtered Radon Domain (Threshold={threshold_percentile}%)', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# ì œê±°ëœ ì„±ë¶„ (Multiple)\n",
    "radon_removed = radon_original - radon_filtered\n",
    "axes[2].imshow(radon_removed, aspect='auto', cmap='seismic', \n",
    "               vmin=-vmax_radon, vmax=vmax_radon, \n",
    "               extent=[p_values[0]*1000, p_values[-1]*1000, processor.time[-1], processor.time[0]])\n",
    "axes[2].set_xlabel('Ray Parameter p (Ã—10â»Â³ s/m)', fontsize=12, fontweight='bold')\n",
    "axes[2].set_ylabel('Intercept Time Ï„ (s)', fontsize=12, fontweight='bold')\n",
    "axes[2].set_title('Removed Components (Multiples)', fontsize=14, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"ğŸ’¡ Ï„-p ë„ë©”ì¸ í•´ì„:\")\n",
    "print(\"   - ì›ë³¸: Multipleì´ ì €ì†ë„(ë‚®ì€ p ê°’) ì˜ì—­ì— ë¶„í¬\")\n",
    "print(\"   - í•„í„°ë§: ê³ ì†ë„ ì„±ë¶„ë§Œ ë‚¨ê¹€ (Primary reflection)\")\n",
    "print(\"   - ì œê±°: Multiple ì„±ë¶„ì„ Ï„-pì—ì„œ í™•ì¸\")\n",
    "print()\n",
    "print(\"ğŸ”§ íŒŒë¼ë¯¸í„° ì¡°ì • ë°©ë²•:\")\n",
    "print(\"   - threshold_percentile â†“ â†’ ë” ë§ì€ Multiple ì œê±° (ë‹¨, ì‹ í˜¸ ì†ì‹¤ ì£¼ì˜)\")\n",
    "print(\"   - threshold_percentile â†‘ â†’ ì‹ í˜¸ ë³´ì¡´ ìš°ì„  (Multiple ì”ì¡´ ê°€ëŠ¥)\")\n",
    "print(\"   - n_p â†‘ â†’ Ray parameter í•´ìƒë„ ì¦ê°€ (ê³„ì‚° ì‹œê°„ ì¦ê°€)\")\n",
    "print()\n",
    "\n",
    "# ì‹œê°í™”\n",
    "print(\"ğŸ“ˆ Radon Transform Demultiple ê²°ê³¼ ì‹œê°í™”...\")\n",
    "processor.plot_shot_gather(after_radon, offsets, \"ğŸ”„ After Radon Demultiple\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step11"
   },
   "source": [
    "## ğŸ“Š Step 11: ì „ì²´ ë¹„êµ (5ë‹¨ê³„)\n",
    "\n",
    "**ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ì „ì²´ ë¹„êµ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ“Š ì „ì²´ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ë¹„êµ...\")\n",
    "print()\n",
    "\n",
    "titles = [\n",
    "    'Input\\n(Noisy)',\n",
    "    'AAA + Lowcut\\n+ Curvelet',\n",
    "    'Water Bottom\\nDemultiple',\n",
    "    'Radon\\nDemultiple',\n",
    "    'Final\\n(All Processing)'\n",
    "]\n",
    "\n",
    "processor.plot_comparison_5(noisy_shot, final_shot, after_wb, after_radon, after_radon, \n",
    "                           offsets, titles)\n",
    "\n",
    "print(\"âœ… ë¹„êµ ì™„ë£Œ!\")\n",
    "print()\n",
    "print(\"ğŸ’¡ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸:\")\n",
    "print(\"   1ï¸âƒ£ Input: Multiple + ë…¸ì´ì¦ˆ\")\n",
    "print(\"   2ï¸âƒ£ AAA + Lowcut + Curvelet: ë…¸ì´ì¦ˆ ì œê±°\")\n",
    "print(\"   3ï¸âƒ£ WB Demult: í•´ì €ë©´ multiple ì œê±°\")\n",
    "print(\"   4ï¸âƒ£ Radon: ì¶”ê°€ multiple ì œê±°\")\n",
    "print(\"   5ï¸âƒ£ Final: ìµœì¢… ê²°ê³¼\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step12"
   },
   "source": [
    "## ğŸ’¾ Step 12: ë°ì´í„° ì €ì¥ ë° ë‹¤ìš´ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ’¾ ë°ì´í„° ì €ì¥ ì¤‘...\")\n",
    "print()\n",
    "\n",
    "# ì €ì¥\n",
    "np.savez('shot_input.npz', shot_gather=noisy_shot, offsets=offsets, time=processor.time, model=model)\n",
    "print(\"âœ… shot_input.npz\")\n",
    "\n",
    "np.savez('shot_after_aaa.npz', shot_gather=after_aaa, offsets=offsets, time=processor.time, model=model)\n",
    "print(\"âœ… shot_after_aaa.npz\")\n",
    "\n",
    "np.savez('shot_after_lowcut.npz', shot_gather=after_lowcut, offsets=offsets, time=processor.time, model=model)\n",
    "print(\"âœ… shot_after_lowcut.npz\")\n",
    "\n",
    "np.savez('shot_after_curvelet.npz', shot_gather=final_shot, offsets=offsets, time=processor.time, model=model)\n",
    "print(\"âœ… shot_after_curvelet.npz\")\n",
    "\n",
    "np.savez('shot_after_wb.npz', shot_gather=after_wb, offsets=offsets, time=processor.time, model=model)\n",
    "print(\"âœ… shot_after_wb.npz\")\n",
    "\n",
    "np.savez('shot_final.npz', shot_gather=after_radon, offsets=offsets, time=processor.time, model=model)\n",
    "print(\"âœ… shot_final.npz\")\n",
    "print()\n",
    "\n",
    "# Colab ë‹¤ìš´ë¡œë“œ\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print(\"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì‹œì‘...\")\n",
    "    files.download('shot_input.npz')\n",
    "    files.download('shot_final.npz')\n",
    "    print(\"âœ… ì£¼ìš” íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")\n",
    "except:\n",
    "    print(\"â„¹ï¸ ë¡œì»¬ í™˜ê²½ - íŒŒì¼ì´ í˜„ì¬ ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ‰ ì „ì²´ ê³ ê¸‰ ì²˜ë¦¬ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ!\")\n",
    "print(\"=\"*80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "final"
   },
   "source": [
    "## ğŸ‰ ì™„ë£Œ!\n",
    "\n",
    "---\n",
    "\n",
    "### â­ ê³ ê¸‰ ì²˜ë¦¬ ê¸°ë²• ìš”ì•½\n",
    "\n",
    "| ë‹¨ê³„ | ê¸°ë²• | ëª©ì  | íŠ¹ì§• |\n",
    "|------|------|------|------|\n",
    "| 7 | **Anomalous Amplitude Attenuation** | ì´ìƒ ì§„í­ ê°ì‡  | ë¡œì»¬ í†µê³„ ê¸°ë°˜ |\n",
    "| 8 | **Low-cut Filter** | ì €ì£¼íŒŒ ì œê±° | 1.5 Hz Butterworth |\n",
    "| 9 | **Curvelet Denoise** | ì¼ë°˜ ë…¸ì´ì¦ˆ ì œê±° | Wavelet ë³€í™˜ |\n",
    "| 10 | **Water Bottom Demultiple** | í•´ì €ë©´ multiple ì œê±° | ì˜ˆì¸¡ ë° ì ì‘ ê°ì‡  |\n",
    "| 11 | **Radon Transform** | ì¶”ê°€ multiple ì œê±° | t-x â†’ Ï„-p ë³€í™˜ |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Š ì²˜ë¦¬ ìˆœì„œì˜ ì¤‘ìš”ì„±\n",
    "\n",
    "**ë…¸ì´ì¦ˆ ì œê±° ë¨¼ì € â†’ Multiple ì œê±°**\n",
    "\n",
    "1. ğŸ”´ **AAA**: ì´ìƒ ì§„í­ ì œê±° (Burst noise)\n",
    "2. ğŸŸ  **Low-cut**: ì €ì£¼íŒŒ ë…¸ì´ì¦ˆ ì œê±° (Swell, Ship)\n",
    "3. ğŸŸ¡ **Curvelet**: ì¼ë°˜ ë…¸ì´ì¦ˆ ì œê±° (White noise)\n",
    "4. ğŸŸ¢ **WB Demult**: ê¹¨ë—í•œ ì‹ í˜¸ì—ì„œ Multiple ì œê±°\n",
    "5. ğŸ”µ **Radon**: ìµœì¢… Multiple ì œê±°\n",
    "\n",
    "**ë…¸ì´ì¦ˆê°€ ê¹¨ë—í•´ì•¼ Radon Ï„-p ë„ë©”ì¸ì´ ì •í™•í•©ë‹ˆë‹¤!**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Š ì„±ëŠ¥ ë¹„êµ\n",
    "\n",
    "**ì´ì „ ê¸°ë²• vs ê³ ê¸‰ ê¸°ë²•:**\n",
    "\n",
    "- ğŸ”´ **ì´ì „**: Multiple ë¨¼ì € ì œê±° â†’ ë…¸ì´ì¦ˆì— ì˜í•œ ê°„ì„­\n",
    "- ğŸŸ¢ **í˜„ì¬**: ë…¸ì´ì¦ˆ ë¨¼ì € ì œê±° â†’ Multiple ì •í™•íˆ ì œê±°\n",
    "\n",
    "**SNR ê°œì„ :**\n",
    "- ì¼ë°˜ì ìœ¼ë¡œ **20-30 dB** ê°œì„ \n",
    "- ë…¸ì´ì¦ˆì™€ Multiple ëª¨ë‘ íš¨ê³¼ì ìœ¼ë¡œ ì œê±°\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¾ ìƒì„±ëœ íŒŒì¼ (6ê°œ)\n",
    "\n",
    "1. **shot_input.npz** - ì…ë ¥ (Multiple + ë…¸ì´ì¦ˆ)\n",
    "2. **shot_after_aaa.npz** - AAA í›„\n",
    "3. **shot_after_lowcut.npz** - Low-cut í›„\n",
    "4. **shot_after_curvelet.npz** - Curvelet í›„\n",
    "5. **shot_after_wb.npz** - WB Demult í›„\n",
    "6. **shot_final.npz** - ìµœì¢… ê²°ê³¼ (Radon í›„)\n",
    "\n",
    "---\n",
    "\n",
    "**Made with â¤ï¸ for Advanced Marine Seismic Processing**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}