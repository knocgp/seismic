{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# ğŸ¯ Shot Gather ëŒ€í™”í˜• ì›Œí¬í”Œë¡œìš°\n",
    "# Interactive Shot Gather Workflow\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/knocgp/seismic/blob/main/Shot_Gather_Interactive.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ ë‹¨ê³„ë³„ ì‹¤í–‰ ì›Œí¬í”Œë¡œìš°\n",
    "\n",
    "**ê° ì…€ì„ í•˜ë‚˜ì”© ì‹¤í–‰í•˜ë©´ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”!**\n",
    "\n",
    "1. âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° í´ë˜ìŠ¤ ì •ì˜\n",
    "2. âœ… ëœë¤ í•©ì„± ëª¨ë¸ ìƒì„± â†’ ì¦‰ì‹œ ì‹œê°í™”\n",
    "3. âœ… Shot Gather ìƒì„± â†’ ì¦‰ì‹œ ì‹œê°í™”\n",
    "4. âœ… ë…¸ì´ì¦ˆ ì¶”ê°€ â†’ ì¦‰ì‹œ ì‹œê°í™”\n",
    "5. âœ… ë…¸ì´ì¦ˆ ì œê±° â†’ ì¦‰ì‹œ ì‹œê°í™”\n",
    "6. âœ… ì „ì²´ ë¹„êµ â†’ ì¦‰ì‹œ ì‹œê°í™”\n",
    "7. âœ… ë°ì´í„° ì €ì¥ ë° ë‹¤ìš´ë¡œë“œ\n",
    "8. âœ… ì¶”ê°€ ë¶„ì„ (íŠ¸ë ˆì´ìŠ¤, ìŠ¤í™íŠ¸ëŸ¼)\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸš€ ì‚¬ìš©ë²•: ê° ì…€ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰ (Shift + Enter)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1"
   },
   "source": [
    "## ğŸ“¦ Step 1: íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "!pip install -q numpy scipy matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.ndimage import median_filter\n",
    "from typing import Tuple, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ë° ì„í¬íŠ¸ ì™„ë£Œ!\")\n",
    "print(\"   - NumPy\")\n",
    "print(\"   - SciPy\")\n",
    "print(\"   - Matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1b"
   },
   "source": [
    "## ğŸ”§ Step 1-2: ShotGatherProcessor í´ë˜ìŠ¤ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "class_definition"
   },
   "outputs": [],
   "source": [
    "class ShotGatherProcessor:\n",
    "    \"\"\"Shot Gather ìƒì„± ë° ì²˜ë¦¬ í´ë˜ìŠ¤\"\"\"\n",
    "    \n",
    "    def __init__(self, dt: float = 0.002, nt: int = 1500):\n",
    "        self.dt = dt\n",
    "        self.nt = nt\n",
    "        self.time = np.arange(nt) * dt\n",
    "        \n",
    "    def create_random_model(self, nlayers: int = None) -> Dict:\n",
    "        \"\"\"ì™„ì „ ëœë¤ í•©ì„± ì§€ë°˜ ëª¨ë¸ ìƒì„±\"\"\"\n",
    "        if nlayers is None:\n",
    "            nlayers = np.random.randint(4, 9)\n",
    "        \n",
    "        model = {'velocity': [], 'density': [], 'thickness': [], 'depth': [], 'name': []}\n",
    "        \n",
    "        # í•´ìˆ˜ì¸µ\n",
    "        water_depth = np.random.uniform(300, 800)\n",
    "        model['velocity'].append(1500.0)\n",
    "        model['density'].append(1030.0)\n",
    "        model['thickness'].append(water_depth)\n",
    "        model['depth'].append(0.0)\n",
    "        model['name'].append('Water')\n",
    "        \n",
    "        # í•´ì €ë©´\n",
    "        seabed_vp = np.random.uniform(1600, 2000)\n",
    "        seabed_rho = np.random.uniform(1900, 2100)\n",
    "        seabed_thick = np.random.uniform(200, 400)\n",
    "        model['velocity'].append(seabed_vp)\n",
    "        model['density'].append(seabed_rho)\n",
    "        model['thickness'].append(seabed_thick)\n",
    "        model['depth'].append(water_depth)\n",
    "        model['name'].append('Seabed')\n",
    "        \n",
    "        # ì§€í•˜ ì§€ì¸µë“¤\n",
    "        current_depth = water_depth + seabed_thick\n",
    "        for i in range(nlayers - 2):\n",
    "            if i == 0:\n",
    "                base_vp = seabed_vp + np.random.uniform(200, 500)\n",
    "            else:\n",
    "                base_vp = model['velocity'][-1] + np.random.uniform(100, 600)\n",
    "            \n",
    "            vp = base_vp + np.random.normal(0, 100)\n",
    "            vp = np.clip(vp, 2000, 5000)\n",
    "            rho = 2000 + (vp - 2000) * 0.2 + np.random.normal(0, 50)\n",
    "            rho = np.clip(rho, 2000, 2800)\n",
    "            thickness = np.random.uniform(150, 600)\n",
    "            \n",
    "            model['velocity'].append(vp)\n",
    "            model['density'].append(rho)\n",
    "            model['thickness'].append(thickness)\n",
    "            model['depth'].append(current_depth)\n",
    "            model['name'].append(f'Layer {i+3}')\n",
    "            current_depth += thickness\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def calculate_reflection_coefficients(self, model: Dict):\n",
    "        velocities = np.array(model['velocity'])\n",
    "        densities = np.array(model['density'])\n",
    "        thicknesses = np.array(model['thickness'])\n",
    "        impedance = velocities * densities\n",
    "        \n",
    "        rc = np.zeros(len(velocities) - 1)\n",
    "        for i in range(len(velocities) - 1):\n",
    "            rc[i] = (impedance[i+1] - impedance[i]) / (impedance[i+1] + impedance[i])\n",
    "        \n",
    "        times = np.zeros(len(velocities) - 1)\n",
    "        cumulative_time = 0\n",
    "        for i in range(len(velocities) - 1):\n",
    "            travel_time = thicknesses[i] / velocities[i]\n",
    "            cumulative_time += travel_time\n",
    "            times[i] = cumulative_time * 2\n",
    "        \n",
    "        return rc, times\n",
    "    \n",
    "    def ricker_wavelet(self, freq: float = 25.0):\n",
    "        duration = 0.2\n",
    "        t = np.arange(-duration/2, duration/2, self.dt)\n",
    "        a = (np.pi * freq * t) ** 2\n",
    "        wavelet = (1 - 2*a) * np.exp(-a)\n",
    "        return wavelet / np.max(np.abs(wavelet))\n",
    "    \n",
    "    def generate_shot_gather(self, model: Dict, n_traces: int = 48, \n",
    "                           offset_min: float = 100, offset_max: float = 2400,\n",
    "                           freq: float = 25.0):\n",
    "        \"\"\"Shot Gather ìƒì„±\"\"\"\n",
    "        offsets = np.linspace(offset_min, offset_max, n_traces)\n",
    "        shot_gather = np.zeros((self.nt, n_traces))\n",
    "        wavelet = self.ricker_wavelet(freq)\n",
    "        rc, zero_offset_times = self.calculate_reflection_coefficients(model)\n",
    "        \n",
    "        for i_trace, offset in enumerate(offsets):\n",
    "            reflectivity = np.zeros(self.nt)\n",
    "            \n",
    "            for j, (rc_val, t0) in enumerate(zip(rc, zero_offset_times)):\n",
    "                depths = np.array(model['depth'])\n",
    "                velocities = np.array(model['velocity'])\n",
    "                \n",
    "                if j < len(depths) - 1:\n",
    "                    avg_depth = depths[j+1]\n",
    "                    avg_velocity = np.mean(velocities[:j+2])\n",
    "                    t_nmo = np.sqrt(t0**2 + (offset / avg_velocity)**2)\n",
    "                    angle = np.arctan(offset / avg_depth)\n",
    "                    avo_factor = 1 - 0.3 * np.sin(angle)**2\n",
    "                    \n",
    "                    idx = int(t_nmo / self.dt)\n",
    "                    if idx < self.nt:\n",
    "                        reflectivity[idx] += rc_val * avo_factor\n",
    "            \n",
    "            trace = signal.convolve(reflectivity, wavelet, mode='same')\n",
    "            spreading = 1 / (1 + offset / 1000)\n",
    "            shot_gather[:, i_trace] = trace * spreading\n",
    "        \n",
    "        return shot_gather, offsets\n",
    "    \n",
    "    def add_realistic_noise(self, shot_gather, noise_level: float = 0.10):\n",
    "        \"\"\"ì‹¤ì œì ì¸ ë…¸ì´ì¦ˆ ì¶”ê°€\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        signal_power = np.std(shot_gather)\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        \n",
    "        # ë°±ìƒ‰ ì¡ìŒ\n",
    "        white_noise = np.random.normal(0, noise_level * signal_power * 0.3, (nt, n_traces))\n",
    "        result += white_noise\n",
    "        \n",
    "        # Ground Roll\n",
    "        for i in range(5):\n",
    "            freq = np.random.uniform(5, 15)\n",
    "            phase_velocity = np.random.uniform(300, 800)\n",
    "            amplitude = noise_level * signal_power * np.random.uniform(0.5, 1.5)\n",
    "            \n",
    "            for j in range(n_traces):\n",
    "                offset = j * 50\n",
    "                time_shift = offset / phase_velocity\n",
    "                phase = 2 * np.pi * freq * (self.time - time_shift)\n",
    "                ground_roll = amplitude * np.sin(phase + np.random.uniform(0, 2*np.pi))\n",
    "                decay = np.exp(-self.time / 0.5)\n",
    "                result[:, j] += ground_roll * decay\n",
    "        \n",
    "        # ìŠ¤íŒŒì´í¬ ë…¸ì´ì¦ˆ\n",
    "        n_spikes = np.random.randint(1, 4)\n",
    "        for _ in range(n_spikes):\n",
    "            spike_trace = np.random.randint(0, n_traces)\n",
    "            spike_time = np.random.randint(0, nt)\n",
    "            spike_duration = np.random.randint(20, 100)\n",
    "            if spike_time + spike_duration < nt:\n",
    "                spike = noise_level * signal_power * 5.0 * np.random.randn(spike_duration)\n",
    "                result[spike_time:spike_time+spike_duration, spike_trace] += spike\n",
    "        \n",
    "        # ì €ì£¼íŒŒ íŠ¸ë Œë“œ\n",
    "        for j in range(n_traces):\n",
    "            trend_freq = np.random.uniform(0.5, 2.0)\n",
    "            trend = noise_level * signal_power * 0.4 * np.sin(2 * np.pi * trend_freq * self.time)\n",
    "            result[:, j] += trend\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def denoise_bandpass_filter(self, shot_gather, low_freq: float = 8.0, high_freq: float = 60.0):\n",
    "        \"\"\"ë°´ë“œíŒ¨ìŠ¤ í•„í„°\"\"\"\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        denoised = np.zeros_like(shot_gather)\n",
    "        nyquist = 1 / (2 * self.dt)\n",
    "        low = low_freq / nyquist\n",
    "        high = high_freq / nyquist\n",
    "        b, a = signal.butter(4, [low, high], btype='band')\n",
    "        \n",
    "        for i in range(n_traces):\n",
    "            denoised[:, i] = signal.filtfilt(b, a, shot_gather[:, i])\n",
    "        return denoised\n",
    "    \n",
    "    def denoise_fk_filter(self, shot_gather, velocity_cutoff: float = 1500):\n",
    "        \"\"\"F-K í•„í„°\"\"\"\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        fk_spectrum = np.fft.fft2(shot_gather)\n",
    "        fk_spectrum_shifted = np.fft.fftshift(fk_spectrum)\n",
    "        \n",
    "        freq = np.fft.fftshift(np.fft.fftfreq(nt, self.dt))\n",
    "        k = np.fft.fftshift(np.fft.fftfreq(n_traces, 50))\n",
    "        \n",
    "        fk_filter = np.ones_like(fk_spectrum_shifted)\n",
    "        for i, f in enumerate(freq):\n",
    "            for j, kval in enumerate(k):\n",
    "                if f != 0 and kval != 0:\n",
    "                    apparent_velocity = abs(f / kval)\n",
    "                    if apparent_velocity < velocity_cutoff:\n",
    "                        fk_filter[i, j] = 0.1\n",
    "        \n",
    "        fk_filtered = fk_spectrum_shifted * fk_filter\n",
    "        fk_filtered_unshifted = np.fft.ifftshift(fk_filtered)\n",
    "        return np.real(np.fft.ifft2(fk_filtered_unshifted))\n",
    "    \n",
    "    def denoise_median_filter(self, shot_gather, size: int = 5):\n",
    "        \"\"\"Median í•„í„°\"\"\"\n",
    "        return median_filter(shot_gather, size=(size, 1))\n",
    "    \n",
    "    def denoise_combined(self, shot_gather):\n",
    "        \"\"\"ì¡°í•© ë…¸ì´ì¦ˆ ì œê±°\"\"\"\n",
    "        result = self.denoise_bandpass_filter(shot_gather, 8.0, 60.0)\n",
    "        result = self.denoise_fk_filter(result, 1500)\n",
    "        result = self.denoise_median_filter(result, 5)\n",
    "        return result\n",
    "    \n",
    "    def plot_model(self, model: Dict):\n",
    "        \"\"\"ì§€ì¸µ ëª¨ë¸ ì‹œê°í™”\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 8))\n",
    "        \n",
    "        depths = model['depth']\n",
    "        velocities = model['velocity']\n",
    "        densities = model['density']\n",
    "        \n",
    "        for i in range(len(depths)):\n",
    "            depth_top = depths[i]\n",
    "            depth_bottom = depths[i] + model['thickness'][i]\n",
    "            \n",
    "            ax1.fill_between([velocities[i]-100, velocities[i]+100],\n",
    "                            depth_top, depth_bottom,\n",
    "                            alpha=0.4, label=model['name'][i] if i < 5 else None)\n",
    "            ax1.plot([velocities[i], velocities[i]], [depth_top, depth_bottom],\n",
    "                    'b-', linewidth=2.5)\n",
    "            \n",
    "            ax2.fill_between([densities[i]-50, densities[i]+50],\n",
    "                            depth_top, depth_bottom,\n",
    "                            alpha=0.4)\n",
    "            ax2.plot([densities[i], densities[i]], [depth_top, depth_bottom],\n",
    "                    'r-', linewidth=2.5)\n",
    "        \n",
    "        ax1.set_xlabel('Velocity (m/s)', fontsize=13, fontweight='bold')\n",
    "        ax1.set_ylabel('Depth (m)', fontsize=13, fontweight='bold')\n",
    "        ax1.set_title('Velocity Model', fontsize=15, fontweight='bold')\n",
    "        ax1.invert_yaxis()\n",
    "        ax1.grid(True, alpha=0.4)\n",
    "        ax1.legend(fontsize=10)\n",
    "        \n",
    "        ax2.set_xlabel('Density (kg/mÂ³)', fontsize=13, fontweight='bold')\n",
    "        ax2.set_ylabel('Depth (m)', fontsize=13, fontweight='bold')\n",
    "        ax2.set_title('Density Model', fontsize=15, fontweight='bold')\n",
    "        ax2.invert_yaxis()\n",
    "        ax2.grid(True, alpha=0.4)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_shot_gather(self, shot_gather, offsets, title: str = \"Shot Gather\", clip_percentile: float = 99):\n",
    "        \"\"\"Shot Gather ì‹œê°í™”\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(14, 10))\n",
    "        vmax = np.percentile(np.abs(shot_gather), clip_percentile)\n",
    "        \n",
    "        for i, offset in enumerate(offsets):\n",
    "            trace = shot_gather[:, i]\n",
    "            trace_scaled = trace / vmax * 30\n",
    "            ax.plot(offset + trace_scaled, self.time, 'k-', linewidth=0.3)\n",
    "            ax.fill_betweenx(self.time, offset, offset + trace_scaled,\n",
    "                            where=(trace_scaled > 0), color='black', alpha=0.6)\n",
    "        \n",
    "        ax.set_xlabel('Offset (m)', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Time (s)', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(title, fontsize=15, fontweight='bold')\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax.set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_comparison(self, original, noisy, denoised, offsets):\n",
    "        \"\"\"3ê°œ ë¹„êµ\"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(20, 10))\n",
    "        titles = ['Original (Clean)', 'With Noise', 'Denoised']\n",
    "        data_list = [original, noisy, denoised]\n",
    "        vmax = np.percentile(np.abs(original), 99)\n",
    "        \n",
    "        for ax, data, title in zip(axes, data_list, titles):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                trace = data[:, i]\n",
    "                trace_scaled = trace / vmax * 30\n",
    "                ax.plot(offset + trace_scaled, self.time, 'k-', linewidth=0.3)\n",
    "                ax.fill_betweenx(self.time, offset, offset + trace_scaled,\n",
    "                                where=(trace_scaled > 0), color='black', alpha=0.6)\n",
    "            \n",
    "            ax.set_xlabel('Offset (m)', fontsize=12, fontweight='bold')\n",
    "            ax.set_ylabel('Time (s)', fontsize=12, fontweight='bold')\n",
    "            ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "            ax.invert_yaxis()\n",
    "            ax.grid(True, alpha=0.3, linestyle='--')\n",
    "            ax.set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"âœ… ShotGatherProcessor í´ë˜ìŠ¤ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step2"
   },
   "source": [
    "## ğŸŒ Step 2: ëœë¤ í•©ì„± ëª¨ë¸ ìƒì„±\n",
    "\n",
    "**ì´ ì…€ì„ ì‹¤í–‰í•˜ë©´:**\n",
    "- ì™„ì „ ëœë¤ ì§€ì¸µ ëª¨ë¸ ìƒì„±\n",
    "- ì§€ì¸µ ì •ë³´ í…Œì´ë¸” ì¶œë ¥\n",
    "- ì†ë„ ë° ë°€ë„ í”„ë¡œíŒŒì¼ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_model"
   },
   "outputs": [],
   "source": [
    "# í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”\n",
    "processor = ShotGatherProcessor(dt=0.002, nt=1500)\n",
    "print(\"âœ… í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "print(f\"   - ìƒ˜í”Œë§ ê°„ê²©: {processor.dt*1000:.1f} ms\")\n",
    "print(f\"   - ì‹œê°„ ìƒ˜í”Œ: {processor.nt}ê°œ\")\n",
    "print(f\"   - ì´ ì‹œê°„: {processor.time[-1]:.2f} s\")\n",
    "print()\n",
    "\n",
    "# ëœë¤ ëª¨ë¸ ìƒì„±\n",
    "print(\"ğŸŒ ëœë¤ í•©ì„± ì§€ë°˜ ëª¨ë¸ ìƒì„± ì¤‘...\")\n",
    "model = processor.create_random_model(nlayers=6)\n",
    "print(\"âœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ!\")\n",
    "print()\n",
    "\n",
    "# ì§€ì¸µ ì •ë³´ ì¶œë ¥\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ“Š ìƒì„±ëœ ì§€ì¸µ ì •ë³´\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Layer':<15} {'Depth (m)':<12} {'Thickness (m)':<15} {'Velocity (m/s)':<15} {'Density (kg/mÂ³)'}\")\n",
    "print(\"-\"*80)\n",
    "for i in range(len(model['name'])):\n",
    "    print(f\"{model['name'][i]:<15} {model['depth'][i]:<12.1f} {model['thickness'][i]:<15.1f} \"\n",
    "          f\"{model['velocity'][i]:<15.1f} {model['density'][i]:<15.1f}\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# ëª¨ë¸ ì‹œê°í™”\n",
    "print(\"ğŸ“ˆ ì§€ì¸µ ëª¨ë¸ ì‹œê°í™”...\")\n",
    "processor.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step3"
   },
   "source": [
    "## ğŸ¯ Step 3: Shot Gather ìƒì„± (Clean)\n",
    "\n",
    "**ì´ ì…€ì„ ì‹¤í–‰í•˜ë©´:**\n",
    "- 48ê°œ íŠ¸ë ˆì´ìŠ¤ Shot Gather ìƒì„±\n",
    "- NMO ë° AVO íš¨ê³¼ ì ìš©\n",
    "- ì›ë³¸ Shot Gather ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate_shot"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ¯ Shot Gather ìƒì„± ì¤‘...\")\n",
    "print()\n",
    "\n",
    "# Shot Gather ìƒì„±\n",
    "n_traces = 48\n",
    "offset_min = 100\n",
    "offset_max = 2400\n",
    "freq = 25.0\n",
    "\n",
    "clean_shot, offsets = processor.generate_shot_gather(\n",
    "    model,\n",
    "    n_traces=n_traces,\n",
    "    offset_min=offset_min,\n",
    "    offset_max=offset_max,\n",
    "    freq=freq\n",
    ")\n",
    "\n",
    "print(\"âœ… Shot Gather ìƒì„± ì™„ë£Œ!\")\n",
    "print()\n",
    "print(\"ğŸ“Š Shot Gather ì •ë³´:\")\n",
    "print(f\"   - íŠ¸ë ˆì´ìŠ¤ ê°œìˆ˜: {n_traces}\")\n",
    "print(f\"   - ì˜¤í”„ì…‹ ë²”ìœ„: {offsets[0]:.0f} ~ {offsets[-1]:.0f} m\")\n",
    "print(f\"   - Wavelet ì£¼íŒŒìˆ˜: {freq} Hz\")\n",
    "print(f\"   - ë°ì´í„° í¬ê¸°: {clean_shot.shape}\")\n",
    "print(f\"   - RMS: {np.sqrt(np.mean(clean_shot**2)):.6f}\")\n",
    "print()\n",
    "\n",
    "# ì‹œê°í™”\n",
    "print(\"ğŸ“ˆ ì›ë³¸ Shot Gather ì‹œê°í™”...\")\n",
    "processor.plot_shot_gather(clean_shot, offsets, \"âœ¨ Original Shot Gather (Clean)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step4"
   },
   "source": [
    "## ğŸ“¢ Step 4: ë…¸ì´ì¦ˆ ì¶”ê°€\n",
    "\n",
    "**ì´ ì…€ì„ ì‹¤í–‰í•˜ë©´:**\n",
    "- 4ê°€ì§€ ë…¸ì´ì¦ˆ ì¶”ê°€ (ë°±ìƒ‰ì¡ìŒ, Ground Roll, ìŠ¤íŒŒì´í¬, ì €ì£¼íŒŒ)\n",
    "- ë…¸ì´ì¦ˆê°€ ì¶”ê°€ëœ Shot Gather ì‹œê°í™”\n",
    "- SNR ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "add_noise"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ“¢ ë…¸ì´ì¦ˆ ì¶”ê°€ ì¤‘...\")\n",
    "print()\n",
    "\n",
    "# ë…¸ì´ì¦ˆ ì¶”ê°€\n",
    "noise_level = 0.12\n",
    "noisy_shot = processor.add_realistic_noise(clean_shot, noise_level=noise_level)\n",
    "\n",
    "print(\"âœ… ë…¸ì´ì¦ˆ ì¶”ê°€ ì™„ë£Œ!\")\n",
    "print()\n",
    "print(\"ğŸ“Š ì¶”ê°€ëœ ë…¸ì´ì¦ˆ:\")\n",
    "print(\"   âœ… ë°±ìƒ‰ ì¡ìŒ (White Noise)\")\n",
    "print(\"   âœ… Ground Roll (5-15 Hz)\")\n",
    "print(\"   âœ… ìŠ¤íŒŒì´í¬ ë…¸ì´ì¦ˆ (Bad Traces)\")\n",
    "print(\"   âœ… ì €ì£¼íŒŒ íŠ¸ë Œë“œ\")\n",
    "print()\n",
    "\n",
    "# í†µê³„\n",
    "noise = noisy_shot - clean_shot\n",
    "snr_before = 20 * np.log10(np.std(clean_shot) / np.std(noise))\n",
    "\n",
    "print(\"ğŸ“ˆ í†µê³„:\")\n",
    "print(f\"   - Clean RMS: {np.sqrt(np.mean(clean_shot**2)):.6f}\")\n",
    "print(f\"   - Noisy RMS: {np.sqrt(np.mean(noisy_shot**2)):.6f}\")\n",
    "print(f\"   - Noise RMS: {np.sqrt(np.mean(noise**2)):.6f}\")\n",
    "print(f\"   - SNR: {snr_before:.2f} dB\")\n",
    "print()\n",
    "\n",
    "# ì‹œê°í™”\n",
    "print(\"ğŸ“ˆ ë…¸ì´ì¦ˆê°€ ì¶”ê°€ëœ Shot Gather ì‹œê°í™”...\")\n",
    "processor.plot_shot_gather(noisy_shot, offsets, \"ğŸ“¢ Shot Gather with Noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step5"
   },
   "source": [
    "## ğŸ”§ Step 5: ë…¸ì´ì¦ˆ ì œê±°\n",
    "\n",
    "**ì´ ì…€ì„ ì‹¤í–‰í•˜ë©´:**\n",
    "- ë°´ë“œíŒ¨ìŠ¤ í•„í„° (8-60 Hz)\n",
    "- F-K í•„í„° (Ground Roll ì œê±°)\n",
    "- Median í•„í„° (ìŠ¤íŒŒì´í¬ ì œê±°)\n",
    "- ë…¸ì´ì¦ˆ ì œê±°ëœ Shot Gather ì‹œê°í™”\n",
    "- SNR ê°œì„  ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "denoise"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ”§ ë…¸ì´ì¦ˆ ì œê±° ì¤‘...\")\n",
    "print()\n",
    "print(\"ì ìš© ê¸°ë²•:\")\n",
    "print(\"   1ï¸âƒ£ ë°´ë“œíŒ¨ìŠ¤ í•„í„° (8-60 Hz)\")\n",
    "print(\"   2ï¸âƒ£ F-K í•„í„° (Ground Roll ì œê±°, < 1500 m/s)\")\n",
    "print(\"   3ï¸âƒ£ Median í•„í„° (ìŠ¤íŒŒì´í¬ ì œê±°)\")\n",
    "print()\n",
    "\n",
    "# ë…¸ì´ì¦ˆ ì œê±°\n",
    "denoised_shot = processor.denoise_combined(noisy_shot)\n",
    "\n",
    "print(\"âœ… ë…¸ì´ì¦ˆ ì œê±° ì™„ë£Œ!\")\n",
    "print()\n",
    "\n",
    "# í†µê³„\n",
    "residual = denoised_shot - clean_shot\n",
    "snr_after = 20 * np.log10(np.std(clean_shot) / np.std(residual))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ“Š ë…¸ì´ì¦ˆ ì œê±° ê²°ê³¼\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Denoised RMS:    {np.sqrt(np.mean(denoised_shot**2)):.6f}\")\n",
    "print(f\"Residual RMS:    {np.sqrt(np.mean(residual**2)):.6f}\")\n",
    "print()\n",
    "print(f\"SNR (ë…¸ì´ì¦ˆ ì¶”ê°€ í›„):  {snr_before:.2f} dB\")\n",
    "print(f\"SNR (ë…¸ì´ì¦ˆ ì œê±° í›„):  {snr_after:.2f} dB\")\n",
    "print(f\"SNR ê°œì„ :             {snr_after - snr_before:.2f} dB  â¬†ï¸\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# ì‹œê°í™”\n",
    "print(\"ğŸ“ˆ ë…¸ì´ì¦ˆ ì œê±°ëœ Shot Gather ì‹œê°í™”...\")\n",
    "processor.plot_shot_gather(denoised_shot, offsets, \"ğŸ”§ Denoised Shot Gather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step6"
   },
   "source": [
    "## ğŸ“Š Step 6: ì „ì²´ ë¹„êµ\n",
    "\n",
    "**ì´ ì…€ì„ ì‹¤í–‰í•˜ë©´:**\n",
    "- ì›ë³¸, ë…¸ì´ì¦ˆ, ë…¸ì´ì¦ˆ ì œê±° 3ê°œ ë‚˜ë€íˆ ë¹„êµ\n",
    "- ì‹œê°ì ìœ¼ë¡œ ì°¨ì´ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ“Š ì „ì²´ ë¹„êµ ì‹œê°í™”...\")\n",
    "print()\n",
    "\n",
    "processor.plot_comparison(clean_shot, noisy_shot, denoised_shot, offsets)\n",
    "\n",
    "print(\"âœ… ë¹„êµ ì™„ë£Œ!\")\n",
    "print()\n",
    "print(\"ğŸ’¡ ì£¼ì˜ ê¹Šê²Œ ë³´ì„¸ìš”:\")\n",
    "print(\"   - Original: ê¹¨ë—í•œ ë°˜ì‚¬ ì‹ í˜¸\")\n",
    "print(\"   - With Noise: Ground Rollê³¼ ìŠ¤íŒŒì´í¬ê°€ ë³´ì…ë‹ˆë‹¤\")\n",
    "print(\"   - Denoised: ë…¸ì´ì¦ˆê°€ ì œê±°ë˜ê³  ì›ë³¸ì— ê°€ê¹Œì›Œì¡ŒìŠµë‹ˆë‹¤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step7"
   },
   "source": [
    "## ğŸ’¾ Step 7: ë°ì´í„° ì €ì¥ ë° ë‹¤ìš´ë¡œë“œ\n",
    "\n",
    "**ì´ ì…€ì„ ì‹¤í–‰í•˜ë©´:**\n",
    "- 3ê°œ NPZ íŒŒì¼ ì €ì¥\n",
    "- ìë™ ë‹¤ìš´ë¡œë“œ (Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_download"
   },
   "outputs": [],
   "source": [
    "print(\"ğŸ’¾ ë°ì´í„° ì €ì¥ ì¤‘...\")\n",
    "print()\n",
    "\n",
    "# ë°ì´í„° ì €ì¥\n",
    "np.savez('shot_gather_clean.npz',\n",
    "         shot_gather=clean_shot,\n",
    "         offsets=offsets,\n",
    "         time=processor.time,\n",
    "         model=model)\n",
    "print(\"âœ… shot_gather_clean.npz ì €ì¥ ì™„ë£Œ\")\n",
    "\n",
    "np.savez('shot_gather_noisy.npz',\n",
    "         shot_gather=noisy_shot,\n",
    "         offsets=offsets,\n",
    "         time=processor.time,\n",
    "         model=model)\n",
    "print(\"âœ… shot_gather_noisy.npz ì €ì¥ ì™„ë£Œ\")\n",
    "\n",
    "np.savez('shot_gather_denoised.npz',\n",
    "         shot_gather=denoised_shot,\n",
    "         offsets=offsets,\n",
    "         time=processor.time,\n",
    "         model=model)\n",
    "print(\"âœ… shot_gather_denoised.npz ì €ì¥ ì™„ë£Œ\")\n",
    "print()\n",
    "\n",
    "# Colabì—ì„œ ë‹¤ìš´ë¡œë“œ\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print(\"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì‹œì‘...\")\n",
    "    print()\n",
    "    files.download('shot_gather_clean.npz')\n",
    "    files.download('shot_gather_noisy.npz')\n",
    "    files.download('shot_gather_denoised.npz')\n",
    "    print(\"âœ… ëª¨ë“  íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")\n",
    "except:\n",
    "    print(\"â„¹ï¸ ë¡œì»¬ í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘ - íŒŒì¼ì´ í˜„ì¬ ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ‰ ì „ì²´ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step8"
   },
   "source": [
    "## ğŸ”¬ Step 8: ì¶”ê°€ ë¶„ì„ - ë‹¨ì¼ íŠ¸ë ˆì´ìŠ¤ ë¹„êµ\n",
    "\n",
    "**ì„ íƒì‚¬í•­: íŠ¹ì • íŠ¸ë ˆì´ìŠ¤ë¥¼ ìì„¸íˆ ë¶„ì„**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trace_analysis"
   },
   "outputs": [],
   "source": [
    "# ì¤‘ê°„ ì˜¤í”„ì…‹ íŠ¸ë ˆì´ìŠ¤ ì„ íƒ\n",
    "trace_idx = len(offsets) // 2\n",
    "\n",
    "print(f\"ğŸ”¬ íŠ¸ë ˆì´ìŠ¤ {trace_idx} ë¶„ì„ (ì˜¤í”„ì…‹ = {offsets[trace_idx]:.0f} m)\")\n",
    "print()\n",
    "\n",
    "# í”Œë¡¯\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 8))\n",
    "\n",
    "axes[0].plot(clean_shot[:, trace_idx], processor.time, 'b-', linewidth=1.5)\n",
    "axes[0].set_xlabel('Amplitude', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Time (s)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title(f'Clean Trace\\n(Offset={offsets[trace_idx]:.0f}m)', fontsize=13, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(noisy_shot[:, trace_idx], processor.time, 'r-', linewidth=1.5)\n",
    "axes[1].set_xlabel('Amplitude', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Time (s)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title(f'Noisy Trace\\n(Offset={offsets[trace_idx]:.0f}m)', fontsize=13, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(denoised_shot[:, trace_idx], processor.time, 'g-', linewidth=1.5)\n",
    "axes[2].set_xlabel('Amplitude', fontsize=12, fontweight='bold')\n",
    "axes[2].set_ylabel('Time (s)', fontsize=12, fontweight='bold')\n",
    "axes[2].set_title(f'Denoised Trace\\n(Offset={offsets[trace_idx]:.0f}m)', fontsize=13, fontweight='bold')\n",
    "axes[2].invert_yaxis()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… íŠ¸ë ˆì´ìŠ¤ {trace_idx} ë¹„êµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step9"
   },
   "source": [
    "## ğŸ“Š Step 9: ì£¼íŒŒìˆ˜ ìŠ¤í™íŠ¸ëŸ¼ ë¶„ì„\n",
    "\n",
    "**ì„ íƒì‚¬í•­: ì£¼íŒŒìˆ˜ ë„ë©”ì¸ì—ì„œ ë¹„êµ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "spectrum"
   },
   "outputs": [],
   "source": [
    "# ì¤‘ê°„ íŠ¸ë ˆì´ìŠ¤ FFT\n",
    "trace_idx = len(offsets) // 2\n",
    "dt = processor.time[1] - processor.time[0]\n",
    "\n",
    "print(f\"ğŸ“Š ì£¼íŒŒìˆ˜ ìŠ¤í™íŠ¸ëŸ¼ ë¶„ì„ (íŠ¸ë ˆì´ìŠ¤ {trace_idx}, ì˜¤í”„ì…‹ {offsets[trace_idx]:.0f}m)\")\n",
    "print()\n",
    "\n",
    "# FFT ê³„ì‚°\n",
    "freq = np.fft.rfftfreq(len(processor.time), dt)\n",
    "clean_fft = np.abs(np.fft.rfft(clean_shot[:, trace_idx]))\n",
    "noisy_fft = np.abs(np.fft.rfft(noisy_shot[:, trace_idx]))\n",
    "denoised_fft = np.abs(np.fft.rfft(denoised_shot[:, trace_idx]))\n",
    "\n",
    "# í”Œë¡¯\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(freq, clean_fft, 'b-', linewidth=2, label='Clean', alpha=0.8)\n",
    "ax.plot(freq, noisy_fft, 'r-', linewidth=2, label='Noisy', alpha=0.6)\n",
    "ax.plot(freq, denoised_fft, 'g-', linewidth=2, label='Denoised', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Frequency (Hz)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Amplitude Spectrum', fontsize=13, fontweight='bold')\n",
    "ax.set_title(f'Frequency Spectrum Comparison (Offset={offsets[trace_idx]:.0f}m)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xlim([0, 100])\n",
    "ax.legend(fontsize=12, loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"âœ… ì£¼íŒŒìˆ˜ ìŠ¤í™íŠ¸ëŸ¼ ë¶„ì„ ì™„ë£Œ!\")\n",
    "print()\n",
    "print(\"ğŸ’¡ ê´€ì°° í¬ì¸íŠ¸:\")\n",
    "print(\"   - Noisy (ë¹¨ê°•): ì €ì£¼íŒŒ ë° ê³ ì£¼íŒŒì— ë…¸ì´ì¦ˆê°€ ë§ìŠµë‹ˆë‹¤\")\n",
    "print(\"   - Denoised (ì´ˆë¡): í•„í„°ë§ìœ¼ë¡œ ë…¸ì´ì¦ˆê°€ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤\")\n",
    "print(\"   - Clean (íŒŒë‘): ì›ë³¸ ì‹ í˜¸ì˜ ì£¼íŒŒìˆ˜ íŠ¹ì„±\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "final"
   },
   "source": [
    "## ğŸ‰ ì™„ë£Œ!\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“ ìš”ì•½\n",
    "\n",
    "ëª¨ë“  ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ì…¨ë‹¤ë©´:\n",
    "\n",
    "âœ… ëœë¤ ì§€ì¸µ ëª¨ë¸ ìƒì„± ì™„ë£Œ  \n",
    "âœ… Shot Gather ìƒì„± ì™„ë£Œ  \n",
    "âœ… ë…¸ì´ì¦ˆ ì¶”ê°€ ì™„ë£Œ  \n",
    "âœ… ë…¸ì´ì¦ˆ ì œê±° ì™„ë£Œ  \n",
    "âœ… 3ê°œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¾ ìƒì„±ëœ íŒŒì¼\n",
    "\n",
    "1. **shot_gather_clean.npz** - ì›ë³¸ Shot Gather\n",
    "2. **shot_gather_noisy.npz** - ë…¸ì´ì¦ˆ ì¶”ê°€ëœ Shot Gather\n",
    "3. **shot_gather_denoised.npz** - ë…¸ì´ì¦ˆ ì œê±°ëœ Shot Gather\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”„ ë‹¤ì‹œ ì‹¤í–‰í•˜ê¸°\n",
    "\n",
    "ìƒˆë¡œìš´ ëœë¤ ëª¨ë¸ë¡œ ë‹¤ì‹œ ì‹¤í–‰í•˜ë ¤ë©´:\n",
    "- **Step 2**ë¶€í„° ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”!\n",
    "- ë§¤ë²ˆ ë‹¤ë¥¸ ì§€ì¸µ ëª¨ë¸ê³¼ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“š ê´€ë ¨ ë§í¬\n",
    "\n",
    "- **GitHub**: https://github.com/knocgp/seismic\n",
    "- **ìƒì„¸ ê°€ì´ë“œ**: [SHOT_GATHER_GUIDE.md](https://github.com/knocgp/seismic/blob/main/SHOT_GATHER_GUIDE.md)\n",
    "- **Colab ê°€ì´ë“œ**: [COLAB_GUIDE_KR.md](https://github.com/knocgp/seismic/blob/main/COLAB_GUIDE_KR.md)\n",
    "\n",
    "---\n",
    "\n",
    "**Made with â¤ï¸ for Seismic Data Processing**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
