{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# üéØ Shot Gather ÎåÄÌôîÌòï ÏõåÌÅ¨ÌîåÎ°úÏö∞\n",
    "# Interactive Shot Gather Workflow\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/knocgp/seismic/blob/main/Shot_Gather_Interactive.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Îã®Í≥ÑÎ≥Ñ Ïã§Ìñâ ÏõåÌÅ¨ÌîåÎ°úÏö∞\n",
    "\n",
    "**Í∞Å ÏÖÄÏùÑ ÌïòÎÇòÏî© Ïã§ÌñâÌïòÎ©¥ÏÑú Í≤∞Í≥ºÎ•º ÌôïÏù∏ÌïòÏÑ∏Ïöî!**\n",
    "\n",
    "1. ‚úÖ Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò Î∞è ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
    "2. ‚úÖ ÎûúÎç§ Ìï©ÏÑ± Î™®Îç∏ ÏÉùÏÑ± ‚Üí Ï¶âÏãú ÏãúÍ∞ÅÌôî\n",
    "3. ‚úÖ Shot Gather ÏÉùÏÑ± ‚Üí Ï¶âÏãú ÏãúÍ∞ÅÌôî\n",
    "4. ‚úÖ ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä ‚Üí Ï¶âÏãú ÏãúÍ∞ÅÌôî\n",
    "5. ‚úÖ ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ ‚Üí Ï¶âÏãú ÏãúÍ∞ÅÌôî\n",
    "6. ‚úÖ Ï†ÑÏ≤¥ ÎπÑÍµê ‚Üí Ï¶âÏãú ÏãúÍ∞ÅÌôî\n",
    "7. ‚úÖ Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• Î∞è Îã§Ïö¥Î°úÎìú\n",
    "8. ‚úÖ Ï∂îÍ∞Ä Î∂ÑÏÑù (Ìä∏Î†àÏù¥Ïä§, Ïä§ÌéôÌä∏Îüº)\n",
    "\n",
    "---\n",
    "\n",
    "**üöÄ ÏÇ¨Ïö©Î≤ï: Í∞Å ÏÖÄÏùÑ ÏàúÏÑúÎåÄÎ°ú Ïã§Ìñâ (Shift + Enter)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1"
   },
   "source": [
    "## üì¶ Step 1: Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò Î∞è ÏûÑÌè¨Ìä∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "!pip install -q numpy scipy matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.ndimage import median_filter\n",
    "from typing import Tuple, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò Î∞è ÏûÑÌè¨Ìä∏ ÏôÑÎ£å!\")\n",
    "print(\"   - NumPy\")\n",
    "print(\"   - SciPy\")\n",
    "print(\"   - Matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1b"
   },
   "source": [
    "## üîß Step 1-2: ShotGatherProcessor ÌÅ¥ÎûòÏä§ Ï†ïÏùò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "class_definition"
   },
   "outputs": [],
   "source": [
    "class ShotGatherProcessor:\n",
    "    \"\"\"Shot Gather ÏÉùÏÑ± Î∞è Ï≤òÎ¶¨ ÌÅ¥ÎûòÏä§\"\"\"\n",
    "    \n",
    "    def __init__(self, dt: float = 0.002, nt: int = 1500):\n",
    "        self.dt = dt\n",
    "        self.nt = nt\n",
    "        self.time = np.arange(nt) * dt\n",
    "        \n",
    "    def create_random_model(self, nlayers: int = None) -> Dict:\n",
    "        \"\"\"ÏôÑÏ†Ñ ÎûúÎç§ Ìï©ÏÑ± ÏßÄÎ∞ò Î™®Îç∏ ÏÉùÏÑ±\"\"\"\n",
    "        if nlayers is None:\n",
    "            nlayers = np.random.randint(4, 9)\n",
    "        \n",
    "        model = {'velocity': [], 'density': [], 'thickness': [], 'depth': [], 'name': []}\n",
    "        \n",
    "        # Ìï¥ÏàòÏ∏µ\n",
    "        water_depth = np.random.uniform(300, 800)\n",
    "        model['velocity'].append(1500.0)\n",
    "        model['density'].append(1030.0)\n",
    "        model['thickness'].append(water_depth)\n",
    "        model['depth'].append(0.0)\n",
    "        model['name'].append('Water')\n",
    "        \n",
    "        # Ìï¥Ï†ÄÎ©¥\n",
    "        seabed_vp = np.random.uniform(1600, 2000)\n",
    "        seabed_rho = np.random.uniform(1900, 2100)\n",
    "        seabed_thick = np.random.uniform(200, 400)\n",
    "        model['velocity'].append(seabed_vp)\n",
    "        model['density'].append(seabed_rho)\n",
    "        model['thickness'].append(seabed_thick)\n",
    "        model['depth'].append(water_depth)\n",
    "        model['name'].append('Seabed')\n",
    "        \n",
    "        # ÏßÄÌïò ÏßÄÏ∏µÎì§\n",
    "        current_depth = water_depth + seabed_thick\n",
    "        for i in range(nlayers - 2):\n",
    "            if i == 0:\n",
    "                base_vp = seabed_vp + np.random.uniform(200, 500)\n",
    "            else:\n",
    "                base_vp = model['velocity'][-1] + np.random.uniform(100, 600)\n",
    "            \n",
    "            vp = base_vp + np.random.normal(0, 100)\n",
    "            vp = np.clip(vp, 2000, 5000)\n",
    "            rho = 2000 + (vp - 2000) * 0.2 + np.random.normal(0, 50)\n",
    "            rho = np.clip(rho, 2000, 2800)\n",
    "            thickness = np.random.uniform(150, 600)\n",
    "            \n",
    "            model['velocity'].append(vp)\n",
    "            model['density'].append(rho)\n",
    "            model['thickness'].append(thickness)\n",
    "            model['depth'].append(current_depth)\n",
    "            model['name'].append(f'Layer {i+3}')\n",
    "            current_depth += thickness\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def calculate_reflection_coefficients(self, model: Dict):\n",
    "        velocities = np.array(model['velocity'])\n",
    "        densities = np.array(model['density'])\n",
    "        thicknesses = np.array(model['thickness'])\n",
    "        impedance = velocities * densities\n",
    "        \n",
    "        rc = np.zeros(len(velocities) - 1)\n",
    "        for i in range(len(velocities) - 1):\n",
    "            rc[i] = (impedance[i+1] - impedance[i]) / (impedance[i+1] + impedance[i])\n",
    "        \n",
    "        times = np.zeros(len(velocities) - 1)\n",
    "        cumulative_time = 0\n",
    "        for i in range(len(velocities) - 1):\n",
    "            travel_time = thicknesses[i] / velocities[i]\n",
    "            cumulative_time += travel_time\n",
    "            times[i] = cumulative_time * 2\n",
    "        \n",
    "        return rc, times\n",
    "    \n",
    "    def ricker_wavelet(self, freq: float = 25.0):\n",
    "        duration = 0.2\n",
    "        t = np.arange(-duration/2, duration/2, self.dt)\n",
    "        a = (np.pi * freq * t) ** 2\n",
    "        wavelet = (1 - 2*a) * np.exp(-a)\n",
    "        return wavelet / np.max(np.abs(wavelet))\n",
    "    \n",
    "    def generate_shot_gather(self, model: Dict, n_traces: int = 48, \n",
    "                           offset_min: float = 100, offset_max: float = 2400,\n",
    "                           freq: float = 25.0):\n",
    "        \"\"\"Shot Gather ÏÉùÏÑ±\"\"\"\n",
    "        offsets = np.linspace(offset_min, offset_max, n_traces)\n",
    "        shot_gather = np.zeros((self.nt, n_traces))\n",
    "        wavelet = self.ricker_wavelet(freq)\n",
    "        rc, zero_offset_times = self.calculate_reflection_coefficients(model)\n",
    "        \n",
    "        for i_trace, offset in enumerate(offsets):\n",
    "            reflectivity = np.zeros(self.nt)\n",
    "            \n",
    "            for j, (rc_val, t0) in enumerate(zip(rc, zero_offset_times)):\n",
    "                depths = np.array(model['depth'])\n",
    "                velocities = np.array(model['velocity'])\n",
    "                \n",
    "                if j < len(depths) - 1:\n",
    "                    avg_depth = depths[j+1]\n",
    "                    avg_velocity = np.mean(velocities[:j+2])\n",
    "                    t_nmo = np.sqrt(t0**2 + (offset / avg_velocity)**2)\n",
    "                    angle = np.arctan(offset / avg_depth)\n",
    "                    avo_factor = 1 - 0.3 * np.sin(angle)**2\n",
    "                    \n",
    "                    idx = int(t_nmo / self.dt)\n",
    "                    if idx < self.nt:\n",
    "                        reflectivity[idx] += rc_val * avo_factor\n",
    "            \n",
    "            trace = signal.convolve(reflectivity, wavelet, mode='same')\n",
    "            spreading = 1 / (1 + offset / 1000)\n",
    "            shot_gather[:, i_trace] = trace * spreading\n",
    "        \n",
    "        return shot_gather, offsets\n",
    "    \n",
    "    def add_realistic_noise(self, shot_gather, noise_level: float = 0.10):\n",
    "        \"\"\"Ïã§Ï†úÏ†ÅÏù∏ ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        signal_power = np.std(shot_gather)\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        \n",
    "        # Î∞±ÏÉâ Ïû°Ïùå\n",
    "        white_noise = np.random.normal(0, noise_level * signal_power * 0.3, (nt, n_traces))\n",
    "        result += white_noise\n",
    "        \n",
    "        # Ground Roll\n",
    "        for i in range(5):\n",
    "            freq = np.random.uniform(5, 15)\n",
    "            phase_velocity = np.random.uniform(300, 800)\n",
    "            amplitude = noise_level * signal_power * np.random.uniform(0.5, 1.5)\n",
    "            \n",
    "            for j in range(n_traces):\n",
    "                offset = j * 50\n",
    "                time_shift = offset / phase_velocity\n",
    "                phase = 2 * np.pi * freq * (self.time - time_shift)\n",
    "                ground_roll = amplitude * np.sin(phase + np.random.uniform(0, 2*np.pi))\n",
    "                decay = np.exp(-self.time / 0.5)\n",
    "                result[:, j] += ground_roll * decay\n",
    "        \n",
    "        # Ïä§ÌååÏù¥ÌÅ¨ ÎÖ∏Ïù¥Ï¶à\n",
    "        n_spikes = np.random.randint(1, 4)\n",
    "        for _ in range(n_spikes):\n",
    "            spike_trace = np.random.randint(0, n_traces)\n",
    "            spike_time = np.random.randint(0, nt)\n",
    "            spike_duration = np.random.randint(20, 100)\n",
    "            if spike_time + spike_duration < nt:\n",
    "                spike = noise_level * signal_power * 5.0 * np.random.randn(spike_duration)\n",
    "                result[spike_time:spike_time+spike_duration, spike_trace] += spike\n",
    "        \n",
    "        # Ï†ÄÏ£ºÌåå Ìä∏Î†åÎìú\n",
    "        for j in range(n_traces):\n",
    "            trend_freq = np.random.uniform(0.5, 2.0)\n",
    "            trend = noise_level * signal_power * 0.4 * np.sin(2 * np.pi * trend_freq * self.time)\n",
    "            result[:, j] += trend\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def denoise_bandpass_filter(self, shot_gather, low_freq: float = 8.0, high_freq: float = 60.0):\n",
    "        \"\"\"Î∞¥ÎìúÌå®Ïä§ ÌïÑÌÑ∞\"\"\"\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        denoised = np.zeros_like(shot_gather)\n",
    "        nyquist = 1 / (2 * self.dt)\n",
    "        low = low_freq / nyquist\n",
    "        high = high_freq / nyquist\n",
    "        b, a = signal.butter(4, [low, high], btype='band')\n",
    "        \n",
    "        for i in range(n_traces):\n",
    "            denoised[:, i] = signal.filtfilt(b, a, shot_gather[:, i])\n",
    "        return denoised\n",
    "    \n",
    "    def denoise_fk_filter(self, shot_gather, velocity_cutoff: float = 1500):\n",
    "        \"\"\"F-K ÌïÑÌÑ∞\"\"\"\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        fk_spectrum = np.fft.fft2(shot_gather)\n",
    "        fk_spectrum_shifted = np.fft.fftshift(fk_spectrum)\n",
    "        \n",
    "        freq = np.fft.fftshift(np.fft.fftfreq(nt, self.dt))\n",
    "        k = np.fft.fftshift(np.fft.fftfreq(n_traces, 50))\n",
    "        \n",
    "        fk_filter = np.ones_like(fk_spectrum_shifted)\n",
    "        for i, f in enumerate(freq):\n",
    "            for j, kval in enumerate(k):\n",
    "                if f != 0 and kval != 0:\n",
    "                    apparent_velocity = abs(f / kval)\n",
    "                    if apparent_velocity < velocity_cutoff:\n",
    "                        fk_filter[i, j] = 0.1\n",
    "        \n",
    "        fk_filtered = fk_spectrum_shifted * fk_filter\n",
    "        fk_filtered_unshifted = np.fft.ifftshift(fk_filtered)\n",
    "        return np.real(np.fft.ifft2(fk_filtered_unshifted))\n",
    "    \n",
    "    def denoise_median_filter(self, shot_gather, size: int = 5):\n",
    "        \"\"\"Median ÌïÑÌÑ∞\"\"\"\n",
    "        return median_filter(shot_gather, size=(size, 1))\n",
    "    \n",
    "    def denoise_combined(self, shot_gather):\n",
    "        \"\"\"Ï°∞Ìï© ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞\"\"\"\n",
    "        result = self.denoise_bandpass_filter(shot_gather, 8.0, 60.0)\n",
    "        result = self.denoise_fk_filter(result, 1500)\n",
    "        result = self.denoise_median_filter(result, 5)\n",
    "        return result\n",
    "    \n",
    "    def plot_model(self, model: Dict):\n",
    "        \"\"\"ÏßÄÏ∏µ Î™®Îç∏ ÏãúÍ∞ÅÌôî\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 8))\n",
    "        \n",
    "        depths = model['depth']\n",
    "        velocities = model['velocity']\n",
    "        densities = model['density']\n",
    "        \n",
    "        for i in range(len(depths)):\n",
    "            depth_top = depths[i]\n",
    "            depth_bottom = depths[i] + model['thickness'][i]\n",
    "            \n",
    "            ax1.fill_between([velocities[i]-100, velocities[i]+100],\n",
    "                            depth_top, depth_bottom,\n",
    "                            alpha=0.4, label=model['name'][i] if i < 5 else None)\n",
    "            ax1.plot([velocities[i], velocities[i]], [depth_top, depth_bottom],\n",
    "                    'b-', linewidth=2.5)\n",
    "            \n",
    "            ax2.fill_between([densities[i]-50, densities[i]+50],\n",
    "                            depth_top, depth_bottom,\n",
    "                            alpha=0.4)\n",
    "            ax2.plot([densities[i], densities[i]], [depth_top, depth_bottom],\n",
    "                    'r-', linewidth=2.5)\n",
    "        \n",
    "        ax1.set_xlabel('Velocity (m/s)', fontsize=13, fontweight='bold')\n",
    "        ax1.set_ylabel('Depth (m)', fontsize=13, fontweight='bold')\n",
    "        ax1.set_title('Velocity Model', fontsize=15, fontweight='bold')\n",
    "        ax1.invert_yaxis()\n",
    "        ax1.grid(True, alpha=0.4)\n",
    "        ax1.legend(fontsize=10)\n",
    "        \n",
    "        ax2.set_xlabel('Density (kg/m¬≥)', fontsize=13, fontweight='bold')\n",
    "        ax2.set_ylabel('Depth (m)', fontsize=13, fontweight='bold')\n",
    "        ax2.set_title('Density Model', fontsize=15, fontweight='bold')\n",
    "        ax2.invert_yaxis()\n",
    "        ax2.grid(True, alpha=0.4)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_shot_gather(self, shot_gather, offsets, title: str = \"Shot Gather\", clip_percentile: float = 99):\n",
    "        \"\"\"Shot Gather ÏãúÍ∞ÅÌôî\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(14, 10))\n",
    "        vmax = np.percentile(np.abs(shot_gather), clip_percentile)\n",
    "        \n",
    "        for i, offset in enumerate(offsets):\n",
    "            trace = shot_gather[:, i]\n",
    "            trace_scaled = trace / vmax * 30\n",
    "            ax.plot(offset + trace_scaled, self.time, 'k-', linewidth=0.3)\n",
    "            ax.fill_betweenx(self.time, offset, offset + trace_scaled,\n",
    "                            where=(trace_scaled > 0), color='black', alpha=0.6)\n",
    "        \n",
    "        ax.set_xlabel('Offset (m)', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Time (s)', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(title, fontsize=15, fontweight='bold')\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax.set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_comparison(self, original, noisy, denoised, offsets):\n",
    "        \"\"\"3Í∞ú ÎπÑÍµê\"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(20, 10))\n",
    "        titles = ['Original (Clean)', 'With Noise', 'Denoised']\n",
    "        data_list = [original, noisy, denoised]\n",
    "        vmax = np.percentile(np.abs(original), 99)\n",
    "        \n",
    "        for ax, data, title in zip(axes, data_list, titles):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                trace = data[:, i]\n",
    "                trace_scaled = trace / vmax * 30\n",
    "                ax.plot(offset + trace_scaled, self.time, 'k-', linewidth=0.3)\n",
    "                ax.fill_betweenx(self.time, offset, offset + trace_scaled,\n",
    "                                where=(trace_scaled > 0), color='black', alpha=0.6)\n",
    "            \n",
    "            ax.set_xlabel('Offset (m)', fontsize=12, fontweight='bold')\n",
    "            ax.set_ylabel('Time (s)', fontsize=12, fontweight='bold')\n",
    "            ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "            ax.invert_yaxis()\n",
    "            ax.grid(True, alpha=0.3, linestyle='--')\n",
    "            ax.set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"‚úÖ ShotGatherProcessor ÌÅ¥ÎûòÏä§ Ï†ïÏùò ÏôÑÎ£å!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step2"
   },
   "source": [
    "## üåç Step 2: ÎûúÎç§ Ìï©ÏÑ± Î™®Îç∏ ÏÉùÏÑ±\n",
    "\n",
    "**Ïù¥ ÏÖÄÏùÑ Ïã§ÌñâÌïòÎ©¥:**\n",
    "- ÏôÑÏ†Ñ ÎûúÎç§ ÏßÄÏ∏µ Î™®Îç∏ ÏÉùÏÑ±\n",
    "- ÏßÄÏ∏µ Ï†ïÎ≥¥ ÌÖåÏù¥Î∏î Ï∂úÎ†•\n",
    "- ÏÜçÎèÑ Î∞è Î∞ÄÎèÑ ÌîÑÎ°úÌååÏùº ÏãúÍ∞ÅÌôî"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_model"
   },
   "outputs": [],
   "source": [
    "# ÌîÑÎ°úÏÑ∏ÏÑú Ï¥àÍ∏∞Ìôî\n",
    "processor = ShotGatherProcessor(dt=0.002, nt=1500)\n",
    "print(\"‚úÖ ÌîÑÎ°úÏÑ∏ÏÑú Ï¥àÍ∏∞Ìôî ÏôÑÎ£å\")\n",
    "print(f\"   - ÏÉòÌîåÎßÅ Í∞ÑÍ≤©: {processor.dt*1000:.1f} ms\")\n",
    "print(f\"   - ÏãúÍ∞Ñ ÏÉòÌîå: {processor.nt}Í∞ú\")\n",
    "print(f\"   - Ï¥ù ÏãúÍ∞Ñ: {processor.time[-1]:.2f} s\")\n",
    "print()\n",
    "\n",
    "# ÎûúÎç§ Î™®Îç∏ ÏÉùÏÑ±\n",
    "print(\"üåç ÎûúÎç§ Ìï©ÏÑ± ÏßÄÎ∞ò Î™®Îç∏ ÏÉùÏÑ± Ï§ë...\")\n",
    "model = processor.create_random_model(nlayers=6)\n",
    "print(\"‚úÖ Î™®Îç∏ ÏÉùÏÑ± ÏôÑÎ£å!\")\n",
    "print()\n",
    "\n",
    "# ÏßÄÏ∏µ Ï†ïÎ≥¥ Ï∂úÎ†•\n",
    "print(\"=\"*80)\n",
    "print(\"üìä ÏÉùÏÑ±Îêú ÏßÄÏ∏µ Ï†ïÎ≥¥\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Layer':<15} {'Depth (m)':<12} {'Thickness (m)':<15} {'Velocity (m/s)':<15} {'Density (kg/m¬≥)'}\")\n",
    "print(\"-\"*80)\n",
    "for i in range(len(model['name'])):\n",
    "    print(f\"{model['name'][i]:<15} {model['depth'][i]:<12.1f} {model['thickness'][i]:<15.1f} \"\n",
    "          f\"{model['velocity'][i]:<15.1f} {model['density'][i]:<15.1f}\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Î™®Îç∏ ÏãúÍ∞ÅÌôî\n",
    "print(\"üìà ÏßÄÏ∏µ Î™®Îç∏ ÏãúÍ∞ÅÌôî...\")\n",
    "processor.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step3"
   },
   "source": [
    "## üéØ Step 3: Shot Gather ÏÉùÏÑ± (Clean)\n",
    "\n",
    "**Ïù¥ ÏÖÄÏùÑ Ïã§ÌñâÌïòÎ©¥:**\n",
    "- 48Í∞ú Ìä∏Î†àÏù¥Ïä§ Shot Gather ÏÉùÏÑ±\n",
    "- NMO Î∞è AVO Ìö®Í≥º Ï†ÅÏö©\n",
    "- ÏõêÎ≥∏ Shot Gather ÏãúÍ∞ÅÌôî"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate_shot"
   },
   "outputs": [],
   "source": [
    "print(\"üéØ Shot Gather ÏÉùÏÑ± Ï§ë...\")\n",
    "print()\n",
    "\n",
    "# Shot Gather ÏÉùÏÑ±\n",
    "n_traces = 48\n",
    "offset_min = 100\n",
    "offset_max = 2400\n",
    "freq = 25.0\n",
    "\n",
    "clean_shot, offsets = processor.generate_shot_gather(\n",
    "    model,\n",
    "    n_traces=n_traces,\n",
    "    offset_min=offset_min,\n",
    "    offset_max=offset_max,\n",
    "    freq=freq\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Shot Gather ÏÉùÏÑ± ÏôÑÎ£å!\")\n",
    "print()\n",
    "print(\"üìä Shot Gather Ï†ïÎ≥¥:\")\n",
    "print(f\"   - Ìä∏Î†àÏù¥Ïä§ Í∞úÏàò: {n_traces}\")\n",
    "print(f\"   - Ïò§ÌîÑÏÖã Î≤îÏúÑ: {offsets[0]:.0f} ~ {offsets[-1]:.0f} m\")\n",
    "print(f\"   - Wavelet Ï£ºÌååÏàò: {freq} Hz\")\n",
    "print(f\"   - Îç∞Ïù¥ÌÑ∞ ÌÅ¨Í∏∞: {clean_shot.shape}\")\n",
    "print(f\"   - RMS: {np.sqrt(np.mean(clean_shot**2)):.6f}\")\n",
    "print()\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî\n",
    "print(\"üìà ÏõêÎ≥∏ Shot Gather ÏãúÍ∞ÅÌôî...\")\n",
    "processor.plot_shot_gather(clean_shot, offsets, \"‚ú® Original Shot Gather (Clean)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step4"
   },
   "source": [
    "## üì¢ Step 4: ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä\n",
    "\n",
    "**Ïù¥ ÏÖÄÏùÑ Ïã§ÌñâÌïòÎ©¥:**\n",
    "- 4Í∞ÄÏßÄ ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä (Î∞±ÏÉâÏû°Ïùå, Ground Roll, Ïä§ÌååÏù¥ÌÅ¨, Ï†ÄÏ£ºÌåå)\n",
    "- ÎÖ∏Ïù¥Ï¶àÍ∞Ä Ï∂îÍ∞ÄÎêú Shot Gather ÏãúÍ∞ÅÌôî\n",
    "- SNR Í≥ÑÏÇ∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "add_noise"
   },
   "outputs": [],
   "source": [
    "print(\"üì¢ ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä Ï§ë...\")\n",
    "print()\n",
    "\n",
    "# ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä\n",
    "noise_level = 0.12\n",
    "noisy_shot = processor.add_realistic_noise(clean_shot, noise_level=noise_level)\n",
    "\n",
    "print(\"‚úÖ ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä ÏôÑÎ£å!\")\n",
    "print()\n",
    "print(\"üìä Ï∂îÍ∞ÄÎêú ÎÖ∏Ïù¥Ï¶à:\")\n",
    "print(\"   ‚úÖ Î∞±ÏÉâ Ïû°Ïùå (White Noise)\")\n",
    "print(\"   ‚úÖ Ground Roll (5-15 Hz)\")\n",
    "print(\"   ‚úÖ Ïä§ÌååÏù¥ÌÅ¨ ÎÖ∏Ïù¥Ï¶à (Bad Traces)\")\n",
    "print(\"   ‚úÖ Ï†ÄÏ£ºÌåå Ìä∏Î†åÎìú\")\n",
    "print()\n",
    "\n",
    "# ÌÜµÍ≥Ñ\n",
    "noise = noisy_shot - clean_shot\n",
    "snr_before = 20 * np.log10(np.std(clean_shot) / np.std(noise))\n",
    "\n",
    "print(\"üìà ÌÜµÍ≥Ñ:\")\n",
    "print(f\"   - Clean RMS: {np.sqrt(np.mean(clean_shot**2)):.6f}\")\n",
    "print(f\"   - Noisy RMS: {np.sqrt(np.mean(noisy_shot**2)):.6f}\")\n",
    "print(f\"   - Noise RMS: {np.sqrt(np.mean(noise**2)):.6f}\")\n",
    "print(f\"   - SNR: {snr_before:.2f} dB\")\n",
    "print()\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî\n",
    "print(\"üìà ÎÖ∏Ïù¥Ï¶àÍ∞Ä Ï∂îÍ∞ÄÎêú Shot Gather ÏãúÍ∞ÅÌôî...\")\n",
    "processor.plot_shot_gather(noisy_shot, offsets, \"üì¢ Shot Gather with Noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step5"
   },
   "source": [
    "## üîß Step 5: ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞\n",
    "\n",
    "**Ïù¥ ÏÖÄÏùÑ Ïã§ÌñâÌïòÎ©¥:**\n",
    "- Î∞¥ÎìúÌå®Ïä§ ÌïÑÌÑ∞ (8-60 Hz)\n",
    "- F-K ÌïÑÌÑ∞ (Ground Roll Ï†úÍ±∞)\n",
    "- Median ÌïÑÌÑ∞ (Ïä§ÌååÏù¥ÌÅ¨ Ï†úÍ±∞)\n",
    "- ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞Îêú Shot Gather ÏãúÍ∞ÅÌôî\n",
    "- SNR Í∞úÏÑ† Í≥ÑÏÇ∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "denoise"
   },
   "outputs": [],
   "source": [
    "print(\"üîß ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ Ï§ë...\")\n",
    "print()\n",
    "print(\"Ï†ÅÏö© Í∏∞Î≤ï:\")\n",
    "print(\"   1Ô∏è‚É£ Î∞¥ÎìúÌå®Ïä§ ÌïÑÌÑ∞ (8-60 Hz)\")\n",
    "print(\"   2Ô∏è‚É£ F-K ÌïÑÌÑ∞ (Ground Roll Ï†úÍ±∞, < 1500 m/s)\")\n",
    "print(\"   3Ô∏è‚É£ Median ÌïÑÌÑ∞ (Ïä§ÌååÏù¥ÌÅ¨ Ï†úÍ±∞)\")\n",
    "print()\n",
    "\n",
    "# ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞\n",
    "denoised_shot = processor.denoise_combined(noisy_shot)\n",
    "\n",
    "print(\"‚úÖ ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ ÏôÑÎ£å!\")\n",
    "print()\n",
    "\n",
    "# ÌÜµÍ≥Ñ\n",
    "residual = denoised_shot - clean_shot\n",
    "snr_after = 20 * np.log10(np.std(clean_shot) / np.std(residual))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ Í≤∞Í≥º\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Denoised RMS:    {np.sqrt(np.mean(denoised_shot**2)):.6f}\")\n",
    "print(f\"Residual RMS:    {np.sqrt(np.mean(residual**2)):.6f}\")\n",
    "print()\n",
    "print(f\"SNR (ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä ÌõÑ):  {snr_before:.2f} dB\")\n",
    "print(f\"SNR (ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ ÌõÑ):  {snr_after:.2f} dB\")\n",
    "print(f\"SNR Í∞úÏÑ†:             {snr_after - snr_before:.2f} dB  ‚¨ÜÔ∏è\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî\n",
    "print(\"üìà ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞Îêú Shot Gather ÏãúÍ∞ÅÌôî...\")\n",
    "processor.plot_shot_gather(denoised_shot, offsets, \"üîß Denoised Shot Gather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step6"
   },
   "source": [
    "## üìä Step 6: Ï†ÑÏ≤¥ ÎπÑÍµê\n",
    "\n",
    "**Ïù¥ ÏÖÄÏùÑ Ïã§ÌñâÌïòÎ©¥:**\n",
    "- ÏõêÎ≥∏, ÎÖ∏Ïù¥Ï¶à, ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ 3Í∞ú ÎÇòÎûÄÌûà ÎπÑÍµê\n",
    "- ÏãúÍ∞ÅÏ†ÅÏúºÎ°ú Ï∞®Ïù¥ ÌôïÏù∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison"
   },
   "outputs": [],
   "source": [
    "print(\"üìä Ï†ÑÏ≤¥ ÎπÑÍµê ÏãúÍ∞ÅÌôî...\")\n",
    "print()\n",
    "\n",
    "processor.plot_comparison(clean_shot, noisy_shot, denoised_shot, offsets)\n",
    "\n",
    "print(\"‚úÖ ÎπÑÍµê ÏôÑÎ£å!\")\n",
    "print()\n",
    "print(\"üí° Ï£ºÏùò ÍπäÍ≤å Î≥¥ÏÑ∏Ïöî:\")\n",
    "print(\"   - Original: Íπ®ÎÅóÌïú Î∞òÏÇ¨ Ïã†Ìò∏\")\n",
    "print(\"   - With Noise: Ground RollÍ≥º Ïä§ÌååÏù¥ÌÅ¨Í∞Ä Î≥¥ÏûÖÎãàÎã§\")\n",
    "print(\"   - Denoised: ÎÖ∏Ïù¥Ï¶àÍ∞Ä Ï†úÍ±∞ÎêòÍ≥† ÏõêÎ≥∏Ïóê Í∞ÄÍπåÏõåÏ°åÏäµÎãàÎã§\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step7"
   },
   "source": [
    "## üíæ Step 7: Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• Î∞è Îã§Ïö¥Î°úÎìú\n",
    "\n",
    "**Ïù¥ ÏÖÄÏùÑ Ïã§ÌñâÌïòÎ©¥:**\n",
    "- 3Í∞ú NPZ ÌååÏùº Ï†ÄÏû•\n",
    "- ÏûêÎèô Îã§Ïö¥Î°úÎìú (Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save_download"
   },
   "outputs": [],
   "source": [
    "print(\"üíæ Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• Ï§ë...\")\n",
    "print()\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû•\n",
    "np.savez('shot_gather_clean.npz',\n",
    "         shot_gather=clean_shot,\n",
    "         offsets=offsets,\n",
    "         time=processor.time,\n",
    "         model=model)\n",
    "print(\"‚úÖ shot_gather_clean.npz Ï†ÄÏû• ÏôÑÎ£å\")\n",
    "\n",
    "np.savez('shot_gather_noisy.npz',\n",
    "         shot_gather=noisy_shot,\n",
    "         offsets=offsets,\n",
    "         time=processor.time,\n",
    "         model=model)\n",
    "print(\"‚úÖ shot_gather_noisy.npz Ï†ÄÏû• ÏôÑÎ£å\")\n",
    "\n",
    "np.savez('shot_gather_denoised.npz',\n",
    "         shot_gather=denoised_shot,\n",
    "         offsets=offsets,\n",
    "         time=processor.time,\n",
    "         model=model)\n",
    "print(\"‚úÖ shot_gather_denoised.npz Ï†ÄÏû• ÏôÑÎ£å\")\n",
    "print()\n",
    "\n",
    "# ColabÏóêÏÑú Îã§Ïö¥Î°úÎìú\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print(\"üì• Îã§Ïö¥Î°úÎìú ÏãúÏûë...\")\n",
    "    print()\n",
    "    files.download('shot_gather_clean.npz')\n",
    "    files.download('shot_gather_noisy.npz')\n",
    "    files.download('shot_gather_denoised.npz')\n",
    "    print(\"‚úÖ Î™®Îì† ÌååÏùº Îã§Ïö¥Î°úÎìú ÏôÑÎ£å!\")\n",
    "except:\n",
    "    print(\"‚ÑπÔ∏è Î°úÏª¨ ÌôòÍ≤ΩÏóêÏÑú Ïã§Ìñâ Ï§ë - ÌååÏùºÏù¥ ÌòÑÏû¨ ÎîîÎ†âÌÜ†Î¶¨Ïóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"üéâ Ï†ÑÏ≤¥ ÏõåÌÅ¨ÌîåÎ°úÏö∞ ÏôÑÎ£å!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step8"
   },
   "source": [
    "## üî¨ Step 8: Ï∂îÍ∞Ä Î∂ÑÏÑù - Îã®Ïùº Ìä∏Î†àÏù¥Ïä§ ÎπÑÍµê\n",
    "\n",
    "**ÏÑ†ÌÉùÏÇ¨Ìï≠: ÌäπÏ†ï Ìä∏Î†àÏù¥Ïä§Î•º ÏûêÏÑ∏Ìûà Î∂ÑÏÑù**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "trace_analysis"
   },
   "outputs": [],
   "source": [
    "# Ï§ëÍ∞Ñ Ïò§ÌîÑÏÖã Ìä∏Î†àÏù¥Ïä§ ÏÑ†ÌÉù\n",
    "trace_idx = len(offsets) // 2\n",
    "\n",
    "print(f\"üî¨ Ìä∏Î†àÏù¥Ïä§ {trace_idx} Î∂ÑÏÑù (Ïò§ÌîÑÏÖã = {offsets[trace_idx]:.0f} m)\")\n",
    "print()\n",
    "\n",
    "# ÌîåÎ°Ø\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 8))\n",
    "\n",
    "axes[0].plot(clean_shot[:, trace_idx], processor.time, 'b-', linewidth=1.5)\n",
    "axes[0].set_xlabel('Amplitude', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Time (s)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title(f'Clean Trace\\n(Offset={offsets[trace_idx]:.0f}m)', fontsize=13, fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(noisy_shot[:, trace_idx], processor.time, 'r-', linewidth=1.5)\n",
    "axes[1].set_xlabel('Amplitude', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Time (s)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title(f'Noisy Trace\\n(Offset={offsets[trace_idx]:.0f}m)', fontsize=13, fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(denoised_shot[:, trace_idx], processor.time, 'g-', linewidth=1.5)\n",
    "axes[2].set_xlabel('Amplitude', fontsize=12, fontweight='bold')\n",
    "axes[2].set_ylabel('Time (s)', fontsize=12, fontweight='bold')\n",
    "axes[2].set_title(f'Denoised Trace\\n(Offset={offsets[trace_idx]:.0f}m)', fontsize=13, fontweight='bold')\n",
    "axes[2].invert_yaxis()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Ìä∏Î†àÏù¥Ïä§ {trace_idx} ÎπÑÍµê ÏôÑÎ£å!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step9"
   },
   "source": [
    "## üìä Step 9: Ï£ºÌååÏàò Ïä§ÌéôÌä∏Îüº Î∂ÑÏÑù\n",
    "\n",
    "**ÏÑ†ÌÉùÏÇ¨Ìï≠: Ï£ºÌååÏàò ÎèÑÎ©îÏù∏ÏóêÏÑú ÎπÑÍµê**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "spectrum"
   },
   "outputs": [],
   "source": [
    "# Ï§ëÍ∞Ñ Ìä∏Î†àÏù¥Ïä§ FFT\n",
    "trace_idx = len(offsets) // 2\n",
    "dt = processor.time[1] - processor.time[0]\n",
    "\n",
    "print(f\"üìä Ï£ºÌååÏàò Ïä§ÌéôÌä∏Îüº Î∂ÑÏÑù (Ìä∏Î†àÏù¥Ïä§ {trace_idx}, Ïò§ÌîÑÏÖã {offsets[trace_idx]:.0f}m)\")\n",
    "print()\n",
    "\n",
    "# FFT Í≥ÑÏÇ∞\n",
    "freq = np.fft.rfftfreq(len(processor.time), dt)\n",
    "clean_fft = np.abs(np.fft.rfft(clean_shot[:, trace_idx]))\n",
    "noisy_fft = np.abs(np.fft.rfft(noisy_shot[:, trace_idx]))\n",
    "denoised_fft = np.abs(np.fft.rfft(denoised_shot[:, trace_idx]))\n",
    "\n",
    "# ÌîåÎ°Ø\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(freq, clean_fft, 'b-', linewidth=2, label='Clean', alpha=0.8)\n",
    "ax.plot(freq, noisy_fft, 'r-', linewidth=2, label='Noisy', alpha=0.6)\n",
    "ax.plot(freq, denoised_fft, 'g-', linewidth=2, label='Denoised', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Frequency (Hz)', fontsize=13, fontweight='bold')\n",
    "ax.set_ylabel('Amplitude Spectrum', fontsize=13, fontweight='bold')\n",
    "ax.set_title(f'Frequency Spectrum Comparison (Offset={offsets[trace_idx]:.0f}m)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xlim([0, 100])\n",
    "ax.legend(fontsize=12, loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Ï£ºÌååÏàò Ïä§ÌéôÌä∏Îüº Î∂ÑÏÑù ÏôÑÎ£å!\")\n",
    "print()\n",
    "print(\"üí° Í¥ÄÏ∞∞ Ìè¨Ïù∏Ìä∏:\")\n",
    "print(\"   - Noisy (Îπ®Í∞ï): Ï†ÄÏ£ºÌåå Î∞è Í≥†Ï£ºÌååÏóê ÎÖ∏Ïù¥Ï¶àÍ∞Ä ÎßéÏäµÎãàÎã§\")\n",
    "print(\"   - Denoised (Ï¥àÎ°ù): ÌïÑÌÑ∞ÎßÅÏúºÎ°ú ÎÖ∏Ïù¥Ï¶àÍ∞Ä Ï†úÍ±∞ÎêòÏóàÏäµÎãàÎã§\")\n",
    "print(\"   - Clean (ÌååÎûë): ÏõêÎ≥∏ Ïã†Ìò∏Ïùò Ï£ºÌååÏàò ÌäπÏÑ±\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "final"
   },
   "source": [
    "## üéâ ÏôÑÎ£å!\n",
    "\n",
    "---\n",
    "\n",
    "### üìù ÏöîÏïΩ\n",
    "\n",
    "Î™®Îì† Îã®Í≥ÑÎ•º Ïã§ÌñâÌïòÏÖ®Îã§Î©¥:\n",
    "\n",
    "‚úÖ ÎûúÎç§ ÏßÄÏ∏µ Î™®Îç∏ ÏÉùÏÑ± ÏôÑÎ£å  \n",
    "‚úÖ Shot Gather ÏÉùÏÑ± ÏôÑÎ£å  \n",
    "‚úÖ ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä ÏôÑÎ£å  \n",
    "‚úÖ ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ ÏôÑÎ£å  \n",
    "‚úÖ 3Í∞ú ÌååÏùº Îã§Ïö¥Î°úÎìú ÏôÑÎ£å\n",
    "\n",
    "---\n",
    "\n",
    "### üíæ ÏÉùÏÑ±Îêú ÌååÏùº\n",
    "\n",
    "1. **shot_gather_clean.npz** - ÏõêÎ≥∏ Shot Gather\n",
    "2. **shot_gather_noisy.npz** - ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞ÄÎêú Shot Gather\n",
    "3. **shot_gather_denoised.npz** - ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞Îêú Shot Gather\n",
    "\n",
    "---\n",
    "\n",
    "### üîÑ Îã§Ïãú Ïã§ÌñâÌïòÍ∏∞\n",
    "\n",
    "ÏÉàÎ°úÏö¥ ÎûúÎç§ Î™®Îç∏Î°ú Îã§Ïãú Ïã§ÌñâÌïòÎ†§Î©¥:\n",
    "- **Step 2**Î∂ÄÌÑ∞ Îã§Ïãú Ïã§ÌñâÌïòÏÑ∏Ïöî!\n",
    "- Îß§Î≤à Îã§Î•∏ ÏßÄÏ∏µ Î™®Îç∏Í≥º Í≤∞Í≥ºÎ•º ÏñªÏùÑ Ïàò ÏûàÏäµÎãàÎã§.\n",
    "\n",
    "---\n",
    "\n",
    "### üìö Í¥ÄÎ†® ÎßÅÌÅ¨\n",
    "\n",
    "- **GitHub**: https://github.com/knocgp/seismic\n",
    "- **ÏÉÅÏÑ∏ Í∞ÄÏù¥Îìú**: [SHOT_GATHER_GUIDE.md](https://github.com/knocgp/seismic/blob/main/SHOT_GATHER_GUIDE.md)\n",
    "- **Colab Í∞ÄÏù¥Îìú**: [COLAB_GUIDE_KR.md](https://github.com/knocgp/seismic/blob/main/COLAB_GUIDE_KR.md)\n",
    "\n",
    "---\n",
    "\n",
    "**Made with ‚ù§Ô∏è for Seismic Data Processing**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
