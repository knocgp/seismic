{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "## üìã Îã®Í≥ÑÎ≥Ñ Ïã§Ìñâ ÏõåÌÅ¨ÌîåÎ°úÏö∞\n",
    "\n",
    "**Í∞Å ÏÖÄÏùÑ ÌïòÎÇòÏî© Ïã§ÌñâÌïòÎ©¥ÏÑú Í≤∞Í≥ºÎ•º ÌôïÏù∏ÌïòÏÑ∏Ïöî!**\n",
    "\n",
    "1. ‚úÖ Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò Î∞è ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
    "2. ‚úÖ ÎûúÎç§ Ìï©ÏÑ± Î™®Îç∏ ÏÉùÏÑ±\n",
    "3. ‚úÖ Shot Gather ÏÉùÏÑ± (Clean)\n",
    "4. ‚úÖ ÏßÅÏ†ëÌåå Ï∂îÍ∞Ä\n",
    "5. ‚úÖ Multiple Ï∂îÍ∞Ä (Ìï¥Î©¥ + ÎÇ¥Î∂Ä)\n",
    "6. ‚úÖ Ìï¥ÏÉÅ ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä\n",
    "7. ‚úÖ **Anomalous Amplitude Attenuation** ‚≠ê ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞\n",
    "8. ‚úÖ **Low-cut Filter (1.5 Hz)** ‚≠ê Ï†ÄÏ£ºÌåå Ï†úÍ±∞\n",
    "9. ‚úÖ **Curvelet Denoise** ‚≠ê ÏùºÎ∞ò ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞\n",
    "10. ‚úÖ **ÏßÅÏ†ëÌåå Ï†úÍ±∞ (Direct Wave Mute)** ‚≠ê NEW\n",
    "11. ‚úÖ **Water Bottom Demultiple** ‚≠ê Multiple Ï†úÍ±∞\n",
    "12. ‚úÖ **Radon Transform Demultiple** ‚≠ê Multiple Ï†úÍ±∞\n",
    "13. ‚úÖ Ï†ÑÏ≤¥ ÎπÑÍµê\n",
    "14. ‚úÖ Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• Î∞è Îã§Ïö¥Î°úÎìú\n",
    "\n",
    "---\n",
    "\n",
    "**üöÄ ÏÇ¨Ïö©Î≤ï: Í∞Å ÏÖÄÏùÑ ÏàúÏÑúÎåÄÎ°ú Ïã§Ìñâ (Shift + Enter)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1"
   },
   "source": [
    "## üì¶ Step 1: Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò Î∞è ÏûÑÌè¨Ìä∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "!pip install -q numpy scipy matplotlib pywt scikit-image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.ndimage import median_filter\n",
    "from scipy.linalg import svd\n",
    "import pywt\n",
    "from skimage.restoration import denoise_wavelet\n",
    "from typing import Tuple, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò Î∞è ÏûÑÌè¨Ìä∏ ÏôÑÎ£å!\")\n",
    "print(\"   - NumPy\")\n",
    "print(\"   - SciPy\")\n",
    "print(\"   - Matplotlib\")\n",
    "print(\"   - PyWavelets (Curvelet)\")\n",
    "print(\"   - scikit-image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1b"
   },
   "source": [
    "## üîß Step 1-2: Í≥†Í∏â Ï≤òÎ¶¨ ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
    "\n",
    "**Í≥†Í∏â Ï≤òÎ¶¨ Í∏∞Î≤ï:**\n",
    "- ‚úÖ Water Bottom Demultiple\n",
    "- ‚úÖ Radon Transform Demultiple  \n",
    "- ‚úÖ Anomalous Amplitude Attenuation\n",
    "- ‚úÖ Curvelet Denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "class_definition"
   },
   "outputs": [],
   "source": [
    "class AdvancedMarineProcessor:\n",
    "    \"\"\"Í≥†Í∏â Ìï¥ÏÉÅ Shot Gather Ï≤òÎ¶¨ ÌÅ¥ÎûòÏä§\"\"\"\n",
    "    \n",
    "    def __init__(self, dt: float = 0.002, nt: int = 1500):\n",
    "        self.dt = dt\n",
    "        self.nt = nt\n",
    "        self.time = np.arange(nt) * dt\n",
    "        \n",
    "    def create_random_model(self, nlayers: int = None) -> Dict:\n",
    "        \"\"\"ÏôÑÏ†Ñ ÎûúÎç§ Ìï©ÏÑ± ÏßÄÎ∞ò Î™®Îç∏ ÏÉùÏÑ±\"\"\"\n",
    "        if nlayers is None:\n",
    "            nlayers = np.random.randint(4, 9)\n",
    "        \n",
    "        model = {'velocity': [], 'density': [], 'thickness': [], 'depth': [], 'name': []}\n",
    "        \n",
    "        # Ìï¥ÏàòÏ∏µ\n",
    "        water_depth = np.random.uniform(300, 800)\n",
    "        model['velocity'].append(1500.0)\n",
    "        model['density'].append(1030.0)\n",
    "        model['thickness'].append(water_depth)\n",
    "        model['depth'].append(0.0)\n",
    "        model['name'].append('Water')\n",
    "        \n",
    "        # Ìï¥Ï†ÄÎ©¥\n",
    "        seabed_vp = np.random.uniform(1600, 2000)\n",
    "        seabed_rho = np.random.uniform(1900, 2100)\n",
    "        seabed_thick = np.random.uniform(200, 400)\n",
    "        model['velocity'].append(seabed_vp)\n",
    "        model['density'].append(seabed_rho)\n",
    "        model['thickness'].append(seabed_thick)\n",
    "        model['depth'].append(water_depth)\n",
    "        model['name'].append('Seabed')\n",
    "        \n",
    "        # ÏßÄÌïò ÏßÄÏ∏µÎì§\n",
    "        current_depth = water_depth + seabed_thick\n",
    "        for i in range(nlayers - 2):\n",
    "            if i == 0:\n",
    "                base_vp = seabed_vp + np.random.uniform(200, 500)\n",
    "            else:\n",
    "                base_vp = model['velocity'][-1] + np.random.uniform(100, 600)\n",
    "            \n",
    "            vp = base_vp + np.random.normal(0, 100)\n",
    "            vp = np.clip(vp, 2000, 5000)\n",
    "            rho = 2000 + (vp - 2000) * 0.2 + np.random.normal(0, 50)\n",
    "            rho = np.clip(rho, 2000, 2800)\n",
    "            thickness = np.random.uniform(150, 600)\n",
    "            \n",
    "            model['velocity'].append(vp)\n",
    "            model['density'].append(rho)\n",
    "            model['thickness'].append(thickness)\n",
    "            model['depth'].append(current_depth)\n",
    "            model['name'].append(f'Layer {i+3}')\n",
    "            current_depth += thickness\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def calculate_reflection_coefficients(self, model: Dict):\n",
    "        velocities = np.array(model['velocity'])\n",
    "        densities = np.array(model['density'])\n",
    "        thicknesses = np.array(model['thickness'])\n",
    "        impedance = velocities * densities\n",
    "        \n",
    "        rc = np.zeros(len(velocities) - 1)\n",
    "        for i in range(len(velocities) - 1):\n",
    "            rc[i] = (impedance[i+1] - impedance[i]) / (impedance[i+1] + impedance[i])\n",
    "        \n",
    "        times = np.zeros(len(velocities) - 1)\n",
    "        cumulative_time = 0\n",
    "        for i in range(len(velocities) - 1):\n",
    "            travel_time = thicknesses[i] / velocities[i]\n",
    "            cumulative_time += travel_time\n",
    "            times[i] = cumulative_time * 2\n",
    "        \n",
    "        return rc, times\n",
    "    \n",
    "    def ricker_wavelet(self, freq: float = 25.0):\n",
    "        duration = 0.2\n",
    "        t = np.arange(-duration/2, duration/2, self.dt)\n",
    "        a = (np.pi * freq * t) ** 2\n",
    "        wavelet = (1 - 2*a) * np.exp(-a)\n",
    "        return wavelet / np.max(np.abs(wavelet))\n",
    "    \n",
    "    def generate_shot_gather(self, model: Dict, n_traces: int = 48, \n",
    "                           offset_min: float = 100, offset_max: float = 2400,\n",
    "                           freq: float = 25.0):\n",
    "        \"\"\"Shot Gather ÏÉùÏÑ±\"\"\"\n",
    "        offsets = np.linspace(offset_min, offset_max, n_traces)\n",
    "        shot_gather = np.zeros((self.nt, n_traces))\n",
    "        wavelet = self.ricker_wavelet(freq)\n",
    "        rc, zero_offset_times = self.calculate_reflection_coefficients(model)\n",
    "        \n",
    "        for i_trace, offset in enumerate(offsets):\n",
    "            reflectivity = np.zeros(self.nt)\n",
    "            \n",
    "            for j, (rc_val, t0) in enumerate(zip(rc, zero_offset_times)):\n",
    "                depths = np.array(model['depth'])\n",
    "                velocities = np.array(model['velocity'])\n",
    "                \n",
    "                if j < len(depths) - 1:\n",
    "                    avg_depth = depths[j+1]\n",
    "                    avg_velocity = np.mean(velocities[:j+2])\n",
    "                    t_nmo = np.sqrt(t0**2 + (offset / avg_velocity)**2)\n",
    "                    angle = np.arctan(offset / avg_depth)\n",
    "                    avo_factor = 1 - 0.3 * np.sin(angle)**2\n",
    "                    \n",
    "                    idx = int(t_nmo / self.dt)\n",
    "                    if idx < self.nt:\n",
    "                        reflectivity[idx] += rc_val * avo_factor\n",
    "            \n",
    "            trace = signal.convolve(reflectivity, wavelet, mode='same')\n",
    "            spreading = 1 / (1 + offset / 1000)\n",
    "            shot_gather[:, i_trace] = trace * spreading\n",
    "        \n",
    "        return shot_gather, offsets\n",
    "    \n",
    "    def add_direct_wave(self, shot_gather, offsets, model: Dict, strength: float = 0.3):\n",
    "        \"\"\"ÏßÅÏ†ëÌåå Ï∂îÍ∞Ä\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        water_velocity = model['velocity'][0]\n",
    "        wavelet = self.ricker_wavelet(25.0)\n",
    "        \n",
    "        for i, offset in enumerate(offsets):\n",
    "            direct_time = offset / water_velocity\n",
    "            idx = int(direct_time / self.dt)\n",
    "            \n",
    "            if idx < self.nt:\n",
    "                amplitude = strength / (1 + offset / 500)\n",
    "                wavelet_start = max(0, idx - len(wavelet)//2)\n",
    "                wavelet_end = min(self.nt, idx + len(wavelet)//2)\n",
    "                wavelet_idx_start = max(0, len(wavelet)//2 - idx)\n",
    "                wavelet_idx_end = wavelet_idx_start + (wavelet_end - wavelet_start)\n",
    "                \n",
    "                result[wavelet_start:wavelet_end, i] += amplitude * wavelet[wavelet_idx_start:wavelet_idx_end]\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def add_sea_surface_multiple(self, shot_gather, model: Dict, strength: float = 0.5):\n",
    "        \"\"\"Ìï¥Î©¥ Î©ÄÌã∞Ìîå Ï∂îÍ∞Ä\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        water_depth = model['thickness'][0]\n",
    "        water_velocity = model['velocity'][0]\n",
    "        two_way_time = 2 * water_depth / water_velocity\n",
    "        delay_samples = int(two_way_time / self.dt)\n",
    "        sea_surface_rc = -0.95\n",
    "        \n",
    "        if delay_samples < self.nt:\n",
    "            result[delay_samples:, :] += shot_gather[:-delay_samples, :] * sea_surface_rc * strength\n",
    "        \n",
    "        if 2 * delay_samples < self.nt:\n",
    "            result[2*delay_samples:, :] += shot_gather[:-2*delay_samples, :] * (sea_surface_rc**2) * strength * 0.5\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def add_internal_multiples(self, shot_gather, model: Dict, strength: float = 0.3):\n",
    "        \"\"\"ÎÇ¥Î∂Ä Î©ÄÌã∞Ìîå Ï∂îÍ∞Ä\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        rc, reflection_times = self.calculate_reflection_coefficients(model)\n",
    "        \n",
    "        strong_reflectors = [(t, rc_val) for t, rc_val in zip(reflection_times, rc) \n",
    "                           if abs(rc_val) > 0.1]\n",
    "        \n",
    "        for i, (t1, rc1) in enumerate(strong_reflectors):\n",
    "            for t2, rc2 in strong_reflectors[i+1:]:\n",
    "                multiple_delay = t2 - t1 + (t2 - t1)\n",
    "                delay_samples = int(multiple_delay / self.dt)\n",
    "                \n",
    "                if delay_samples < self.nt:\n",
    "                    multiple_strength = rc1 * rc2 * strength\n",
    "                    result[delay_samples:, :] += shot_gather[:-delay_samples, :] * multiple_strength\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def add_swell_noise(self, shot_gather, offsets, swell_strength=0.5):\n",
    "        \"\"\"Swell Noise Ï∂îÍ∞Ä - Linear Moveout Coherent Noise\n",
    "        \n",
    "        ÎåÄÍ∞ÅÏÑ† Ìå®ÌÑ¥ÏúºÎ°ú ÎÇòÌÉÄÎÇòÎäî coherent noise:\n",
    "        - Ï£ºÌååÏàò: 0.1-0.5 Hz (Îß§Ïö∞ ÎÇÆÏùå)\n",
    "        - Linear moveout: offsetÏóê ÎπÑÎ°ÄÌïòÎäî ÏãúÍ∞Ñ ÏßÄÏó∞\n",
    "        - Apparent velocity: 1000-2000 m/s (ÎäêÎ¶∞ ÏÜçÎèÑ)\n",
    "        - Ìï¥Ïñë ÌëúÎ©¥Ìåå, ÏºÄÏù¥Î∏î ÏßÑÎèôÏùò Ï†ÑÌåå\n",
    "        \"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        signal_power = np.std(shot_gather)\n",
    "        \n",
    "        # Ïó¨Îü¨ swell ÏÑ±Î∂Ñ (Í∞ÅÍ∞Å Îã§Î•∏ apparent velocity)\n",
    "        n_components = np.random.randint(2, 4)\n",
    "        \n",
    "        for _ in range(n_components):\n",
    "            # Swell Ï£ºÌååÏàò\n",
    "            swell_freq = np.random.uniform(0.1, 0.5)\n",
    "            \n",
    "            # Apparent velocity (ÎäêÎ¶∞ ÏÜçÎèÑ)\n",
    "            apparent_velocity = np.random.uniform(1000, 2000)  # m/s\n",
    "            \n",
    "            # ÏãúÍ∞Ñ Î≥ÄÏ°∞\n",
    "            modulation_freq = np.random.uniform(0.05, 0.15)\n",
    "            \n",
    "            # ÏßÑÌè≠\n",
    "            amplitude = swell_strength * signal_power * (0.8 + 0.4 * np.random.rand())\n",
    "            \n",
    "            # Í∞Å Ìä∏Î†àÏù¥Ïä§Ïóê linear moveout Ï†ÅÏö©\n",
    "            for j, offset in enumerate(offsets):\n",
    "                # Linear moveout: t_arrival = t0 + offset / v_app\n",
    "                time_shift = offset / apparent_velocity\n",
    "                \n",
    "                # ÏãúÍ∞ÑÏ∂ï ÏÉùÏÑ±\n",
    "                t_shifted = self.time - time_shift\n",
    "                \n",
    "                # ÏãúÍ∞Ñ Î≥ÄÏ°∞\n",
    "                time_modulation = 1 + 0.6 * np.sin(2 * np.pi * modulation_freq * self.time)\n",
    "                \n",
    "                # Swell ÌååÌòï (shifted time)\n",
    "                swell_wave = np.zeros(nt)\n",
    "                for it in range(nt):\n",
    "                    if 0 <= t_shifted[it] <= self.time[-1]:\n",
    "                        swell_wave[it] = np.sin(2 * np.pi * swell_freq * t_shifted[it]) * time_modulation[it]\n",
    "                \n",
    "                result[:, j] += amplitude * swell_wave\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def remove_direct_wave(self, shot_gather, offsets, model: Dict, mute_velocity=1500, taper_length=50):\n",
    "        \"\"\"ÏßÅÏ†ëÌåå(Direct Wave) Ï†úÍ±∞ - Top Mute\n",
    "        \n",
    "        ÏßÅÏ†ëÌååÎäî Ìï¥ÏàòÏ∏µÏùÑ ÌÜµÌï¥ ÏßÅÏ†ë Ï†ÑÌååÎêòÎäî ÌååÎèô:\n",
    "        - ÏÜçÎèÑ: Ìï¥Ïàò ÏùåÏÜç (~1500 m/s)\n",
    "        - Í∞ÄÏû• Î®ºÏ†Ä ÎèÑÎã¨\n",
    "        - Linear moveout: t = offset / velocity\n",
    "        \n",
    "        Top muteÎ°ú Ï†úÍ±∞:\n",
    "        - Mute velocity Ïù¥ÏÉÅÏùò ÏÜçÎèÑÎ•º Í∞ÄÏßÑ Ïù¥Î≤§Ìä∏ Ï†úÍ±∞\n",
    "        - TaperÎ•º Ï†ÅÏö©ÌïòÏó¨ Î∂ÄÎìúÎüΩÍ≤å Ï†úÍ±∞\n",
    "        \"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        \n",
    "        for j, offset in enumerate(offsets):\n",
    "            # Mute time Í≥ÑÏÇ∞: t_mute = offset / mute_velocity\n",
    "            if mute_velocity > 0:\n",
    "                mute_time = offset / mute_velocity\n",
    "            else:\n",
    "                mute_time = 0\n",
    "            \n",
    "            mute_sample = int(mute_time / self.dt)\n",
    "            \n",
    "            # Mute Ï†ÅÏö© (taper Ìè¨Ìï®)\n",
    "            if mute_sample < nt:\n",
    "                # ÏôÑÏ†ÑÌûà Ï†úÍ±∞ÌïòÎäî Íµ¨Í∞Ñ\n",
    "                result[:mute_sample, j] = 0\n",
    "                \n",
    "                # Taper Íµ¨Í∞Ñ (Î∂ÄÎìúÎüΩÍ≤å Ï†ÑÌôò)\n",
    "                taper_end = min(mute_sample + taper_length, nt)\n",
    "                taper_samples = taper_end - mute_sample\n",
    "                \n",
    "                if taper_samples > 0:\n",
    "                    # Cosine taper\n",
    "                    taper = 0.5 * (1 - np.cos(np.pi * np.arange(taper_samples) / taper_samples))\n",
    "                    result[mute_sample:taper_end, j] *= taper\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def add_marine_noise(self, shot_gather, offsets, noise_level: float = 0.08):\n",
    "        \"\"\"Ìï¥ÏÉÅ ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        signal_power = np.std(shot_gather)\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        \n",
    "        # Î∞±ÏÉâ Ïû°Ïùå\n",
    "        white_noise = np.random.normal(0, noise_level * signal_power * 0.3, (nt, n_traces))\n",
    "        result += white_noise\n",
    "        \n",
    "        # ÏÑ†Î∞ï ÎÖ∏Ïù¥Ï¶à\n",
    "        ship_freq = np.random.uniform(2, 8)\n",
    "        for j in range(n_traces):\n",
    "            ship_noise = noise_level * signal_power * 0.5 * np.sin(2 * np.pi * ship_freq * self.time)\n",
    "            ship_noise *= (1 + 0.3 * np.sin(2 * np.pi * 0.5 * self.time))\n",
    "            result[:, j] += ship_noise\n",
    "        \n",
    "        # Ïä§Ïõ∞ ÎÖ∏Ïù¥Ï¶à (Í∞úÏÑ†Îêú Î™®Îç∏ ÏÇ¨Ïö©)\n",
    "        result = self.add_swell_noise(result, offsets, swell_strength=noise_level * 0.5)\n",
    "        \n",
    "        # Î≤ÑÏä§Ìä∏ ÎÖ∏Ïù¥Ï¶à\n",
    "        n_bursts = np.random.randint(2, 5)\n",
    "        for _ in range(n_bursts):\n",
    "            burst_trace = np.random.randint(0, n_traces)\n",
    "            burst_time = np.random.randint(0, nt)\n",
    "            burst_duration = np.random.randint(20, 80)\n",
    "            if burst_time + burst_duration < nt:\n",
    "                burst = noise_level * signal_power * 2.0 * np.random.randn(burst_duration)\n",
    "                result[burst_time:burst_time+burst_duration, burst_trace] += burst\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def lowcut_filter(self, shot_gather, cutoff_freq=1.5, order=5):\n",
    "        \"\"\"Low-cut (High-pass) Filter - Ï†ÄÏ£ºÌåå ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞\"\"\"\n",
    "        from scipy.signal import butter, filtfilt\n",
    "        \n",
    "        result = shot_gather.copy()\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        \n",
    "        # Nyquist frequency\n",
    "        fs = 1.0 / self.dt\n",
    "        nyquist = fs / 2.0\n",
    "        \n",
    "        # Normalize cutoff frequency\n",
    "        normalized_cutoff = cutoff_freq / nyquist\n",
    "        \n",
    "        # Design Butterworth high-pass filter\n",
    "        b, a = butter(order, normalized_cutoff, btype='high', analog=False)\n",
    "        \n",
    "        # Apply filter to each trace\n",
    "        for ix in range(n_traces):\n",
    "            result[:, ix] = filtfilt(b, a, shot_gather[:, ix])\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def water_bottom_demultiple(self, shot_gather, model: Dict, strength: float = 0.8):\n",
    "        \"\"\"Water Bottom Demultiple (Ìï¥Ï†ÄÎ©¥ Î©ÄÌã∞Ìîå Ï†úÍ±∞)\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        \n",
    "        # Ìï¥Ï†ÄÎ©¥ ÏñëÎ∞©Ìñ• Ï£ºÏãú Í≥ÑÏÇ∞\n",
    "        water_depth = model['thickness'][0]\n",
    "        water_velocity = model['velocity'][0]\n",
    "        wb_two_way_time = 2 * water_depth / water_velocity\n",
    "        wb_delay = int(wb_two_way_time / self.dt)\n",
    "        \n",
    "        # Ìï¥Ï†ÄÎ©¥ Î∞òÏÇ¨ Í≥ÑÏàò\n",
    "        water_impedance = model['velocity'][0] * model['density'][0]\n",
    "        seabed_impedance = model['velocity'][1] * model['density'][1]\n",
    "        wb_rc = (seabed_impedance - water_impedance) / (seabed_impedance + water_impedance)\n",
    "        \n",
    "        # Ìï¥Î©¥ Î∞òÏÇ¨ Í≥ÑÏàò\n",
    "        sea_surface_rc = -0.95\n",
    "        \n",
    "        # Ìï¥Ï†ÄÎ©¥-Ìï¥Î©¥ Î©ÄÌã∞Ìîå ÏòàÏ∏° Î∞è Ï†úÍ±∞\n",
    "        for order in range(1, 4):  # 1Ï∞®, 2Ï∞®, 3Ï∞® Î©ÄÌã∞Ìîå\n",
    "            delay = wb_delay * order\n",
    "            if delay < self.nt:\n",
    "                # Î©ÄÌã∞Ìîå ÏòàÏ∏°\n",
    "                multiple_strength = (wb_rc * (sea_surface_rc ** order)) * strength\n",
    "                predicted_multiple = np.zeros_like(result)\n",
    "                predicted_multiple[delay:, :] = shot_gather[:-delay, :] * multiple_strength\n",
    "                \n",
    "                # Ï†ÅÏùë Í∞êÏá†\n",
    "                result -= predicted_multiple\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def radon_forward_transform(self, shot_gather, offsets, p_min=-0.001, p_max=0.001, n_p=128):\n",
    "        \"\"\"Forward Radon Transform (t-x -> tau-p) with linear interpolation\"\"\"\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        p_values = np.linspace(p_min, p_max, n_p)\n",
    "        \n",
    "        # Forward Radon Transform: radon(tau, p) = sum over x of data(tau - p*x, x)\n",
    "        radon_domain = np.zeros((nt, n_p))\n",
    "        for ip, p in enumerate(p_values):\n",
    "            for it in range(nt):\n",
    "                tau = self.time[it]\n",
    "                for ix, offset in enumerate(offsets):\n",
    "                    # Time in shot gather: t = tau - p * offset\n",
    "                    t = tau - p * offset\n",
    "                    t_idx = t / self.dt\n",
    "                    \n",
    "                    # Linear interpolation\n",
    "                    if 0 <= t_idx < nt - 1:\n",
    "                        idx_low = int(np.floor(t_idx))\n",
    "                        idx_high = idx_low + 1\n",
    "                        weight = t_idx - idx_low\n",
    "                        \n",
    "                        radon_domain[it, ip] += (1 - weight) * shot_gather[idx_low, ix] +                                                 weight * shot_gather[idx_high, ix]\n",
    "        \n",
    "        return radon_domain, p_values\n",
    "    \n",
    "    def radon_inverse_transform(self, radon_domain, p_values, offsets, nt):\n",
    "        \"\"\"Inverse Radon Transform (tau-p -> t-x) with linear interpolation\"\"\"\n",
    "        n_p = len(p_values)\n",
    "        n_traces = len(offsets)\n",
    "        result = np.zeros((nt, n_traces))\n",
    "        \n",
    "        # Inverse Radon Transform: data(t, x) = sum over p of radon(t + p*x, p)\n",
    "        for ix, offset in enumerate(offsets):\n",
    "            for it in range(nt):\n",
    "                t = self.time[it]\n",
    "                for ip, p in enumerate(p_values):\n",
    "                    # Tau in radon domain: tau = t + p * offset\n",
    "                    tau = t + p * offset\n",
    "                    tau_idx = tau / self.dt\n",
    "                    \n",
    "                    # Linear interpolation\n",
    "                    if 0 <= tau_idx < nt - 1:\n",
    "                        idx_low = int(np.floor(tau_idx))\n",
    "                        idx_high = idx_low + 1\n",
    "                        weight = tau_idx - idx_low\n",
    "                        \n",
    "                        result[it, ix] += (1 - weight) * radon_domain[idx_low, ip] +                                          weight * radon_domain[idx_high, ip]\n",
    "        \n",
    "        # Normalize by number of p values (simple adjoint)\n",
    "        result /= n_p\n",
    "        return result\n",
    "    \n",
    "    def radon_transform_demultiple(self, shot_gather, offsets, p_min=-0.001, p_max=0.001, n_p=128, threshold_percentile=75):\n",
    "        \"\"\"Radon Transform Í∏∞Î∞ò Demultiple (ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï Í∞ÄÎä•)\"\"\"\n",
    "        # Forward transform\n",
    "        radon_domain, p_values = self.radon_forward_transform(shot_gather, offsets, p_min, p_max, n_p)\n",
    "        \n",
    "        # Multiple ÏñµÏ†ú\n",
    "        threshold = np.percentile(np.abs(radon_domain), threshold_percentile)\n",
    "        mask = np.abs(radon_domain) > threshold\n",
    "        radon_filtered = radon_domain * mask\n",
    "        \n",
    "        # Inverse transform\n",
    "        result = self.radon_inverse_transform(radon_filtered, p_values, offsets, self.nt)\n",
    "        \n",
    "        return result, radon_domain, radon_filtered, p_values\n",
    "    \n",
    "    def anomalous_amplitude_attenuation(self, shot_gather, window_size=50, threshold_factor=3.0):\n",
    "        \"\"\"Anomalous Amplitude Attenuation (Ïù¥ÏÉÅ ÏßÑÌè≠ Í∞êÏá†)\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        \n",
    "        # Í∞Å Ìä∏Î†àÏù¥Ïä§Ïóê ÎåÄÌï¥\n",
    "        for ix in range(n_traces):\n",
    "            trace = shot_gather[:, ix]\n",
    "            \n",
    "            # Ïù¥Îèô ÏúàÎèÑÏö∞Î°ú Î°úÏª¨ ÌÜµÍ≥Ñ Í≥ÑÏÇ∞\n",
    "            for it in range(0, nt, window_size//2):\n",
    "                window_start = max(0, it - window_size//2)\n",
    "                window_end = min(nt, it + window_size//2)\n",
    "                window = trace[window_start:window_end]\n",
    "                \n",
    "                # Î°úÏª¨ ÌèâÍ∑† Î∞è ÌëúÏ§ÄÌé∏Ï∞®\n",
    "                local_mean = np.mean(window)\n",
    "                local_std = np.std(window)\n",
    "                \n",
    "                # Ïù¥ÏÉÅ ÏßÑÌè≠ ÌÉêÏßÄ Î∞è Í∞êÏá†\n",
    "                for i in range(window_start, window_end):\n",
    "                    if abs(trace[i] - local_mean) > threshold_factor * local_std:\n",
    "                        # Ïù¥ÏÉÅ ÏßÑÌè≠ÏùÑ Î°úÏª¨ ÌèâÍ∑†ÏúºÎ°ú ÎåÄÏ≤¥ (Î∂ÄÎìúÎüΩÍ≤å)\n",
    "                        excess = trace[i] - local_mean\n",
    "                        attenuation = np.exp(-abs(excess) / (threshold_factor * local_std))\n",
    "                        result[i, ix] = local_mean + excess * attenuation\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def curvelet_denoise(self, shot_gather, wavelet='db4', level=None, threshold_scale=1.5, return_coeffs=False):\n",
    "        \"\"\"Curvelet Í∏∞Î∞ò ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ (Wavelet Í∑ºÏÇ¨) - ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï Í∞ÄÎä•\"\"\"\n",
    "        result = np.zeros_like(shot_gather)\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        \n",
    "        # Í∞Å Ìä∏Î†àÏù¥Ïä§Ïóê Wavelet Denoising Ï†ÅÏö©\n",
    "        for ix in range(n_traces):\n",
    "            trace = shot_gather[:, ix]\n",
    "            \n",
    "            # Wavelet decomposition\n",
    "            if level is None:\n",
    "                level = pywt.dwt_max_level(len(trace), wavelet)\n",
    "            \n",
    "            coeffs = pywt.wavedec(trace, wavelet, level=level)\n",
    "            \n",
    "            # Threshold estimation (Donoho)\n",
    "            sigma = np.median(np.abs(coeffs[-1])) / 0.6745\n",
    "            threshold = threshold_scale * sigma * np.sqrt(2 * np.log(len(trace)))\n",
    "            \n",
    "            # Soft thresholding\n",
    "            coeffs_thresh = [coeffs[0]]  # approximation coefficients\n",
    "            for i in range(1, len(coeffs)):\n",
    "                coeffs_thresh.append(pywt.threshold(coeffs[i], threshold, mode='soft'))\n",
    "            \n",
    "            # Reconstruction\n",
    "            result[:, ix] = pywt.waverec(coeffs_thresh, wavelet)[:nt]\n",
    "        \n",
    "        # 2D Wavelet denoising (Î∞©Ìñ•ÏÑ± Í≥†Î†§)\n",
    "        coeffs2d_original = None\n",
    "        coeffs2d_thresh = None\n",
    "        threshold2d = 0.0  # Default value in case 2D transform fails\n",
    "        \n",
    "        try:\n",
    "            # 2D stationary wavelet transform\n",
    "            coeffs2d_original = pywt.swt2(shot_gather, wavelet, level=3)\n",
    "            \n",
    "            # Threshold\n",
    "            sigma2d = np.median(np.abs(coeffs2d_original[-1][1])) / 0.6745\n",
    "            threshold2d = threshold_scale * sigma2d * np.sqrt(2 * np.log(nt * n_traces))\n",
    "            \n",
    "            # Apply thresholding\n",
    "            coeffs2d_thresh = []\n",
    "            for c in coeffs2d_original:\n",
    "                cA = c[0]\n",
    "                cH = pywt.threshold(c[1][0], threshold2d, mode='soft')\n",
    "                cV = pywt.threshold(c[1][1], threshold2d, mode='soft')\n",
    "                cD = pywt.threshold(c[1][2], threshold2d, mode='soft')\n",
    "                coeffs2d_thresh.append((cA, (cH, cV, cD)))\n",
    "            \n",
    "            # Reconstruction\n",
    "            result = pywt.iswt2(coeffs2d_thresh, wavelet)[:nt, :n_traces]\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: 2D wavelet transform failed ({str(e)}), using 1D result\")\n",
    "        \n",
    "        if return_coeffs:\n",
    "            return result, coeffs2d_original, coeffs2d_thresh, threshold2d\n",
    "        else:\n",
    "            return result\n",
    "    \n",
    "    def plot_model(self, model: Dict):\n",
    "        \"\"\"ÏßÄÏ∏µ Î™®Îç∏ ÏãúÍ∞ÅÌôî\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 8))\n",
    "        \n",
    "        depths = model['depth']\n",
    "        velocities = model['velocity']\n",
    "        densities = model['density']\n",
    "        \n",
    "        for i in range(len(depths)):\n",
    "            depth_top = depths[i]\n",
    "            depth_bottom = depths[i] + model['thickness'][i]\n",
    "            \n",
    "            ax1.fill_between([velocities[i]-100, velocities[i]+100],\n",
    "                            depth_top, depth_bottom,\n",
    "                            alpha=0.4, label=model['name'][i] if i < 5 else None)\n",
    "            ax1.plot([velocities[i], velocities[i]], [depth_top, depth_bottom],\n",
    "                    'b-', linewidth=2.5)\n",
    "            \n",
    "            ax2.fill_between([densities[i]-50, densities[i]+50],\n",
    "                            depth_top, depth_bottom,\n",
    "                            alpha=0.4)\n",
    "            ax2.plot([densities[i], densities[i]], [depth_top, depth_bottom],\n",
    "                    'r-', linewidth=2.5)\n",
    "        \n",
    "        ax1.set_xlabel('Velocity (m/s)', fontsize=13, fontweight='bold')\n",
    "        ax1.set_ylabel('Depth (m)', fontsize=13, fontweight='bold')\n",
    "        ax1.set_title('Velocity Model', fontsize=15, fontweight='bold')\n",
    "        ax1.invert_yaxis()\n",
    "        ax1.grid(True, alpha=0.4)\n",
    "        ax1.legend(fontsize=10)\n",
    "        \n",
    "        ax2.set_xlabel('Density (kg/m¬≥)', fontsize=13, fontweight='bold')\n",
    "        ax2.set_ylabel('Depth (m)', fontsize=13, fontweight='bold')\n",
    "        ax2.set_title('Density Model', fontsize=15, fontweight='bold')\n",
    "        ax2.invert_yaxis()\n",
    "        ax2.grid(True, alpha=0.4)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_shot_gather(self, shot_gather, offsets, title: str = \"Shot Gather\", clip_percentile: float = 99):\n",
    "        \"\"\"Shot Gather ÏãúÍ∞ÅÌôî\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(14, 10))\n",
    "        vmax = np.percentile(np.abs(shot_gather), clip_percentile)\n",
    "        \n",
    "        for i, offset in enumerate(offsets):\n",
    "            trace = shot_gather[:, i]\n",
    "            trace_scaled = trace / vmax * 30\n",
    "            ax.plot(offset + trace_scaled, self.time, 'k-', linewidth=0.3)\n",
    "            ax.fill_betweenx(self.time, offset, offset + trace_scaled,\n",
    "                            where=(trace_scaled > 0), color='black', alpha=0.6)\n",
    "        \n",
    "        ax.set_xlabel('Offset (m)', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Time (s)', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(title, fontsize=15, fontweight='bold')\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax.set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_comparison_5(self, data1, data2, data3, data4, data5, offsets, titles):\n",
    "        \"\"\"5Í∞ú ÎπÑÍµê\"\"\"\n",
    "        fig, axes = plt.subplots(1, 5, figsize=(28, 10))\n",
    "        data_list = [data1, data2, data3, data4, data5]\n",
    "        vmax = np.percentile(np.abs(data1), 99)\n",
    "        \n",
    "        for ax, data, title in zip(axes, data_list, titles):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                trace = data[:, i]\n",
    "                trace_scaled = trace / vmax * 30\n",
    "                ax.plot(offset + trace_scaled, self.time, 'k-', linewidth=0.3)\n",
    "                ax.fill_betweenx(self.time, offset, offset + trace_scaled,\n",
    "                                where=(trace_scaled > 0), color='black', alpha=0.6)\n",
    "            \n",
    "            ax.set_xlabel('Offset (m)', fontsize=10, fontweight='bold')\n",
    "            ax.set_ylabel('Time (s)', fontsize=10, fontweight='bold')\n",
    "            ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "            ax.invert_yaxis()\n",
    "            ax.grid(True, alpha=0.3, linestyle='--')\n",
    "            ax.set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"‚úÖ AdvancedMarineProcessor ÌÅ¥ÎûòÏä§ Ï†ïÏùò ÏôÑÎ£å!\")\n",
    "print(\"\\n‚≠ê Í≥†Í∏â Ï≤òÎ¶¨ Í∏∞Î≤ï:\")\n",
    "print(\"  1. Water Bottom Demultiple\")\n",
    "print(\"  2. Radon Transform Demultiple\")\n",
    "print(\"  3. Anomalous Amplitude Attenuation\")\n",
    "print(\"  4. Curvelet Denoise\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step2"
   },
   "source": [
    "## üåç Step 2: ÎûúÎç§ Ìï©ÏÑ± Î™®Îç∏ ÏÉùÏÑ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_model"
   },
   "outputs": [],
   "source": [
    "processor = AdvancedMarineProcessor(dt=0.002, nt=1500)\n",
    "print(\"‚úÖ Í≥†Í∏â ÌîÑÎ°úÏÑ∏ÏÑú Ï¥àÍ∏∞Ìôî ÏôÑÎ£å\")\n",
    "print(f\"   - ÏÉòÌîåÎßÅ Í∞ÑÍ≤©: {processor.dt*1000:.1f} ms\")\n",
    "print(f\"   - ÏãúÍ∞Ñ ÏÉòÌîå: {processor.nt}Í∞ú\")\n",
    "print(f\"   - Ï¥ù ÏãúÍ∞Ñ: {processor.time[-1]:.2f} s\")\n",
    "print()\n",
    "\n",
    "print(\"üåç ÎûúÎç§ Ìï©ÏÑ± ÏßÄÎ∞ò Î™®Îç∏ ÏÉùÏÑ± Ï§ë...\")\n",
    "model = processor.create_random_model(nlayers=6)\n",
    "print(\"‚úÖ Î™®Îç∏ ÏÉùÏÑ± ÏôÑÎ£å!\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä ÏÉùÏÑ±Îêú ÏßÄÏ∏µ Ï†ïÎ≥¥\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Layer':<15} {'Depth (m)':<12} {'Thickness (m)':<15} {'Velocity (m/s)':<15} {'Density (kg/m¬≥)'}\")\n",
    "print(\"-\"*80)\n",
    "for i in range(len(model['name'])):\n",
    "    print(f\"{model['name'][i]:<15} {model['depth'][i]:<12.1f} {model['thickness'][i]:<15.1f} \"\n",
    "          f\"{model['velocity'][i]:<15.1f} {model['density'][i]:<15.1f}\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "processor.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step3"
   },
   "source": [
    "## üéØ Step 3-6: Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ± (Clean ‚Üí Direct ‚Üí Multiples ‚Üí Noise)\n",
    "\n",
    "**Ìïú Î≤àÏóê Ïã§ÌñâÌïòÏó¨ Í∏∞Î≥∏ Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate_data"
   },
   "outputs": [],
   "source": [
    "print(\"üéØ Shot Gather ÏÉùÏÑ± ÌååÏù¥ÌîÑÎùºÏù∏...\")\n",
    "print()\n",
    "\n",
    "# Í∏∞Î≥∏ ÌååÎùºÎØ∏ÌÑ∞\n",
    "n_traces = 48\n",
    "offset_min = 100\n",
    "offset_max = 2400\n",
    "freq = 25.0\n",
    "\n",
    "# Step 3: Clean Shot Gather\n",
    "print(\"[1/4] Clean Shot Gather ÏÉùÏÑ±...\")\n",
    "clean_shot, offsets = processor.generate_shot_gather(model, n_traces=n_traces, \n",
    "                                                      offset_min=offset_min, \n",
    "                                                      offset_max=offset_max, freq=freq)\n",
    "print(f\"   ‚úÖ RMS: {np.sqrt(np.mean(clean_shot**2)):.6f}\")\n",
    "\n",
    "# Step 4: ÏßÅÏ†ëÌåå Ï∂îÍ∞Ä\n",
    "print(\"[2/4] ÏßÅÏ†ëÌåå Ï∂îÍ∞Ä...\")\n",
    "with_direct = processor.add_direct_wave(clean_shot, offsets, model, strength=0.3)\n",
    "print(f\"   ‚úÖ RMS: {np.sqrt(np.mean(with_direct**2)):.6f}\")\n",
    "\n",
    "# Step 5: Multiple Ï∂îÍ∞Ä\n",
    "print(\"[3/4] Multiple Ï∂îÍ∞Ä (Ìï¥Î©¥ + ÎÇ¥Î∂Ä)...\")\n",
    "with_sea_mult = processor.add_sea_surface_multiple(with_direct, model, strength=0.5)\n",
    "with_multiples = processor.add_internal_multiples(with_sea_mult, model, strength=0.3)\n",
    "print(f\"   ‚úÖ RMS: {np.sqrt(np.mean(with_multiples**2)):.6f}\")\n",
    "\n",
    "# Step 6: Ìï¥ÏÉÅ ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä\n",
    "print(\"[4/4] Ìï¥ÏÉÅ ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä...\")\n",
    "noisy_shot = processor.add_marine_noise(with_multiples, offsets, noise_level=0.10)\n",
    "print(f\"   ‚úÖ RMS: {np.sqrt(np.mean(noisy_shot**2)):.6f}\")\n",
    "print()\n",
    "\n",
    "# ÌÜµÍ≥Ñ\n",
    "noise = noisy_shot - with_multiples\n",
    "snr_initial = 20 * np.log10(np.std(with_multiples) / np.std(noise))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä Ï¥àÍ∏∞ Îç∞Ïù¥ÌÑ∞ ÌÜµÍ≥Ñ\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Signal RMS (Multiples):  {np.sqrt(np.mean(with_multiples**2)):.6f}\")\n",
    "print(f\"Noisy RMS:               {np.sqrt(np.mean(noisy_shot**2)):.6f}\")\n",
    "print(f\"SNR:                     {snr_initial:.2f} dB\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî\n",
    "print(\"üìà ÎÖ∏Ïù¥Ï¶àÍ∞Ä Ï∂îÍ∞ÄÎêú Shot Gather ÏãúÍ∞ÅÌôî...\")\n",
    "processor.plot_shot_gather(noisy_shot, offsets, \"üì¢ Noisy Shot Gather (Input)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step9"
   },
   "source": [
    "## ‚ö° Step 7: Anomalous Amplitude Attenuation\n",
    "\n",
    "**Ïù¥ ÏÖÄÏùÑ Ïã§ÌñâÌïòÎ©¥:**\n",
    "- Ïù¥Îèô ÏúàÎèÑÏö∞Î°ú Î°úÏª¨ ÌÜµÍ≥Ñ Í≥ÑÏÇ∞\n",
    "- Ïù¥ÏÉÅ ÏßÑÌè≠ ÌÉêÏßÄ (ÏûÑÍ≥ÑÍ∞í Ï¥àÍ≥º)\n",
    "- ÏßÄÏàò Í∞êÏá†Î°ú Î∂ÄÎìúÎüΩÍ≤å ÏñµÏ†ú\n",
    "- Ï¶âÏãú ÏãúÍ∞ÅÌôî"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aaa"
   },
   "outputs": [],
   "source": [
    "print(\"‚ö° Anomalous Amplitude Attenuation Ï†ÅÏö© Ï§ë...\")\n",
    "print()\n",
    "print(\"Ï≤òÎ¶¨ Î∞©Î≤ï:\")\n",
    "print(\"   - Ïù¥Îèô ÏúàÎèÑÏö∞ ÌÜµÍ≥Ñ (ÌèâÍ∑†, ÌëúÏ§ÄÌé∏Ï∞®)\")\n",
    "print(\"   - Ïù¥ÏÉÅ ÏßÑÌè≠ ÌÉêÏßÄ (> 3œÉ)\")\n",
    "print(\"   - ÏßÄÏàò Í∞êÏá† Ï†ÅÏö©\")\n",
    "print()\n",
    "\n",
    "# Anomalous Amplitude Attenuation\n",
    "after_aaa = processor.anomalous_amplitude_attenuation(noisy_shot, \n",
    "                                                       window_size=50, \n",
    "                                                       threshold_factor=3.0)\n",
    "\n",
    "print(\"‚úÖ Anomalous Amplitude Attenuation ÏôÑÎ£å!\")\n",
    "print()\n",
    "\n",
    "# ÌÜµÍ≥Ñ\n",
    "removed_anom = noisy_shot - after_aaa\n",
    "\n",
    "print(\"üìà ÌÜµÍ≥Ñ:\")\n",
    "print(f\"   - Before AAA RMS: {np.sqrt(np.mean(noisy_shot**2)):.6f}\")\n",
    "print(f\"   - After AAA RMS:  {np.sqrt(np.mean(after_aaa**2)):.6f}\")\n",
    "print(f\"   - Attenuated RMS: {np.sqrt(np.mean(removed_anom**2)):.6f}\")\n",
    "print(f\"   - Anomaly Reduction: {(np.sqrt(np.mean(removed_anom**2))/np.sqrt(np.mean(noisy_shot**2)))*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî\n",
    "print(\"üìà Anomalous Amplitude Attenuation Í≤∞Í≥º ÏãúÍ∞ÅÌôî...\")\n",
    "processor.plot_shot_gather(after_aaa, offsets, \"‚ö° After Anomalous Amplitude Attenuation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step8"
   },
   "source": [
    "## üîä Step 8: Low-cut Filter (1.5 Hz)\n",
    "\n",
    "**Ïù¥ ÏÖÄÏùÑ Ïã§ÌñâÌïòÎ©¥:**\n",
    "- High-pass (Low-cut) ÌïÑÌÑ∞ Ï†ÅÏö©\n",
    "- 1.5 Hz Ïù¥Ìïò Ï†ÄÏ£ºÌåå ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞\n",
    "- Swell noise, Ship noise Ï†ÄÏ£ºÌåå ÏÑ±Î∂Ñ Ï†úÍ±∞\n",
    "- **ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï**: `cutoff_freq`, `filter_order`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lowcut"
   },
   "outputs": [],
   "source": [
    "print(\"üîä Low-cut Filter Ï†ÅÏö© Ï§ë...\")\n",
    "print()\n",
    "print(\"Ï≤òÎ¶¨ Î∞©Î≤ï:\")\n",
    "print(\"   - Butterworth High-pass Filter\")\n",
    "print(\"   - Ï†ÄÏ£ºÌåå ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ (Swell, Ship)\")\n",
    "print(\"   - Zero-phase filtering (filtfilt)\")\n",
    "print()\n",
    "print(\"‚öôÔ∏è ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï Í∞ÄÎä•:\")\n",
    "print(\"   - cutoff_freq: Cutoff Ï£ºÌååÏàò (Í∏∞Î≥∏ 1.5 Hz)\")\n",
    "print(\"   - filter_order: ÌïÑÌÑ∞ Ï∞®Ïàò (Í∏∞Î≥∏ 5)\")\n",
    "print()\n",
    "\n",
    "# üîß Ïó¨Í∏∞ÏÑú ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï!\n",
    "cutoff_freq = 1.5  # Hz, Ïù¥ Ï£ºÌååÏàò Ïù¥ÌïòÎ•º Ï†úÍ±∞ (Ïòà: 1.0, 1.5, 2.0, 3.0)\n",
    "filter_order = 5   # ÌïÑÌÑ∞ Ï∞®Ïàò, ÎÜíÏùÑÏàòÎ°ù sharp (Ïòà: 3, 5, 7)\n",
    "\n",
    "print(f\"\\nüìå ÌòÑÏû¨ ÌååÎùºÎØ∏ÌÑ∞:\")\n",
    "print(f\"   - Cutoff Frequency: {cutoff_freq} Hz\")\n",
    "print(f\"   - Filter Order: {filter_order}\")\n",
    "print()\n",
    "\n",
    "# Low-cut Filter\n",
    "after_lowcut = processor.lowcut_filter(after_aaa, cutoff_freq=cutoff_freq, order=filter_order)\n",
    "\n",
    "print(\"‚úÖ Low-cut Filter ÏôÑÎ£å!\")\n",
    "print()\n",
    "\n",
    "# ÌÜµÍ≥Ñ\n",
    "removed_lowfreq = after_aaa - after_lowcut\n",
    "\n",
    "print(\"üìà ÌÜµÍ≥Ñ:\")\n",
    "print(f\"   - Before Lowcut RMS: {np.sqrt(np.mean(after_aaa**2)):.6f}\")\n",
    "print(f\"   - After Lowcut RMS:  {np.sqrt(np.mean(after_lowcut**2)):.6f}\")\n",
    "print(f\"   - Removed Low-freq RMS: {np.sqrt(np.mean(removed_lowfreq**2)):.6f}\")\n",
    "print(f\"   - Energy Reduction: {(np.sqrt(np.mean(removed_lowfreq**2))/np.sqrt(np.mean(after_aaa**2)))*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# Ï£ºÌååÏàò Ïä§ÌéôÌä∏Îüº ÎπÑÍµê\n",
    "print(\"üìä Ï£ºÌååÏàò Ïä§ÌéôÌä∏Îüº ÎπÑÍµê...\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Before lowcut - frequency spectrum\n",
    "trace_before = after_aaa[:, after_aaa.shape[1]//2]  # Middle trace\n",
    "fft_before = np.fft.rfft(trace_before)\n",
    "freq = np.fft.rfftfreq(len(trace_before), processor.dt)\n",
    "power_before = np.abs(fft_before)**2\n",
    "\n",
    "# After lowcut - frequency spectrum\n",
    "trace_after = after_lowcut[:, after_lowcut.shape[1]//2]\n",
    "fft_after = np.fft.rfft(trace_after)\n",
    "power_after = np.abs(fft_after)**2\n",
    "\n",
    "axes[0].semilogy(freq, power_before, \"b-\", label=\"Before Lowcut\", linewidth=1.5, alpha=0.7)\n",
    "axes[0].semilogy(freq, power_after, \"r-\", label=\"After Lowcut\", linewidth=1.5, alpha=0.7)\n",
    "axes[0].axvline(cutoff_freq, color=\"green\", linestyle=\"--\", linewidth=2, label=f\"Cutoff ({cutoff_freq} Hz)\")\n",
    "axes[0].set_xlabel(\"Frequency (Hz)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0].set_ylabel(\"Power\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0].set_title(\"Frequency Spectrum (Ï§ëÏïô Ìä∏Î†àÏù¥Ïä§)\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0].set_xlim([0, 100])\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend(fontsize=11)\n",
    "\n",
    "# Shot gather comparison\n",
    "for i, offset in enumerate(offsets):\n",
    "    trace = after_lowcut[:, i]\n",
    "    vmax = np.percentile(np.abs(after_lowcut), 99)\n",
    "    trace_scaled = trace / vmax * 30\n",
    "    axes[1].plot(offset + trace_scaled, processor.time, \"k-\", linewidth=0.3)\n",
    "    axes[1].fill_betweenx(processor.time, offset, offset + trace_scaled,\n",
    "                         where=(trace_scaled > 0), color=\"black\", alpha=0.6)\n",
    "\n",
    "axes[1].set_xlabel(\"Offset (m)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1].set_ylabel(\"Time (s)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1].set_title(\"After Low-cut Filter\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(True, alpha=0.3, linestyle=\"--\")\n",
    "axes[1].set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"üí° Ìï¥ÏÑù:\")\n",
    "print(\"   - Ï¢åÏ∏°: 1.5 Hz Ïù¥Ìïò Ï†ÄÏ£ºÌååÍ∞Ä Ï†úÍ±∞ÎêòÏóàÏùåÏùÑ ÌôïÏù∏\")\n",
    "print(\"   - Ïö∞Ï∏°: Swell noise, Ship noise Ï†ÄÏ£ºÌåå ÏÑ±Î∂Ñ Í∞êÏÜå\")\n",
    "print()\n",
    "print(\"üîß ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï Î∞©Î≤ï:\")\n",
    "print(\"   - cutoff_freq ‚Üë ‚Üí Îçî ÎßéÏùÄ Ï†ÄÏ£ºÌåå Ï†úÍ±∞ (Îã®, Ïã†Ìò∏ Ï†ÄÏ£ºÌååÎèÑ ÏÜêÏã§)\")\n",
    "print(\"   - cutoff_freq ‚Üì ‚Üí Ïã†Ìò∏ Î≥¥Ï°¥ Ïö∞ÏÑ† (Ï†ÄÏ£ºÌåå ÎÖ∏Ïù¥Ï¶à ÏûîÏ°¥)\")\n",
    "print(\"   - Í∂åÏû•Í∞í: 1.0 ~ 3.0 Hz Î≤îÏúÑ\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step10"
   },
   "source": [
    "## üåÄ Step 9: Curvelet Denoise (Ïù∏ÌÑ∞ÎûôÌã∞Î∏å)\n",
    "\n",
    "**Ïù¥ ÏÖÄÏùÑ Ïã§ÌñâÌïòÎ©¥:**\n",
    "- 1D Wavelet Î∂ÑÌï¥ (Í∞Å Ìä∏Î†àÏù¥Ïä§)\n",
    "- 2D Stationary Wavelet Transform (Î∞©Ìñ•ÏÑ± Í≥†Î†§)\n",
    "- **Wavelet Í≥ÑÏàò ÏãúÍ∞ÅÌôî** (ÏõêÎ≥∏ + Thresholding)\n",
    "- Soft thresholding\n",
    "- Wavelet Ïû¨Íµ¨ÏÑ±\n",
    "- **ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï**: `threshold_scale`, `wavelet`, `level`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "curvelet"
   },
   "outputs": [],
   "source": [
    "print(\"üåÄ Curvelet Denoise Ï†ÅÏö© Ï§ë...\")\n",
    "print()\n",
    "print(\"Ï≤òÎ¶¨ Î∞©Î≤ï:\")\n",
    "print(\"   - 1D Wavelet Î∂ÑÌï¥ (Í∞Å Ìä∏Î†àÏù¥Ïä§)\")\n",
    "print(\"   - 2D Stationary Wavelet Transform\")\n",
    "print(\"   - Soft thresholding (Donoho)\")\n",
    "print(\"   - Wavelet Ïû¨Íµ¨ÏÑ±\")\n",
    "print()\n",
    "print(\"‚öôÔ∏è ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï Í∞ÄÎä•:\")\n",
    "print(\"   - threshold_scale: Threshold Ïä§ÏºÄÏùºÎßÅ (Í∏∞Î≥∏ 1.5)\")\n",
    "print(\"   - wavelet: Wavelet Ï¢ÖÎ•ò (db4, sym4, coif2 Îì±)\")\n",
    "print(\"   - level: Î∂ÑÌï¥ Î†àÎ≤® (None=ÏûêÎèô)\")\n",
    "print()\n",
    "print(\"‚è≥ Ï≤òÎ¶¨ Ï§ë... (ÏãúÍ∞ÑÏù¥ Í±∏Î¶¥ Ïàò ÏûàÏäµÎãàÎã§)\")\n",
    "\n",
    "# üîß Ïó¨Í∏∞ÏÑú ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï!\n",
    "threshold_scale = 1.5  # ÎÇÆÏ∂îÎ©¥ Îçî ÎßéÏù¥ Ï†úÍ±∞ (Ïòà: 0.5, 1.0, 1.5, 2.0, 2.5)\n",
    "wavelet_type = 'db4'   # 'db4', 'sym4', 'coif2', 'bior2.2' Îì±\n",
    "level = None           # None=ÏûêÎèô, ÎòêÎäî Ï†ïÏàò (Ïòà: 3, 4, 5)\n",
    "\n",
    "print(f\"\\nüìå ÌòÑÏû¨ ÌååÎùºÎØ∏ÌÑ∞:\")\n",
    "print(f\"   - Threshold Scale: {threshold_scale}\")\n",
    "print(f\"   - Wavelet Type: {wavelet_type}\")\n",
    "print(f\"   - Decomposition Level: {level if level else 'Auto'}\")\n",
    "print()\n",
    "\n",
    "# Curvelet Denoise (Í≥ÑÏàò Î∞òÌôò)\n",
    "final_shot, coeffs_original, coeffs_thresh, threshold_value = processor.curvelet_denoise(\n",
    "    after_lowcut, \n",
    "    wavelet=wavelet_type, \n",
    "    level=level, \n",
    "    threshold_scale=threshold_scale,\n",
    "    return_coeffs=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Curvelet Denoise ÏôÑÎ£å!\")\n",
    "print()\n",
    "\n",
    "# ÏµúÏ¢Ö ÌÜµÍ≥Ñ\n",
    "removed_noise = after_lowcut - final_shot\n",
    "final_residual = final_shot - with_direct\n",
    "snr_final = 20 * np.log10(np.std(with_direct) / np.std(final_residual))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä ÏµúÏ¢Ö Í≤∞Í≥º\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Before Curvelet RMS:    {np.sqrt(np.mean(after_lowcut**2)):.6f}\")\n",
    "print(f\"Final RMS:              {np.sqrt(np.mean(final_shot**2)):.6f}\")\n",
    "print(f\"Removed Noise RMS:      {np.sqrt(np.mean(removed_noise**2)):.6f}\")\n",
    "print(f\"Threshold Value:        {threshold_value:.6f}\")\n",
    "print()\n",
    "print(f\"SNR (Ï¥àÍ∏∞):              {snr_initial:.2f} dB\")\n",
    "print(f\"SNR (ÏµúÏ¢Ö):              {snr_final:.2f} dB\")\n",
    "print(f\"SNR Í∞úÏÑ†:                {snr_final - snr_initial:.2f} dB  ‚¨ÜÔ∏è‚¨ÜÔ∏è‚¨ÜÔ∏è\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# üé® Wavelet Í≥ÑÏàò ÏãúÍ∞ÅÌôî\n",
    "if coeffs_original is not None and coeffs_thresh is not None:\n",
    "    print(\"üìä Wavelet Í≥ÑÏàò ÏãúÍ∞ÅÌôî (Level 3, Horizontal/Vertical/Diagonal)...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Level 3 Í≥ÑÏàò Ï∂îÏ∂ú\n",
    "    level_idx = -1  # ÎßàÏßÄÎßâ Î†àÎ≤®\n",
    "    cH_orig = coeffs_original[level_idx][1][0]  # Horizontal\n",
    "    cV_orig = coeffs_original[level_idx][1][1]  # Vertical\n",
    "    cD_orig = coeffs_original[level_idx][1][2]  # Diagonal\n",
    "    \n",
    "    cH_thresh = coeffs_thresh[level_idx][1][0]\n",
    "    cV_thresh = coeffs_thresh[level_idx][1][1]\n",
    "    cD_thresh = coeffs_thresh[level_idx][1][2]\n",
    "    \n",
    "    vmax = np.percentile(np.abs(cH_orig), 99)\n",
    "    \n",
    "    # Original coefficients\n",
    "    im1 = axes[0, 0].imshow(cH_orig, aspect='auto', cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    axes[0, 0].set_title('Original - Horizontal (cH)', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Time', fontsize=11)\n",
    "    axes[0, 0].set_xlabel('Trace', fontsize=11)\n",
    "    plt.colorbar(im1, ax=axes[0, 0])\n",
    "    \n",
    "    im2 = axes[0, 1].imshow(cV_orig, aspect='auto', cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    axes[0, 1].set_title('Original - Vertical (cV)', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Time', fontsize=11)\n",
    "    axes[0, 1].set_xlabel('Trace', fontsize=11)\n",
    "    plt.colorbar(im2, ax=axes[0, 1])\n",
    "    \n",
    "    im3 = axes[0, 2].imshow(cD_orig, aspect='auto', cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    axes[0, 2].set_title('Original - Diagonal (cD)', fontsize=12, fontweight='bold')\n",
    "    axes[0, 2].set_ylabel('Time', fontsize=11)\n",
    "    axes[0, 2].set_xlabel('Trace', fontsize=11)\n",
    "    plt.colorbar(im3, ax=axes[0, 2])\n",
    "    \n",
    "    # Thresholded coefficients\n",
    "    im4 = axes[1, 0].imshow(cH_thresh, aspect='auto', cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    axes[1, 0].set_title(f'Thresholded - Horizontal (scale={threshold_scale})', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('Time', fontsize=11)\n",
    "    axes[1, 0].set_xlabel('Trace', fontsize=11)\n",
    "    plt.colorbar(im4, ax=axes[1, 0])\n",
    "    \n",
    "    im5 = axes[1, 1].imshow(cV_thresh, aspect='auto', cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    axes[1, 1].set_title(f'Thresholded - Vertical (scale={threshold_scale})', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('Time', fontsize=11)\n",
    "    axes[1, 1].set_xlabel('Trace', fontsize=11)\n",
    "    plt.colorbar(im5, ax=axes[1, 1])\n",
    "    \n",
    "    im6 = axes[1, 2].imshow(cD_thresh, aspect='auto', cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    axes[1, 2].set_title(f'Thresholded - Diagonal (scale={threshold_scale})', fontsize=12, fontweight='bold')\n",
    "    axes[1, 2].set_ylabel('Time', fontsize=11)\n",
    "    axes[1, 2].set_xlabel('Trace', fontsize=11)\n",
    "    plt.colorbar(im6, ax=axes[1, 2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print()\n",
    "    print(\"üí° Wavelet Í≥ÑÏàò Ìï¥ÏÑù:\")\n",
    "    print(\"   - Horizontal (cH): ÏàòÌèâ Î∞©Ìñ• Í≥†Ï£ºÌåå (Ï∏µÍ≤ΩÍ≥Ñ)\")\n",
    "    print(\"   - Vertical (cV): ÏàòÏßÅ Î∞©Ìñ• Í≥†Ï£ºÌåå (Ìä∏Î†àÏù¥Ïä§ Í∞Ñ Î≥ÄÌôî)\")\n",
    "    print(\"   - Diagonal (cD): ÎåÄÍ∞ÅÏÑ† Î∞©Ìñ• Í≥†Ï£ºÌåå (Î≥µÌï© ÎÖ∏Ïù¥Ï¶à)\")\n",
    "    print(\"   - Thresholding ÌõÑ: ÏïΩÌïú Í≥ÑÏàò Ï†úÍ±∞ ‚Üí ÎÖ∏Ïù¥Ï¶à Í∞êÏÜå\")\n",
    "    print()\n",
    "    print(\"üîß ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï Î∞©Î≤ï:\")\n",
    "    print(\"   - threshold_scale ‚Üì ‚Üí Îçî ÎßéÏùÄ ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ (Îã®, Ïã†Ìò∏ ÏÜêÏã§ Ï£ºÏùò)\")\n",
    "    print(\"   - threshold_scale ‚Üë ‚Üí Ïã†Ìò∏ Î≥¥Ï°¥ Ïö∞ÏÑ† (ÎÖ∏Ïù¥Ï¶à ÏûîÏ°¥ Í∞ÄÎä•)\")\n",
    "    print(\"   - Í∂åÏû•Í∞í: 0.5 ~ 2.5 Î≤îÏúÑÏóêÏÑú Ï°∞Ï†ï\")\n",
    "    print()\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî\n",
    "print(\"üìà ÏµúÏ¢Ö Í≤∞Í≥º ÏãúÍ∞ÅÌôî...\")\n",
    "processor.plot_shot_gather(final_shot, offsets, \"üåÄ Final: After Curvelet Denoise\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step10"
   },
   "source": [
    "## üéØ Step 10: ÏßÅÏ†ëÌåå Ï†úÍ±∞ (Direct Wave Mute)\n",
    "\n",
    "**Ïù¥ ÏÖÄÏùÑ Ïã§ÌñâÌïòÎ©¥:**\n",
    "- Top Mute Ï†ÅÏö©ÌïòÏó¨ ÏßÅÏ†ëÌåå Ï†úÍ±∞\n",
    "- Mute velocity Ïù¥ÏÉÅÏùò Ïù¥Î≤§Ìä∏ Ï†úÍ±∞ (ÏùºÎ∞òÏ†ÅÏúºÎ°ú ~1500 m/s)\n",
    "- Cosine taperÎ°ú Î∂ÄÎìúÎü¨Ïö¥ Ï†ÑÌôò\n",
    "- **ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï**: `mute_velocity`, `taper_length`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "direct_wave_mute"
   },
   "outputs": [],
   "source": [
    "print(\"üéØ ÏßÅÏ†ëÌåå Ï†úÍ±∞ (Direct Wave Mute) Ï†ÅÏö© Ï§ë...\")\n",
    "print()\n",
    "print(\"Ï≤òÎ¶¨ Î∞©Î≤ï:\")\n",
    "print(\"   - Top Mute: ÏßÅÏ†ëÌåå ÎèÑÎã¨ ÏãúÍ∞Ñ Ïù¥Ï†Ñ Ï†úÍ±∞\")\n",
    "print(\"   - Mute line: t_mute = offset / mute_velocity\")\n",
    "print(\"   - Cosine taperÎ°ú Î∂ÄÎìúÎü¨Ïö¥ Ï†ÑÌôò\")\n",
    "print()\n",
    "print(\"‚öôÔ∏è ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï Í∞ÄÎä•:\")\n",
    "print(\"   - mute_velocity: Mute ÏÜçÎèÑ (Í∏∞Î≥∏ 1500 m/s)\")\n",
    "print(\"   - taper_length: Taper Í∏∏Ïù¥ (ÏÉòÌîå Ïàò, Í∏∞Î≥∏ 50)\")\n",
    "print()\n",
    "\n",
    "# üîß Ïó¨Í∏∞ÏÑú ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï!\n",
    "mute_velocity = 1500  # m/s, Ïù¥ ÏÜçÎèÑ Ïù¥ÏÉÅÏùÑ Ï†úÍ±∞ (Ïòà: 1400, 1500, 1600)\n",
    "taper_length = 50     # samples, taper Íµ¨Í∞Ñ Í∏∏Ïù¥ (Ïòà: 30, 50, 100)\n",
    "\n",
    "print(f\"\\nüìå ÌòÑÏû¨ ÌååÎùºÎØ∏ÌÑ∞:\")\n",
    "print(f\"   - Mute Velocity: {mute_velocity} m/s\")\n",
    "print(f\"   - Taper Length: {taper_length} samples ({taper_length * processor.dt:.3f} s)\")\n",
    "print()\n",
    "\n",
    "# Direct Wave Removal\n",
    "after_direct_mute = processor.remove_direct_wave(final_shot, offsets, model, \n",
    "                                                   mute_velocity=mute_velocity, \n",
    "                                                   taper_length=taper_length)\n",
    "\n",
    "print(\"‚úÖ ÏßÅÏ†ëÌåå Ï†úÍ±∞ ÏôÑÎ£å!\")\n",
    "print()\n",
    "\n",
    "# ÌÜµÍ≥Ñ\n",
    "removed_direct = final_shot - after_direct_mute\n",
    "\n",
    "print(\"üìà ÌÜµÍ≥Ñ:\")\n",
    "print(f\"   - Before Direct Mute RMS: {np.sqrt(np.mean(final_shot**2)):.6f}\")\n",
    "print(f\"   - After Direct Mute RMS:  {np.sqrt(np.mean(after_direct_mute**2)):.6f}\")\n",
    "print(f\"   - Removed Direct Wave RMS: {np.sqrt(np.mean(removed_direct**2)):.6f}\")\n",
    "print(f\"   - Energy Reduction: {(np.sqrt(np.mean(removed_direct**2))/np.sqrt(np.mean(final_shot**2)))*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî - Before/After ÎπÑÍµê\n",
    "print(\"üìä ÏßÅÏ†ëÌåå Ï†úÍ±∞ Ï†ÑÌõÑ ÎπÑÍµê...\")\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "vmax = np.percentile(np.abs(final_shot), 99)\n",
    "\n",
    "# Before\n",
    "for i, offset in enumerate(offsets):\n",
    "    trace = final_shot[:, i]\n",
    "    trace_scaled = trace / vmax * 30\n",
    "    axes[0].plot(offset + trace_scaled, processor.time, \"k-\", linewidth=0.3)\n",
    "    axes[0].fill_betweenx(processor.time, offset, offset + trace_scaled,\n",
    "                         where=(trace_scaled > 0), color=\"black\", alpha=0.6)\n",
    "    # Mute line\n",
    "    mute_time = offset / mute_velocity\n",
    "    axes[0].plot([offset-30, offset+30], [mute_time, mute_time], \"r-\", linewidth=2, alpha=0.7)\n",
    "\n",
    "axes[0].set_xlabel(\"Offset (m)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0].set_ylabel(\"Time (s)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0].set_title(\"Before Direct Wave Mute\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(True, alpha=0.3, linestyle=\"--\")\n",
    "axes[0].set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "\n",
    "# After\n",
    "for i, offset in enumerate(offsets):\n",
    "    trace = after_direct_mute[:, i]\n",
    "    trace_scaled = trace / vmax * 30\n",
    "    axes[1].plot(offset + trace_scaled, processor.time, \"k-\", linewidth=0.3)\n",
    "    axes[1].fill_betweenx(processor.time, offset, offset + trace_scaled,\n",
    "                         where=(trace_scaled > 0), color=\"black\", alpha=0.6)\n",
    "\n",
    "axes[1].set_xlabel(\"Offset (m)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1].set_ylabel(\"Time (s)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1].set_title(\"After Direct Wave Mute\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(True, alpha=0.3, linestyle=\"--\")\n",
    "axes[1].set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "\n",
    "# Removed\n",
    "for i, offset in enumerate(offsets):\n",
    "    trace = removed_direct[:, i]\n",
    "    trace_scaled = trace / vmax * 30\n",
    "    axes[2].plot(offset + trace_scaled, processor.time, \"k-\", linewidth=0.3)\n",
    "    axes[2].fill_betweenx(processor.time, offset, offset + trace_scaled,\n",
    "                         where=(trace_scaled > 0), color=\"black\", alpha=0.6)\n",
    "\n",
    "axes[2].set_xlabel(\"Offset (m)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[2].set_ylabel(\"Time (s)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[2].set_title(\"Removed Direct Wave\", fontsize=14, fontweight=\"bold\")\n",
    "axes[2].invert_yaxis()\n",
    "axes[2].grid(True, alpha=0.3, linestyle=\"--\")\n",
    "axes[2].set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"üí° Ìï¥ÏÑù:\")\n",
    "print(\"   - Ï¢åÏ∏°: ÏßÅÏ†ëÌååÍ∞Ä ÏÑ†Ìòï moveoutÏúºÎ°ú Î≥¥ÏûÑ (Îπ®Í∞Ñ ÏÑ†Ïù¥ mute line)\")\n",
    "print(\"   - Ï§ëÏïô: ÏßÅÏ†ëÌååÍ∞Ä Ï†úÍ±∞ÎêòÍ≥† Î∞òÏÇ¨ÌååÎßå ÎÇ®Ïùå\")\n",
    "print(\"   - Ïö∞Ï∏°: Ï†úÍ±∞Îêú ÏßÅÏ†ëÌåå ÌôïÏù∏\")\n",
    "print()\n",
    "print(\"üîß ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï Î∞©Î≤ï:\")\n",
    "print(\"   - mute_velocity ‚Üì ‚Üí Îçî ÎßéÏù¥ Ï†úÍ±∞ (Îã®, ÏñïÏùÄ Î∞òÏÇ¨Ìåå ÏÜêÏã§ Ï£ºÏùò)\")\n",
    "print(\"   - mute_velocity ‚Üë ‚Üí Î≥¥ÏàòÏ†Å Ï†úÍ±∞ (ÏßÅÏ†ëÌåå ÏûîÏ°¥ Í∞ÄÎä•)\")\n",
    "print(\"   - taper_length ‚Üë ‚Üí Î∂ÄÎìúÎü¨Ïö¥ Ï†ÑÌôò (artifacts Í∞êÏÜå)\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step7"
   },
   "source": [
    "## üåä Step 11: Water Bottom Demultiple\n",
    "\n",
    "**Ïù¥ ÏÖÄÏùÑ Ïã§ÌñâÌïòÎ©¥:**\n",
    "- Ìï¥Ï†ÄÎ©¥-Ìï¥Î©¥ Î©ÄÌã∞Ìîå Ï†úÍ±∞\n",
    "- 1Ï∞®, 2Ï∞®, 3Ï∞® Î©ÄÌã∞Ìîå ÏòàÏ∏° Î∞è Í∞êÏá†\n",
    "- Ï¶âÏãú ÏãúÍ∞ÅÌôî"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wb_demult"
   },
   "outputs": [],
   "source": [
    "print(\"üåä Water Bottom Demultiple Ï†ÅÏö© Ï§ë...\")\n",
    "print()\n",
    "print(\"Ï≤òÎ¶¨ Î∞©Î≤ï:\")\n",
    "print(\"   - Ìï¥Ï†ÄÎ©¥ ÏñëÎ∞©Ìñ• Ï£ºÏãú Í≥ÑÏÇ∞\")\n",
    "print(\"   - Ìï¥Ï†ÄÎ©¥-Ìï¥Î©¥ Î©ÄÌã∞Ìîå ÏòàÏ∏°\")\n",
    "print(\"   - 1Ï∞®, 2Ï∞®, 3Ï∞® Î©ÄÌã∞Ìîå Ï†úÍ±∞\")\n",
    "print()\n",
    "\n",
    "# Water Bottom Demultiple\n",
    "wb_demult_strength = 0.8\n",
    "after_wb = processor.water_bottom_demultiple(after_direct_mute, model, strength=wb_demult_strength)\n",
    "\n",
    "print(\"‚úÖ Water Bottom Demultiple ÏôÑÎ£å!\")\n",
    "print()\n",
    "\n",
    "# ÌÜµÍ≥Ñ\n",
    "removed_wb_mult = after_direct_mute - after_wb\n",
    "\n",
    "print(\"üìà ÌÜµÍ≥Ñ:\")\n",
    "print(f\"   - Before WB Demult RMS: {np.sqrt(np.mean(after_direct_mute**2)):.6f}\")\n",
    "print(f\"   - After WB Demult RMS:  {np.sqrt(np.mean(after_wb**2)):.6f}\")\n",
    "print(f\"   - Removed Multiples RMS: {np.sqrt(np.mean(removed_wb_mult**2)):.6f}\")\n",
    "print(f\"   - Reduction: {(1 - np.sqrt(np.mean(after_wb**2))/np.sqrt(np.mean(after_direct_mute**2)))*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî\n",
    "print(\"üìà Water Bottom Demultiple Í≤∞Í≥º ÏãúÍ∞ÅÌôî...\")\n",
    "processor.plot_shot_gather(after_wb, offsets, \"üåä After Water Bottom Demultiple\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step8"
   },
   "source": [
    "## üîÑ Step 12: Radon Transform Demultiple (Ïù∏ÌÑ∞ÎûôÌã∞Î∏å)\n",
    "\n",
    "**Ïù¥ ÏÖÄÏùÑ Ïã§ÌñâÌïòÎ©¥:**\n",
    "- Radon Î≥ÄÌôòÏúºÎ°ú t-x ‚Üí œÑ-p ÎèÑÎ©îÏù∏ Î≥ÄÌôò\n",
    "- **œÑ-p ÎèÑÎ©îÏù∏ ÏãúÍ∞ÅÌôî** (ÏõêÎ≥∏ + ÌïÑÌÑ∞ÎßÅ)\n",
    "- Multiple ÏÑ±Î∂Ñ ÏñµÏ†ú (ÎÇÆÏùÄ ray parameter)\n",
    "- Ïó≠Î≥ÄÌôòÏúºÎ°ú Î≥µÏõê\n",
    "- **ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï**: `threshold_percentile`, `p_min`, `p_max`, `n_p`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "radon_demult"
   },
   "outputs": [],
   "source": [
    "print(\"üîÑ Radon Transform Demultiple Ï†ÅÏö© Ï§ë...\")\n",
    "print()\n",
    "print(\"Ï≤òÎ¶¨ Î∞©Î≤ï:\")\n",
    "print(\"   - Forward Radon Transform (t-x ‚Üí œÑ-p)\")\n",
    "print(\"   - Multiple ÏÑ±Î∂Ñ ÏñµÏ†ú (ÎÇÆÏùÄ ray parameter)\")\n",
    "print(\"   - Inverse Radon Transform (œÑ-p ‚Üí t-x)\")\n",
    "print()\n",
    "print(\"‚öôÔ∏è ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï Í∞ÄÎä•:\")\n",
    "print(\"   - threshold_percentile: Multiple Ï†úÍ±∞ ÏûÑÍ≥ÑÍ∞í (Í∏∞Î≥∏ 75)\")\n",
    "print(\"   - p_min, p_max: Ray parameter Î≤îÏúÑ\")\n",
    "print(\"   - n_p: Ray parameter ÏÉòÌîå Ïàò\")\n",
    "print()\n",
    "print(\"‚è≥ Ï≤òÎ¶¨ Ï§ë... (ÏãúÍ∞ÑÏù¥ Í±∏Î¶¥ Ïàò ÏûàÏäµÎãàÎã§)\")\n",
    "\n",
    "# üîß Ïó¨Í∏∞ÏÑú ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï!\n",
    "threshold_percentile = 75  # ÎÇÆÏ∂îÎ©¥ Îçî ÎßéÏù¥ Ï†úÍ±∞ (Ïòà: 50, 60, 70, 75, 80, 90)\n",
    "p_min = -0.001  # Ray parameter ÏµúÏÜåÍ∞í\n",
    "p_max = 0.001   # Ray parameter ÏµúÎåÄÍ∞í\n",
    "n_p = 64        # Ray parameter ÏÉòÌîå Ïàò\n",
    "\n",
    "print(f\"\\nüìå ÌòÑÏû¨ ÌååÎùºÎØ∏ÌÑ∞:\")\n",
    "print(f\"   - Threshold Percentile: {threshold_percentile}\")\n",
    "print(f\"   - Ray Parameter Range: [{p_min}, {p_max}]\")\n",
    "print(f\"   - Number of Ray Parameters: {n_p}\")\n",
    "print()\n",
    "\n",
    "\n",
    "# üìò Radon Transform ÏàòÏãù:\n",
    "#   Forward:  R(œÑ, p) = Œ£_x D(œÑ - p¬∑x, x)  [t-x ‚Üí œÑ-p]\n",
    "#   Inverse:  D(t, x) = Œ£_p R(t + p¬∑x, p)  [œÑ-p ‚Üí t-x]\n",
    "# \n",
    "#   œÑ (tau): Intercept time (ÏàòÏßÅ Ï£ºÏãú)\n",
    "#   p: Ray parameter (slowness, 1/velocity)\n",
    "#   x: Offset (ÏÜ°ÏàòÏã†Í∏∞ Í±∞Î¶¨)\n",
    "#   Primary reflection: ÎÜíÏùÄ ÏÜçÎèÑ (p ‚âà 0)\n",
    "#   Multiple: ÎÇÆÏùÄ ÏÜçÎèÑ (p Í∞íÏù¥ ÌÅ¨Í±∞ÎÇò ÏûëÏùå)\n",
    "\n",
    "# Radon Transform Demultiple (Î∞òÌôòÍ∞í ÌôïÏû•)\n",
    "after_radon, radon_original, radon_filtered, p_values = processor.radon_transform_demultiple(\n",
    "    after_wb, offsets, \n",
    "    p_min=p_min, p_max=p_max, n_p=n_p, \n",
    "    threshold_percentile=threshold_percentile\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Radon Transform Demultiple ÏôÑÎ£å!\")\n",
    "print()\n",
    "\n",
    "# ÌÜµÍ≥Ñ\n",
    "removed_radon_mult = after_wb - after_radon\n",
    "\n",
    "print(\"üìà ÌÜµÍ≥Ñ:\")\n",
    "print(f\"   - Before Radon RMS: {np.sqrt(np.mean(after_wb**2)):.6f}\")\n",
    "print(f\"   - After Radon RMS:  {np.sqrt(np.mean(after_radon**2)):.6f}\")\n",
    "print(f\"   - Removed Multiples RMS: {np.sqrt(np.mean(removed_radon_mult**2)):.6f}\")\n",
    "print(f\"   - Additional Reduction: {(1 - np.sqrt(np.mean(after_radon**2))/np.sqrt(np.mean(after_wb**2)))*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# üé® œÑ-p ÎèÑÎ©îÏù∏ ÏãúÍ∞ÅÌôî (ÏõêÎ≥∏ vs ÌïÑÌÑ∞ÎßÅ)\n",
    "print(\"üìä œÑ-p ÎèÑÎ©îÏù∏ ÏãúÍ∞ÅÌôî...\")\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "# ÏõêÎ≥∏ Radon ÎèÑÎ©îÏù∏\n",
    "vmax_radon = np.percentile(np.abs(radon_original), 99)\n",
    "axes[0].imshow(radon_original, aspect='auto', cmap='seismic', \n",
    "               vmin=-vmax_radon, vmax=vmax_radon, \n",
    "               extent=[p_values[0]*1000, p_values[-1]*1000, processor.time[-1], processor.time[0]])\n",
    "axes[0].set_xlabel('Ray Parameter p (√ó10‚Åª¬≥ s/m)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Intercept Time œÑ (s)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_title('Original Radon Domain (œÑ-p)', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# ÌïÑÌÑ∞ÎßÅÎêú Radon ÎèÑÎ©îÏù∏\n",
    "axes[1].imshow(radon_filtered, aspect='auto', cmap='seismic', \n",
    "               vmin=-vmax_radon, vmax=vmax_radon, \n",
    "               extent=[p_values[0]*1000, p_values[-1]*1000, processor.time[-1], processor.time[0]])\n",
    "axes[1].set_xlabel('Ray Parameter p (√ó10‚Åª¬≥ s/m)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Intercept Time œÑ (s)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_title(f'Filtered Radon Domain (Threshold={threshold_percentile}%)', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Ï†úÍ±∞Îêú ÏÑ±Î∂Ñ (Multiple)\n",
    "radon_removed = radon_original - radon_filtered\n",
    "axes[2].imshow(radon_removed, aspect='auto', cmap='seismic', \n",
    "               vmin=-vmax_radon, vmax=vmax_radon, \n",
    "               extent=[p_values[0]*1000, p_values[-1]*1000, processor.time[-1], processor.time[0]])\n",
    "axes[2].set_xlabel('Ray Parameter p (√ó10‚Åª¬≥ s/m)', fontsize=12, fontweight='bold')\n",
    "axes[2].set_ylabel('Intercept Time œÑ (s)', fontsize=12, fontweight='bold')\n",
    "axes[2].set_title('Removed Components (Multiples)', fontsize=14, fontweight='bold')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"üí° œÑ-p ÎèÑÎ©îÏù∏ Ìï¥ÏÑù:\")\n",
    "print(\"   - ÏõêÎ≥∏: MultipleÏù¥ Ï†ÄÏÜçÎèÑ(ÎÇÆÏùÄ p Í∞í) ÏòÅÏó≠Ïóê Î∂ÑÌè¨\")\n",
    "print(\"   - ÌïÑÌÑ∞ÎßÅ: Í≥†ÏÜçÎèÑ ÏÑ±Î∂ÑÎßå ÎÇ®ÍπÄ (Primary reflection)\")\n",
    "print(\"   - Ï†úÍ±∞: Multiple ÏÑ±Î∂ÑÏùÑ œÑ-pÏóêÏÑú ÌôïÏù∏\")\n",
    "print()\n",
    "print(\"üîß ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï Î∞©Î≤ï:\")\n",
    "print(\"   - threshold_percentile ‚Üì ‚Üí Îçî ÎßéÏùÄ Multiple Ï†úÍ±∞ (Îã®, Ïã†Ìò∏ ÏÜêÏã§ Ï£ºÏùò)\")\n",
    "print(\"   - threshold_percentile ‚Üë ‚Üí Ïã†Ìò∏ Î≥¥Ï°¥ Ïö∞ÏÑ† (Multiple ÏûîÏ°¥ Í∞ÄÎä•)\")\n",
    "print(\"   - n_p ‚Üë ‚Üí Ray parameter Ìï¥ÏÉÅÎèÑ Ï¶ùÍ∞Ä (Í≥ÑÏÇ∞ ÏãúÍ∞Ñ Ï¶ùÍ∞Ä)\")\n",
    "print()\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî\n",
    "print(\"üìà Radon Transform Demultiple Í≤∞Í≥º ÏãúÍ∞ÅÌôî...\")\n",
    "processor.plot_shot_gather(after_radon, offsets, \"üîÑ After Radon Demultiple\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step11"
   },
   "source": [
    "## üìä Step 11: Ï†ÑÏ≤¥ ÎπÑÍµê (5Îã®Í≥Ñ)\n",
    "\n",
    "**Ï≤òÎ¶¨ ÌååÏù¥ÌîÑÎùºÏù∏ Ï†ÑÏ≤¥ ÎπÑÍµê**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison"
   },
   "outputs": [],
   "source": [
    "print(\"üìä Ï†ÑÏ≤¥ Ï≤òÎ¶¨ ÌååÏù¥ÌîÑÎùºÏù∏ ÎπÑÍµê...\")\n",
    "print()\n",
    "\n",
    "titles = [\n",
    "    'Input\\n(Noisy)',\n",
    "    'AAA + Lowcut\\n+ Curvelet',\n",
    "    'Water Bottom\\nDemultiple',\n",
    "    'Radon\\nDemultiple',\n",
    "    'Final\\n(All Processing)'\n",
    "]\n",
    "\n",
    "processor.plot_comparison_5(noisy_shot, final_shot, after_wb, after_radon, after_radon, \n",
    "                           offsets, titles)\n",
    "\n",
    "print(\"‚úÖ ÎπÑÍµê ÏôÑÎ£å!\")\n",
    "print()\n",
    "print(\"üí° Ï≤òÎ¶¨ ÌååÏù¥ÌîÑÎùºÏù∏:\")\n",
    "print(\"   1Ô∏è‚É£ Input: Multiple + ÎÖ∏Ïù¥Ï¶à\")\n",
    "print(\"   2Ô∏è‚É£ AAA + Lowcut + Curvelet: ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞\")\n",
    "print(\"   3Ô∏è‚É£ WB Demult: Ìï¥Ï†ÄÎ©¥ multiple Ï†úÍ±∞\")\n",
    "print(\"   4Ô∏è‚É£ Radon: Ï∂îÍ∞Ä multiple Ï†úÍ±∞\")\n",
    "print(\"   5Ô∏è‚É£ Final: ÏµúÏ¢Ö Í≤∞Í≥º\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step12"
   },
   "source": [
    "## üíæ Step 12: Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• Î∞è Îã§Ïö¥Î°úÎìú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save"
   },
   "outputs": [],
   "source": [
    "print(\"üíæ Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• Ï§ë...\")\n",
    "print()\n",
    "\n",
    "# Ï†ÄÏû•\n",
    "np.savez('shot_input.npz', shot_gather=noisy_shot, offsets=offsets, time=processor.time, model=model)\n",
    "print(\"‚úÖ shot_input.npz\")\n",
    "\n",
    "np.savez('shot_after_aaa.npz', shot_gather=after_aaa, offsets=offsets, time=processor.time, model=model)\n",
    "print(\"‚úÖ shot_after_aaa.npz\")\n",
    "\n",
    "np.savez('shot_after_lowcut.npz', shot_gather=after_lowcut, offsets=offsets, time=processor.time, model=model)\n",
    "print(\"‚úÖ shot_after_lowcut.npz\")\n",
    "\n",
    "np.savez('shot_after_curvelet.npz', shot_gather=final_shot, offsets=offsets, time=processor.time, model=model)\n",
    "print(\"‚úÖ shot_after_curvelet.npz\")\n",
    "\n",
    "np.savez('shot_after_wb.npz', shot_gather=after_wb, offsets=offsets, time=processor.time, model=model)\n",
    "print(\"‚úÖ shot_after_wb.npz\")\n",
    "\n",
    "np.savez('shot_final.npz', shot_gather=after_radon, offsets=offsets, time=processor.time, model=model)\n",
    "print(\"‚úÖ shot_final.npz\")\n",
    "print()\n",
    "\n",
    "# Colab Îã§Ïö¥Î°úÎìú\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print(\"üì• Îã§Ïö¥Î°úÎìú ÏãúÏûë...\")\n",
    "    files.download('shot_input.npz')\n",
    "    files.download('shot_final.npz')\n",
    "    print(\"‚úÖ Ï£ºÏöî ÌååÏùº Îã§Ïö¥Î°úÎìú ÏôÑÎ£å!\")\n",
    "except:\n",
    "    print(\"‚ÑπÔ∏è Î°úÏª¨ ÌôòÍ≤Ω - ÌååÏùºÏù¥ ÌòÑÏû¨ ÎîîÎ†âÌÜ†Î¶¨Ïóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"üéâ Ï†ÑÏ≤¥ Í≥†Í∏â Ï≤òÎ¶¨ ÏõåÌÅ¨ÌîåÎ°úÏö∞ ÏôÑÎ£å!\")\n",
    "print(\"=\"*80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "final"
   },
   "source": [
    "## üéâ ÏôÑÎ£å!\n",
    "\n",
    "---\n",
    "\n",
    "### ‚≠ê Í≥†Í∏â Ï≤òÎ¶¨ Í∏∞Î≤ï ÏöîÏïΩ\n",
    "\n",
    "| Îã®Í≥Ñ | Í∏∞Î≤ï | Î™©Ï†Å | ÌäπÏßï |\n",
    "|------|------|------|------|\n",
    "| 7 | **Anomalous Amplitude Attenuation** | Ïù¥ÏÉÅ ÏßÑÌè≠ Í∞êÏá† | Î°úÏª¨ ÌÜµÍ≥Ñ Í∏∞Î∞ò |\n",
    "| 8 | **Low-cut Filter** | Ï†ÄÏ£ºÌåå Ï†úÍ±∞ | 1.5 Hz Butterworth |\n",
    "| 9 | **Curvelet Denoise** | ÏùºÎ∞ò ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ | Wavelet Î≥ÄÌôò |\n",
    "| 10 | **Water Bottom Demultiple** | Ìï¥Ï†ÄÎ©¥ multiple Ï†úÍ±∞ | ÏòàÏ∏° Î∞è Ï†ÅÏùë Í∞êÏá† |\n",
    "| 11 | **Radon Transform** | Ï∂îÍ∞Ä multiple Ï†úÍ±∞ | t-x ‚Üí œÑ-p Î≥ÄÌôò |\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Ï≤òÎ¶¨ ÏàúÏÑúÏùò Ï§ëÏöîÏÑ±\n",
    "\n",
    "**ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ Î®ºÏ†Ä ‚Üí Multiple Ï†úÍ±∞**\n",
    "\n",
    "1. üî¥ **AAA**: Ïù¥ÏÉÅ ÏßÑÌè≠ Ï†úÍ±∞ (Burst noise)\n",
    "2. üü† **Low-cut**: Ï†ÄÏ£ºÌåå ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ (Swell, Ship)\n",
    "3. üü° **Curvelet**: ÏùºÎ∞ò ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ (White noise)\n",
    "4. üü¢ **WB Demult**: Íπ®ÎÅóÌïú Ïã†Ìò∏ÏóêÏÑú Multiple Ï†úÍ±∞\n",
    "5. üîµ **Radon**: ÏµúÏ¢Ö Multiple Ï†úÍ±∞\n",
    "\n",
    "**ÎÖ∏Ïù¥Ï¶àÍ∞Ä Íπ®ÎÅóÌï¥Ïïº Radon œÑ-p ÎèÑÎ©îÏù∏Ïù¥ Ï†ïÌôïÌï©ÎãàÎã§!**\n",
    "\n",
    "---\n",
    "\n",
    "### üìä ÏÑ±Îä• ÎπÑÍµê\n",
    "\n",
    "**Ïù¥Ï†Ñ Í∏∞Î≤ï vs Í≥†Í∏â Í∏∞Î≤ï:**\n",
    "\n",
    "- üî¥ **Ïù¥Ï†Ñ**: Multiple Î®ºÏ†Ä Ï†úÍ±∞ ‚Üí ÎÖ∏Ïù¥Ï¶àÏóê ÏùòÌïú Í∞ÑÏÑ≠\n",
    "- üü¢ **ÌòÑÏû¨**: ÎÖ∏Ïù¥Ï¶à Î®ºÏ†Ä Ï†úÍ±∞ ‚Üí Multiple Ï†ïÌôïÌûà Ï†úÍ±∞\n",
    "\n",
    "**SNR Í∞úÏÑ†:**\n",
    "- ÏùºÎ∞òÏ†ÅÏúºÎ°ú **20-30 dB** Í∞úÏÑ†\n",
    "- ÎÖ∏Ïù¥Ï¶àÏôÄ Multiple Î™®Îëê Ìö®Í≥ºÏ†ÅÏúºÎ°ú Ï†úÍ±∞\n",
    "\n",
    "---\n",
    "\n",
    "### üíæ ÏÉùÏÑ±Îêú ÌååÏùº (6Í∞ú)\n",
    "\n",
    "1. **shot_input.npz** - ÏûÖÎ†• (Multiple + ÎÖ∏Ïù¥Ï¶à)\n",
    "2. **shot_after_aaa.npz** - AAA ÌõÑ\n",
    "3. **shot_after_lowcut.npz** - Low-cut ÌõÑ\n",
    "4. **shot_after_curvelet.npz** - Curvelet ÌõÑ\n",
    "5. **shot_after_wb.npz** - WB Demult ÌõÑ\n",
    "6. **shot_final.npz** - ÏµúÏ¢Ö Í≤∞Í≥º (Radon ÌõÑ)\n",
    "\n",
    "---\n",
    "\n",
    "**Made with ‚ù§Ô∏è for Advanced Marine Seismic Processing**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}