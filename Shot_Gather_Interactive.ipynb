{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "## üìã Îã®Í≥ÑÎ≥Ñ Ïã§Ìñâ ÏõåÌÅ¨ÌîåÎ°úÏö∞\n",
    "\n",
    "**Í∞Å ÏÖÄÏùÑ ÌïòÎÇòÏî© Ïã§ÌñâÌïòÎ©¥ÏÑú Í≤∞Í≥ºÎ•º ÌôïÏù∏ÌïòÏÑ∏Ïöî!**\n",
    "\n",
    "1. ‚úÖ Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò Î∞è ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
    "2. ‚úÖ ÎûúÎç§ Ìï©ÏÑ± Î™®Îç∏ ÏÉùÏÑ±\n",
    "3. ‚úÖ Shot Gather ÏÉùÏÑ± (Clean)\n",
    "4. ‚úÖ ÏßÅÏ†ëÌåå Ï∂îÍ∞Ä\n",
    "5. ‚úÖ Multiple Ï∂îÍ∞Ä (Ìï¥Î©¥ + ÎÇ¥Î∂Ä)\n",
    "6. ‚úÖ Ìï¥ÏÉÅ ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä\n",
    "7. ‚úÖ **Anomalous Amplitude Attenuation** ‚≠ê ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞\n",
    "8. ‚úÖ **Low-cut Filter (1.5 Hz)** ‚≠ê Ï†ÄÏ£ºÌåå Ï†úÍ±∞\n",
    "9. ‚úÖ **Curvelet Denoise** ‚≠ê ÏùºÎ∞ò ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞\n",
    "10. ‚úÖ **ÏßÅÏ†ëÌåå Ï†úÍ±∞ (Direct Wave Mute)** ‚≠ê NEW\n",
    "11. ‚úÖ **Water Bottom Demultiple** ‚≠ê Multiple Ï†úÍ±∞\n",
    "12. ‚úÖ **Radon Transform Demultiple** ‚≠ê Multiple Ï†úÍ±∞\n",
    "13. ‚úÖ Ï†ÑÏ≤¥ ÎπÑÍµê\n",
    "14. ‚úÖ Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• Î∞è Îã§Ïö¥Î°úÎìú\n",
    "\n",
    "---\n",
    "\n",
    "**üöÄ ÏÇ¨Ïö©Î≤ï: Í∞Å ÏÖÄÏùÑ ÏàúÏÑúÎåÄÎ°ú Ïã§Ìñâ (Shift + Enter)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1"
   },
   "source": [
    "## üì¶ Step 1: Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò Î∞è ÏûÑÌè¨Ìä∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install"
   },
   "outputs": [],
   "source": [
    "!pip install -q numpy scipy matplotlib pywt scikit-image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.ndimage import median_filter\n",
    "from scipy.linalg import svd\n",
    "import pywt\n",
    "from skimage.restoration import denoise_wavelet\n",
    "from typing import Tuple, Dict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Ìå®ÌÇ§ÏßÄ ÏÑ§Ïπò Î∞è ÏûÑÌè¨Ìä∏ ÏôÑÎ£å!\")\n",
    "print(\"   - NumPy\")\n",
    "print(\"   - SciPy\")\n",
    "print(\"   - Matplotlib\")\n",
    "print(\"   - PyWavelets (Curvelet)\")\n",
    "print(\"   - scikit-image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step1b"
   },
   "source": [
    "## üîß Step 1-2: Í≥†Í∏â Ï≤òÎ¶¨ ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
    "\n",
    "**Í≥†Í∏â Ï≤òÎ¶¨ Í∏∞Î≤ï:**\n",
    "- ‚úÖ Water Bottom Demultiple\n",
    "- ‚úÖ Radon Transform Demultiple  \n",
    "- ‚úÖ Anomalous Amplitude Attenuation\n",
    "- ‚úÖ Curvelet Denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "class_definition"
   },
   "outputs": [],
   "source": [
    "class AdvancedMarineProcessor:\n",
    "    \"\"\"Í≥†Í∏â Ìï¥ÏÉÅ Shot Gather Ï≤òÎ¶¨ ÌÅ¥ÎûòÏä§\"\"\"\n",
    "    \n",
    "    def __init__(self, dt: float = 0.002, nt: int = 1500):\n",
    "        self.dt = dt\n",
    "        self.nt = nt\n",
    "        self.time = np.arange(nt) * dt\n",
    "        \n",
    "    def create_random_model(self, nlayers: int = None) -> Dict:\n",
    "        \"\"\"ÏôÑÏ†Ñ ÎûúÎç§ Ìï©ÏÑ± ÏßÄÎ∞ò Î™®Îç∏ ÏÉùÏÑ±\"\"\"\n",
    "        if nlayers is None:\n",
    "            nlayers = np.random.randint(4, 9)\n",
    "        \n",
    "        model = {'velocity': [], 'density': [], 'thickness': [], 'depth': [], 'name': []}\n",
    "        \n",
    "        # Ìï¥ÏàòÏ∏µ\n",
    "        water_depth = np.random.uniform(300, 800)\n",
    "        model['velocity'].append(1500.0)\n",
    "        model['density'].append(1030.0)\n",
    "        model['thickness'].append(water_depth)\n",
    "        model['depth'].append(0.0)\n",
    "        model['name'].append('Water')\n",
    "        \n",
    "        # Ìï¥Ï†ÄÎ©¥\n",
    "        seabed_vp = np.random.uniform(1600, 2000)\n",
    "        seabed_rho = np.random.uniform(1900, 2100)\n",
    "        seabed_thick = np.random.uniform(200, 400)\n",
    "        model['velocity'].append(seabed_vp)\n",
    "        model['density'].append(seabed_rho)\n",
    "        model['thickness'].append(seabed_thick)\n",
    "        model['depth'].append(water_depth)\n",
    "        model['name'].append('Seabed')\n",
    "        \n",
    "        # ÏßÄÌïò ÏßÄÏ∏µÎì§\n",
    "        current_depth = water_depth + seabed_thick\n",
    "        for i in range(nlayers - 2):\n",
    "            if i == 0:\n",
    "                base_vp = seabed_vp + np.random.uniform(200, 500)\n",
    "            else:\n",
    "                base_vp = model['velocity'][-1] + np.random.uniform(100, 600)\n",
    "            \n",
    "            vp = base_vp + np.random.normal(0, 100)\n",
    "            vp = np.clip(vp, 2000, 5000)\n",
    "            rho = 2000 + (vp - 2000) * 0.2 + np.random.normal(0, 50)\n",
    "            rho = np.clip(rho, 2000, 2800)\n",
    "            thickness = np.random.uniform(150, 600)\n",
    "            \n",
    "            model['velocity'].append(vp)\n",
    "            model['density'].append(rho)\n",
    "            model['thickness'].append(thickness)\n",
    "            model['depth'].append(current_depth)\n",
    "            model['name'].append(f'Layer {i+3}')\n",
    "            current_depth += thickness\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def calculate_reflection_coefficients(self, model: Dict):\n",
    "        velocities = np.array(model['velocity'])\n",
    "        densities = np.array(model['density'])\n",
    "        thicknesses = np.array(model['thickness'])\n",
    "        impedance = velocities * densities\n",
    "        \n",
    "        rc = np.zeros(len(velocities) - 1)\n",
    "        for i in range(len(velocities) - 1):\n",
    "            rc[i] = (impedance[i+1] - impedance[i]) / (impedance[i+1] + impedance[i])\n",
    "        \n",
    "        times = np.zeros(len(velocities) - 1)\n",
    "        cumulative_time = 0\n",
    "        for i in range(len(velocities) - 1):\n",
    "            travel_time = thicknesses[i] / velocities[i]\n",
    "            cumulative_time += travel_time\n",
    "            times[i] = cumulative_time * 2\n",
    "        \n",
    "        return rc, times\n",
    "    \n",
    "    def ricker_wavelet(self, freq: float = 25.0):\n",
    "        duration = 0.2\n",
    "        t = np.arange(-duration/2, duration/2, self.dt)\n",
    "        a = (np.pi * freq * t) ** 2\n",
    "        wavelet = (1 - 2*a) * np.exp(-a)\n",
    "        return wavelet / np.max(np.abs(wavelet))\n",
    "    \n",
    "    def generate_shot_gather(self, model: Dict, n_traces: int = 48, \n",
    "                           offset_min: float = 100, offset_max: float = 2400,\n",
    "                           freq: float = 25.0):\n",
    "        \"\"\"Shot Gather ÏÉùÏÑ±\"\"\"\n",
    "        offsets = np.linspace(offset_min, offset_max, n_traces)\n",
    "        shot_gather = np.zeros((self.nt, n_traces))\n",
    "        wavelet = self.ricker_wavelet(freq)\n",
    "        rc, zero_offset_times = self.calculate_reflection_coefficients(model)\n",
    "        \n",
    "        for i_trace, offset in enumerate(offsets):\n",
    "            reflectivity = np.zeros(self.nt)\n",
    "            \n",
    "            for j, (rc_val, t0) in enumerate(zip(rc, zero_offset_times)):\n",
    "                depths = np.array(model['depth'])\n",
    "                velocities = np.array(model['velocity'])\n",
    "                \n",
    "                if j < len(depths) - 1:\n",
    "                    avg_depth = depths[j+1]\n",
    "                    avg_velocity = np.mean(velocities[:j+2])\n",
    "                    t_nmo = np.sqrt(t0**2 + (offset / avg_velocity)**2)\n",
    "                    angle = np.arctan(offset / avg_depth)\n",
    "                    avo_factor = 1 - 0.3 * np.sin(angle)**2\n",
    "                    \n",
    "                    idx = int(t_nmo / self.dt)\n",
    "                    if idx < self.nt:\n",
    "                        reflectivity[idx] += rc_val * avo_factor\n",
    "            \n",
    "            trace = signal.convolve(reflectivity, wavelet, mode='same')\n",
    "            spreading = 1 / (1 + offset / 1000)\n",
    "            shot_gather[:, i_trace] = trace * spreading\n",
    "        \n",
    "        return shot_gather, offsets\n",
    "    \n",
    "    def add_direct_wave(self, shot_gather, offsets, model: Dict, strength: float = 0.3):\n",
    "        \"\"\"ÏßÅÏ†ëÌåå Ï∂îÍ∞Ä\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        water_velocity = model['velocity'][0]\n",
    "        wavelet = self.ricker_wavelet(25.0)\n",
    "        \n",
    "        for i, offset in enumerate(offsets):\n",
    "            direct_time = offset / water_velocity\n",
    "            idx = int(direct_time / self.dt)\n",
    "            \n",
    "            if idx < self.nt:\n",
    "                amplitude = strength / (1 + offset / 500)\n",
    "                wavelet_start = max(0, idx - len(wavelet)//2)\n",
    "                wavelet_end = min(self.nt, idx + len(wavelet)//2)\n",
    "                wavelet_idx_start = max(0, len(wavelet)//2 - idx)\n",
    "                wavelet_idx_end = wavelet_idx_start + (wavelet_end - wavelet_start)\n",
    "                \n",
    "                result[wavelet_start:wavelet_end, i] += amplitude * wavelet[wavelet_idx_start:wavelet_idx_end]\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def add_sea_surface_multiple(self, shot_gather, model: Dict, strength: float = 0.5):\n",
    "        \"\"\"Ìï¥Î©¥ Î©ÄÌã∞Ìîå Ï∂îÍ∞Ä\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        water_depth = model['thickness'][0]\n",
    "        water_velocity = model['velocity'][0]\n",
    "        two_way_time = 2 * water_depth / water_velocity\n",
    "        delay_samples = int(two_way_time / self.dt)\n",
    "        sea_surface_rc = -0.95\n",
    "        \n",
    "        if delay_samples < self.nt:\n",
    "            result[delay_samples:, :] += shot_gather[:-delay_samples, :] * sea_surface_rc * strength\n",
    "        \n",
    "        if 2 * delay_samples < self.nt:\n",
    "            result[2*delay_samples:, :] += shot_gather[:-2*delay_samples, :] * (sea_surface_rc**2) * strength * 0.5\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def add_internal_multiples(self, shot_gather, model: Dict, strength: float = 0.3):\n",
    "        \"\"\"ÎÇ¥Î∂Ä Î©ÄÌã∞Ìîå Ï∂îÍ∞Ä\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        rc, reflection_times = self.calculate_reflection_coefficients(model)\n",
    "        \n",
    "        strong_reflectors = [(t, rc_val) for t, rc_val in zip(reflection_times, rc) \n",
    "                           if abs(rc_val) > 0.1]\n",
    "        \n",
    "        for i, (t1, rc1) in enumerate(strong_reflectors):\n",
    "            for t2, rc2 in strong_reflectors[i+1:]:\n",
    "                multiple_delay = t2 - t1 + (t2 - t1)\n",
    "                delay_samples = int(multiple_delay / self.dt)\n",
    "                \n",
    "                if delay_samples < self.nt:\n",
    "                    multiple_strength = rc1 * rc2 * strength\n",
    "                    result[delay_samples:, :] += shot_gather[:-delay_samples, :] * multiple_strength\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def add_swell_noise(self, shot_gather, offsets, swell_strength=0.5):\n",
    "        \"\"\"Swell Noise Ï∂îÍ∞Ä - Linear Moveout Coherent Noise\n",
    "        \n",
    "        ÎåÄÍ∞ÅÏÑ† Ìå®ÌÑ¥ÏúºÎ°ú ÎÇòÌÉÄÎÇòÎäî coherent noise:\n",
    "        - Ï£ºÌååÏàò: 0.1-0.5 Hz (Îß§Ïö∞ ÎÇÆÏùå)\n",
    "        - Linear moveout: offsetÏóê ÎπÑÎ°ÄÌïòÎäî ÏãúÍ∞Ñ ÏßÄÏó∞\n",
    "        - Apparent velocity: 1000-2000 m/s (ÎäêÎ¶∞ ÏÜçÎèÑ)\n",
    "        - Ìï¥Ïñë ÌëúÎ©¥Ìåå, ÏºÄÏù¥Î∏î ÏßÑÎèôÏùò Ï†ÑÌåå\n",
    "        \"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        signal_power = np.std(shot_gather)\n",
    "        \n",
    "        # Ïó¨Îü¨ swell ÏÑ±Î∂Ñ (Í∞ÅÍ∞Å Îã§Î•∏ apparent velocity)\n",
    "        n_components = np.random.randint(2, 4)\n",
    "        \n",
    "        for _ in range(n_components):\n",
    "            # Swell Ï£ºÌååÏàò\n",
    "            swell_freq = np.random.uniform(0.1, 0.5)\n",
    "            \n",
    "            # Apparent velocity (ÎäêÎ¶∞ ÏÜçÎèÑ)\n",
    "            apparent_velocity = np.random.uniform(1000, 2000)  # m/s\n",
    "            \n",
    "            # ÏãúÍ∞Ñ Î≥ÄÏ°∞\n",
    "            modulation_freq = np.random.uniform(0.05, 0.15)\n",
    "            \n",
    "            # ÏßÑÌè≠\n",
    "            amplitude = swell_strength * signal_power * (0.8 + 0.4 * np.random.rand())\n",
    "            \n",
    "            # Í∞Å Ìä∏Î†àÏù¥Ïä§Ïóê linear moveout Ï†ÅÏö©\n",
    "            for j, offset in enumerate(offsets):\n",
    "                # Linear moveout: t_arrival = t0 + offset / v_app\n",
    "                time_shift = offset / apparent_velocity\n",
    "                \n",
    "                # ÏãúÍ∞ÑÏ∂ï ÏÉùÏÑ±\n",
    "                t_shifted = self.time - time_shift\n",
    "                \n",
    "                # ÏãúÍ∞Ñ Î≥ÄÏ°∞\n",
    "                time_modulation = 1 + 0.6 * np.sin(2 * np.pi * modulation_freq * self.time)\n",
    "                \n",
    "                # Swell ÌååÌòï (shifted time)\n",
    "                swell_wave = np.zeros(nt)\n",
    "                for it in range(nt):\n",
    "                    if 0 <= t_shifted[it] <= self.time[-1]:\n",
    "                        swell_wave[it] = np.sin(2 * np.pi * swell_freq * t_shifted[it]) * time_modulation[it]\n",
    "                \n",
    "                result[:, j] += amplitude * swell_wave\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def remove_direct_wave(self, shot_gather, offsets, model: Dict, mute_velocity=1500, taper_length=50):\n",
    "        \"\"\"ÏßÅÏ†ëÌåå(Direct Wave) Ï†úÍ±∞ - Top Mute\n",
    "        \n",
    "        ÏßÅÏ†ëÌååÎäî Ìï¥ÏàòÏ∏µÏùÑ ÌÜµÌï¥ ÏßÅÏ†ë Ï†ÑÌååÎêòÎäî ÌååÎèô:\n",
    "        - ÏÜçÎèÑ: Ìï¥Ïàò ÏùåÏÜç (~1500 m/s)\n",
    "        - Í∞ÄÏû• Î®ºÏ†Ä ÎèÑÎã¨\n",
    "        - Linear moveout: t = offset / velocity\n",
    "        \n",
    "        Top muteÎ°ú Ï†úÍ±∞:\n",
    "        - Mute velocity Ïù¥ÏÉÅÏùò ÏÜçÎèÑÎ•º Í∞ÄÏßÑ Ïù¥Î≤§Ìä∏ Ï†úÍ±∞\n",
    "        - TaperÎ•º Ï†ÅÏö©ÌïòÏó¨ Î∂ÄÎìúÎüΩÍ≤å Ï†úÍ±∞\n",
    "        \"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        \n",
    "        for j, offset in enumerate(offsets):\n",
    "            # Mute time Í≥ÑÏÇ∞: t_mute = offset / mute_velocity\n",
    "            if mute_velocity > 0:\n",
    "                mute_time = offset / mute_velocity\n",
    "            else:\n",
    "                mute_time = 0\n",
    "            \n",
    "            mute_sample = int(mute_time / self.dt)\n",
    "            \n",
    "            # Mute Ï†ÅÏö© (taper Ìè¨Ìï®)\n",
    "            if mute_sample < nt:\n",
    "                # ÏôÑÏ†ÑÌûà Ï†úÍ±∞ÌïòÎäî Íµ¨Í∞Ñ\n",
    "                result[:mute_sample, j] = 0\n",
    "                \n",
    "                # Taper Íµ¨Í∞Ñ (Î∂ÄÎìúÎüΩÍ≤å Ï†ÑÌôò)\n",
    "                taper_end = min(mute_sample + taper_length, nt)\n",
    "                taper_samples = taper_end - mute_sample\n",
    "                \n",
    "                if taper_samples > 0:\n",
    "                    # Cosine taper\n",
    "                    taper = 0.5 * (1 - np.cos(np.pi * np.arange(taper_samples) / taper_samples))\n",
    "                    result[mute_sample:taper_end, j] *= taper\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def add_marine_noise(self, shot_gather, offsets, noise_level: float = 0.08):\n",
    "        \"\"\"Ìï¥ÏÉÅ ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        signal_power = np.std(shot_gather)\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        \n",
    "        # Î∞±ÏÉâ Ïû°Ïùå\n",
    "        white_noise = np.random.normal(0, noise_level * signal_power * 0.3, (nt, n_traces))\n",
    "        result += white_noise\n",
    "        \n",
    "        # ÏÑ†Î∞ï ÎÖ∏Ïù¥Ï¶à\n",
    "        ship_freq = np.random.uniform(2, 8)\n",
    "        for j in range(n_traces):\n",
    "            ship_noise = noise_level * signal_power * 0.5 * np.sin(2 * np.pi * ship_freq * self.time)\n",
    "            ship_noise *= (1 + 0.3 * np.sin(2 * np.pi * 0.5 * self.time))\n",
    "            result[:, j] += ship_noise\n",
    "        \n",
    "        # Ïä§Ïõ∞ ÎÖ∏Ïù¥Ï¶à (Í∞úÏÑ†Îêú Î™®Îç∏ ÏÇ¨Ïö©)\n",
    "        result = self.add_swell_noise(result, offsets, swell_strength=noise_level * 0.5)\n",
    "        \n",
    "        # Î≤ÑÏä§Ìä∏ ÎÖ∏Ïù¥Ï¶à\n",
    "        n_bursts = np.random.randint(2, 5)\n",
    "        for _ in range(n_bursts):\n",
    "            burst_trace = np.random.randint(0, n_traces)\n",
    "            burst_time = np.random.randint(0, nt)\n",
    "            burst_duration = np.random.randint(20, 80)\n",
    "            if burst_time + burst_duration < nt:\n",
    "                burst = noise_level * signal_power * 2.0 * np.random.randn(burst_duration)\n",
    "                result[burst_time:burst_time+burst_duration, burst_trace] += burst\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def lowcut_filter(self, shot_gather, cutoff_freq=1.5, order=5):\n",
    "        \"\"\"Low-cut (High-pass) Filter - Ï†ÄÏ£ºÌåå ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞\"\"\"\n",
    "        from scipy.signal import butter, filtfilt\n",
    "        \n",
    "        result = shot_gather.copy()\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        \n",
    "        # Nyquist frequency\n",
    "        fs = 1.0 / self.dt\n",
    "        nyquist = fs / 2.0\n",
    "        \n",
    "        # Normalize cutoff frequency\n",
    "        normalized_cutoff = cutoff_freq / nyquist\n",
    "        \n",
    "        # Design Butterworth high-pass filter\n",
    "        b, a = butter(order, normalized_cutoff, btype='high', analog=False)\n",
    "        \n",
    "        # Apply filter to each trace\n",
    "        for ix in range(n_traces):\n",
    "            result[:, ix] = filtfilt(b, a, shot_gather[:, ix])\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def water_bottom_demultiple(self, shot_gather, model: Dict, strength: float = 0.8):\n",
    "        \"\"\"Water Bottom Demultiple (Ìï¥Ï†ÄÎ©¥ Î©ÄÌã∞Ìîå Ï†úÍ±∞)\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        \n",
    "        # Ìï¥Ï†ÄÎ©¥ ÏñëÎ∞©Ìñ• Ï£ºÏãú Í≥ÑÏÇ∞\n",
    "        water_depth = model['thickness'][0]\n",
    "        water_velocity = model['velocity'][0]\n",
    "        wb_two_way_time = 2 * water_depth / water_velocity\n",
    "        wb_delay = int(wb_two_way_time / self.dt)\n",
    "        \n",
    "        # Ìï¥Ï†ÄÎ©¥ Î∞òÏÇ¨ Í≥ÑÏàò\n",
    "        water_impedance = model['velocity'][0] * model['density'][0]\n",
    "        seabed_impedance = model['velocity'][1] * model['density'][1]\n",
    "        wb_rc = (seabed_impedance - water_impedance) / (seabed_impedance + water_impedance)\n",
    "        \n",
    "        # Ìï¥Î©¥ Î∞òÏÇ¨ Í≥ÑÏàò\n",
    "        sea_surface_rc = -0.95\n",
    "        \n",
    "        # Ìï¥Ï†ÄÎ©¥-Ìï¥Î©¥ Î©ÄÌã∞Ìîå ÏòàÏ∏° Î∞è Ï†úÍ±∞\n",
    "        for order in range(1, 4):  # 1Ï∞®, 2Ï∞®, 3Ï∞® Î©ÄÌã∞Ìîå\n",
    "            delay = wb_delay * order\n",
    "            if delay < self.nt:\n",
    "                # Î©ÄÌã∞Ìîå ÏòàÏ∏°\n",
    "                multiple_strength = (wb_rc * (sea_surface_rc ** order)) * strength\n",
    "                predicted_multiple = np.zeros_like(result)\n",
    "                predicted_multiple[delay:, :] = shot_gather[:-delay, :] * multiple_strength\n",
    "                \n",
    "                # Ï†ÅÏùë Í∞êÏá†\n",
    "                result -= predicted_multiple\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def radon_forward_transform(self, shot_gather, offsets, p_min=-0.001, p_max=0.001, n_p=128):\n",
    "        \"\"\"Forward Radon Transform (t-x -> tau-p) with linear interpolation\"\"\"\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        p_values = np.linspace(p_min, p_max, n_p)\n",
    "        \n",
    "        # Forward Radon Transform: radon(tau, p) = sum over x of data(tau - p*x, x)\n",
    "        radon_domain = np.zeros((nt, n_p))\n",
    "        for ip, p in enumerate(p_values):\n",
    "            for it in range(nt):\n",
    "                tau = self.time[it]\n",
    "                for ix, offset in enumerate(offsets):\n",
    "                    # Time in shot gather: t = tau - p * offset\n",
    "                    t = tau - p * offset\n",
    "                    t_idx = t / self.dt\n",
    "                    \n",
    "                    # Linear interpolation\n",
    "                    if 0 <= t_idx < nt - 1:\n",
    "                        idx_low = int(np.floor(t_idx))\n",
    "                        idx_high = idx_low + 1\n",
    "                        weight = t_idx - idx_low\n",
    "                        \n",
    "                        radon_domain[it, ip] += (1 - weight) * shot_gather[idx_low, ix] +                                                 weight * shot_gather[idx_high, ix]\n",
    "        \n",
    "        return radon_domain, p_values\n",
    "    \n",
    "    def radon_inverse_transform(self, radon_domain, p_values, offsets, nt):\n",
    "        \"\"\"Inverse Radon Transform (tau-p -> t-x) with linear interpolation\"\"\"\n",
    "        n_p = len(p_values)\n",
    "        n_traces = len(offsets)\n",
    "        result = np.zeros((nt, n_traces))\n",
    "        \n",
    "        # Inverse Radon Transform: data(t, x) = sum over p of radon(t + p*x, p)\n",
    "        for ix, offset in enumerate(offsets):\n",
    "            for it in range(nt):\n",
    "                t = self.time[it]\n",
    "                for ip, p in enumerate(p_values):\n",
    "                    # Tau in radon domain: tau = t + p * offset\n",
    "                    tau = t + p * offset\n",
    "                    tau_idx = tau / self.dt\n",
    "                    \n",
    "                    # Linear interpolation\n",
    "                    if 0 <= tau_idx < nt - 1:\n",
    "                        idx_low = int(np.floor(tau_idx))\n",
    "                        idx_high = idx_low + 1\n",
    "                        weight = tau_idx - idx_low\n",
    "                        \n",
    "                        result[it, ix] += (1 - weight) * radon_domain[idx_low, ip] +                                          weight * radon_domain[idx_high, ip]\n",
    "        \n",
    "        # Normalize by number of p values (simple adjoint)\n",
    "        result /= n_p\n",
    "        return result\n",
    "    \n",
    "    def radon_transform_demultiple(self, shot_gather, offsets, p_min=-0.001, p_max=0.001, n_p=128, threshold_percentile=75):\n",
    "        \"\"\"Radon Transform Í∏∞Î∞ò Demultiple (ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï Í∞ÄÎä•) - Legacy Method\"\"\"\n",
    "        # Forward transform\n",
    "        radon_domain, p_values = self.radon_forward_transform(shot_gather, offsets, p_min, p_max, n_p)\n",
    "        \n",
    "        # Multiple ÏñµÏ†ú\n",
    "        threshold = np.percentile(np.abs(radon_domain), threshold_percentile)\n",
    "        mask = np.abs(radon_domain) > threshold\n",
    "        radon_filtered = radon_domain * mask\n",
    "        \n",
    "        # Inverse transform\n",
    "        result = self.radon_inverse_transform(radon_filtered, p_values, offsets, self.nt)\n",
    "        \n",
    "        return result, radon_domain, radon_filtered, p_values\n",
    "    \n",
    "    def radon_forward_parabolic(self, shot_gather, offsets, q_min=0.0, q_max=0.001, n_q=128):\n",
    "        \"\"\"Parabolic Radon Transform (t-x -> tau-q)\n",
    "        \n",
    "        Parabolic moveout: t(x) = tau + q * x^2\n",
    "        \n",
    "        SEG Wiki ÌëúÏ§Ä:\n",
    "        - Îçî Ï†ïÌôïÌïú multiple modeling (hyperbolic moveout Í∑ºÏÇ¨)\n",
    "        - PrimaryÎäî q‚âà0, MultipleÏùÄ Îçî ÌÅ∞ q Í∞í\n",
    "        \"\"\"\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        q_values = np.linspace(q_min, q_max, n_q)\n",
    "        \n",
    "        # Normalize offsets to prevent numerical issues\n",
    "        x_norm = offsets / np.max(np.abs(offsets))\n",
    "        \n",
    "        radon_domain = np.zeros((nt, n_q))\n",
    "        \n",
    "        for iq, q in enumerate(q_values):\n",
    "            for ix, x in enumerate(x_norm):\n",
    "                for it in range(nt):\n",
    "                    t = self.time[it]\n",
    "                    tau = t - q * x**2\n",
    "                    tau_idx = tau / self.dt\n",
    "                    \n",
    "                    if 0 <= tau_idx < nt - 1:\n",
    "                        idx_low = int(np.floor(tau_idx))\n",
    "                        idx_high = idx_low + 1\n",
    "                        weight = tau_idx - idx_low\n",
    "                        \n",
    "                        radon_domain[it, iq] += (1 - weight) * shot_gather[idx_low, ix] + weight * shot_gather[idx_high, ix]\n",
    "        \n",
    "        radon_domain /= n_traces\n",
    "        return radon_domain, q_values\n",
    "    \n",
    "    def radon_inverse_parabolic(self, radon_domain, q_values, offsets, nt):\n",
    "        \"\"\"Inverse Parabolic Radon Transform (tau-q -> t-x)\"\"\"\n",
    "        n_q = len(q_values)\n",
    "        n_traces = len(offsets)\n",
    "        result = np.zeros((nt, n_traces))\n",
    "        \n",
    "        x_norm = offsets / np.max(np.abs(offsets))\n",
    "        \n",
    "        for ix, x in enumerate(x_norm):\n",
    "            for iq, q in enumerate(q_values):\n",
    "                for it in range(nt):\n",
    "                    tau = self.time[it]\n",
    "                    t = tau + q * x**2\n",
    "                    t_idx = t / self.dt\n",
    "                    \n",
    "                    if 0 <= t_idx < nt - 1:\n",
    "                        idx_low = int(np.floor(t_idx))\n",
    "                        idx_high = idx_low + 1\n",
    "                        weight = t_idx - idx_low\n",
    "                        \n",
    "                        result[it, ix] += (1 - weight) * radon_domain[idx_low, iq] + weight * radon_domain[idx_high, iq]\n",
    "        \n",
    "        result /= n_q\n",
    "        return result\n",
    "    \n",
    "    def radon_forward_linear(self, shot_gather, offsets, p_min=-0.002, p_max=0.002, n_p=128):\n",
    "        \"\"\"Linear Radon Transform - Improved (SEG Wiki Í∏∞Î∞ò)\n",
    "        \n",
    "        Í∞úÏÑ†Ï†ê:\n",
    "        - Îçî ÎÑìÏùÄ p Î≤îÏúÑ (¬±0.002)\n",
    "        - Ï†ÅÏ†àÌïú Ï†ïÍ∑úÌôî\n",
    "        \"\"\"\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        p_values = np.linspace(p_min, p_max, n_p)\n",
    "        \n",
    "        radon_domain = np.zeros((nt, n_p))\n",
    "        \n",
    "        for ip, p in enumerate(p_values):\n",
    "            for ix, offset in enumerate(offsets):\n",
    "                for it in range(nt):\n",
    "                    tau = self.time[it]\n",
    "                    t = tau - p * offset\n",
    "                    t_idx = t / self.dt\n",
    "                    \n",
    "                    if 0 <= t_idx < nt - 1:\n",
    "                        idx_low = int(np.floor(t_idx))\n",
    "                        idx_high = idx_low + 1\n",
    "                        weight = t_idx - idx_low\n",
    "                        \n",
    "                        radon_domain[it, ip] += (1 - weight) * shot_gather[idx_low, ix] + weight * shot_gather[idx_high, ix]\n",
    "        \n",
    "        radon_domain /= n_traces\n",
    "        return radon_domain, p_values\n",
    "    \n",
    "    def radon_inverse_linear(self, radon_domain, p_values, offsets, nt):\n",
    "        \"\"\"Inverse Linear Radon Transform - Improved\"\"\"\n",
    "        n_p = len(p_values)\n",
    "        n_traces = len(offsets)\n",
    "        result = np.zeros((nt, n_traces))\n",
    "        \n",
    "        for ix, offset in enumerate(offsets):\n",
    "            for ip, p in enumerate(p_values):\n",
    "                for it in range(nt):\n",
    "                    t = self.time[it]\n",
    "                    tau = t + p * offset\n",
    "                    tau_idx = tau / self.dt\n",
    "                    \n",
    "                    if 0 <= tau_idx < nt - 1:\n",
    "                        idx_low = int(np.floor(tau_idx))\n",
    "                        idx_high = idx_low + 1\n",
    "                        weight = tau_idx - idx_low\n",
    "                        \n",
    "                        result[it, ix] += (1 - weight) * radon_domain[idx_low, ip] + weight * radon_domain[idx_high, ip]\n",
    "        \n",
    "        result /= n_p\n",
    "        return result\n",
    "    \n",
    "    def radon_mute_multiples(self, radon_domain, param_values, mute_type='inner', \n",
    "                            p_primary_min=-0.0005, p_primary_max=0.0005):\n",
    "        \"\"\"Radon DomainÏóêÏÑú Multiple Mute (SEG Wiki ÌëúÏ§Ä)\n",
    "        \n",
    "        - PrimaryÎäî p ‚âà 0 Í∑ºÏ≤òÏóê ÏúÑÏπò\n",
    "        - MultipleÏùÄ Îçî ÌÅ∞ |p| Í∞íÏóê ÏúÑÏπò\n",
    "        - MuteÎ•º ÏÇ¨Ïö©ÌïòÏó¨ multiple ÏòÅÏó≠ Ï†úÍ±∞\n",
    "        \"\"\"\n",
    "        muted_radon = radon_domain.copy()\n",
    "        \n",
    "        if mute_type == 'inner':\n",
    "            # Multiple Ï†úÍ±∞: p_primary Î∞ñÏùò ÏòÅÏó≠ÏùÑ 0ÏúºÎ°ú\n",
    "            for ip, p in enumerate(param_values):\n",
    "                if not (p_primary_min <= p <= p_primary_max):\n",
    "                    muted_radon[:, ip] = 0\n",
    "        \n",
    "        elif mute_type == 'outer':\n",
    "            # Primary Ï†úÍ±∞: p_primary ÏïàÏùò ÏòÅÏó≠ÏùÑ 0ÏúºÎ°ú (Í≤ÄÏ¶ùÏö©)\n",
    "            for ip, p in enumerate(param_values):\n",
    "                if p_primary_min <= p <= p_primary_max:\n",
    "                    muted_radon[:, ip] = 0\n",
    "        \n",
    "        return muted_radon\n",
    "    \n",
    "    def radon_adaptive_filter(self, radon_domain, filter_width=5):\n",
    "        \"\"\"Adaptive filtering in Radon domain\"\"\"\n",
    "        from scipy.ndimage import median_filter\n",
    "        filtered_radon = median_filter(radon_domain, size=(1, filter_width))\n",
    "        return filtered_radon\n",
    "    \n",
    "    def radon_demultiple_improved(self, shot_gather, offsets, \n",
    "                                  radon_type='parabolic',\n",
    "                                  p_min=-0.002, p_max=0.002, n_p=128,\n",
    "                                  q_min=0.0, q_max=0.001, n_q=128,\n",
    "                                  mute_type='inner',\n",
    "                                  p_primary_min=-0.0005, p_primary_max=0.0005,\n",
    "                                  apply_adaptive_filter=False):\n",
    "        \"\"\"Í∞úÏÑ†Îêú Radon Transform Multiple Attenuation (SEG Wiki ÌëúÏ§Ä)\n",
    "        \n",
    "        ÏõåÌÅ¨ÌîåÎ°úÏö∞:\n",
    "        1. Forward Radon Transform (Linear ÎòêÎäî Parabolic)\n",
    "        2. Radon DomainÏóêÏÑú Multiple Mute\n",
    "        3. (ÏÑ†ÌÉù) Adaptive Filtering\n",
    "        4. Inverse Radon Transform\n",
    "        \"\"\"\n",
    "        # Step 1: Forward Transform\n",
    "        if radon_type == 'parabolic':\n",
    "            radon_original, param_values = self.radon_forward_parabolic(\n",
    "                shot_gather, offsets, q_min, q_max, n_q\n",
    "            )\n",
    "        else:  # linear\n",
    "            radon_original, param_values = self.radon_forward_linear(\n",
    "                shot_gather, offsets, p_min, p_max, n_p\n",
    "            )\n",
    "        \n",
    "        # Step 2: Mute multiples\n",
    "        radon_muted = self.radon_mute_multiples(\n",
    "            radon_original, param_values, mute_type, p_primary_min, p_primary_max\n",
    "        )\n",
    "        \n",
    "        # Step 3: (Optional) Adaptive filtering\n",
    "        if apply_adaptive_filter:\n",
    "            radon_filtered = self.radon_adaptive_filter(radon_muted)\n",
    "        else:\n",
    "            radon_filtered = radon_muted\n",
    "        \n",
    "        # Step 4: Inverse Transform\n",
    "        if radon_type == 'parabolic':\n",
    "            result = self.radon_inverse_parabolic(\n",
    "                radon_filtered, param_values, offsets, self.nt\n",
    "            )\n",
    "        else:  # linear\n",
    "            result = self.radon_inverse_linear(\n",
    "                radon_filtered, param_values, offsets, self.nt\n",
    "            )\n",
    "        \n",
    "        return result, radon_original, radon_filtered, param_values\n",
    "    \n",
    "    def remove_direct_wave_fk(self, shot_gather, offsets, model, velocity_tolerance=100):\n",
    "        \"\"\"FK DomainÏóêÏÑú ÏßÅÏ†ëÌåå Ï†úÍ±∞ (Ïã†Ìò∏ Î≥¥Ï°¥)\n",
    "        \n",
    "        Top mute ÎåÄÏã† FK domain ÌïÑÌÑ∞ÎßÅ:\n",
    "        - ÏßÅÏ†ëÌåå ÏÜçÎèÑ Ï£ºÎ≥ÄÎßå ÏÑ†ÌÉùÏ†Å Ï†úÍ±∞\n",
    "        - TaperÎ°ú Î∂ÄÎìúÎü¨Ïö¥ Ï†ÑÌôò\n",
    "        - ÏñïÏùÄ Î∞òÏÇ¨Ìåå ÏÜêÏã§ ÏµúÏÜåÌôî\n",
    "        \"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        \n",
    "        water_velocity = model['velocity'][0]\n",
    "        \n",
    "        # 2D FFT (t-x -> f-k)\n",
    "        fft2d = np.fft.fft2(shot_gather)\n",
    "        fft2d_filtered = fft2d.copy()\n",
    "        \n",
    "        freqs = np.fft.fftfreq(nt, self.dt)\n",
    "        dx = np.mean(np.diff(offsets))\n",
    "        kx = np.fft.fftfreq(n_traces, dx)\n",
    "        \n",
    "        for i_freq in range(nt):\n",
    "            freq = freqs[i_freq]\n",
    "            if abs(freq) < 1e-6:\n",
    "                continue\n",
    "            \n",
    "            for i_kx in range(n_traces):\n",
    "                k = kx[i_kx]\n",
    "                \n",
    "                if abs(k) > 1e-6:\n",
    "                    velocity = abs(2 * np.pi * freq / k)\n",
    "                else:\n",
    "                    velocity = 1e9\n",
    "                \n",
    "                if abs(velocity - water_velocity) < velocity_tolerance:\n",
    "                    velocity_diff = abs(velocity - water_velocity)\n",
    "                    taper = velocity_diff / velocity_tolerance\n",
    "                    taper = 0.5 * (1 - np.cos(np.pi * taper))\n",
    "                    fft2d_filtered[i_freq, i_kx] *= taper\n",
    "        \n",
    "        result = np.real(np.fft.ifft2(fft2d_filtered))\n",
    "        return result\n",
    "    \n",
    "    def radon_forward_highres(self, shot_gather, offsets, p_min=-0.003, p_max=0.003, n_p=128, damping=0.01):\n",
    "        \"\"\"High-resolution Linear Radon Transform\n",
    "        \n",
    "        Í∞úÏÑ†Ï†ê:\n",
    "        - L2 regularization (damping)\n",
    "        - Proper amplitude scaling\n",
    "        - Artifacts Í∞êÏÜå\n",
    "        \"\"\"\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        p_values = np.linspace(p_min, p_max, n_p)\n",
    "        radon_domain = np.zeros((nt, n_p))\n",
    "        \n",
    "        amp_scale = np.sqrt(1.0 + (offsets / np.max(offsets))**2)\n",
    "        \n",
    "        for ip, p in enumerate(p_values):\n",
    "            for ix, offset in enumerate(offsets):\n",
    "                for it in range(nt):\n",
    "                    tau = self.time[it]\n",
    "                    t = tau - p * offset\n",
    "                    t_idx = t / self.dt\n",
    "                    \n",
    "                    if 0 <= t_idx < nt - 1:\n",
    "                        idx_low = int(np.floor(t_idx))\n",
    "                        idx_high = idx_low + 1\n",
    "                        weight = t_idx - idx_low\n",
    "                        value = (1 - weight) * shot_gather[idx_low, ix] + weight * shot_gather[idx_high, ix]\n",
    "                        radon_domain[it, ip] += value * amp_scale[ix]\n",
    "        \n",
    "        radon_domain /= (n_traces + damping * n_traces)\n",
    "        return radon_domain, p_values\n",
    "    \n",
    "    def radon_inverse_highres(self, radon_domain, p_values, offsets, nt, damping=0.01):\n",
    "        \"\"\"High-resolution Inverse Linear Radon Transform\"\"\"\n",
    "        n_p = len(p_values)\n",
    "        n_traces = len(offsets)\n",
    "        result = np.zeros((nt, n_traces))\n",
    "        \n",
    "        amp_scale = np.sqrt(1.0 + (offsets / np.max(offsets))**2)\n",
    "        \n",
    "        for ix, offset in enumerate(offsets):\n",
    "            for ip, p in enumerate(p_values):\n",
    "                for it in range(nt):\n",
    "                    t = self.time[it]\n",
    "                    tau = t + p * offset\n",
    "                    tau_idx = tau / self.dt\n",
    "                    \n",
    "                    if 0 <= tau_idx < nt - 1:\n",
    "                        idx_low = int(np.floor(tau_idx))\n",
    "                        idx_high = idx_low + 1\n",
    "                        weight = tau_idx - idx_low\n",
    "                        value = (1 - weight) * radon_domain[idx_low, ip] + weight * radon_domain[idx_high, ip]\n",
    "                        result[it, ix] += value * amp_scale[ix]\n",
    "        \n",
    "        result /= (n_p + damping * n_p)\n",
    "        return result\n",
    "    \n",
    "    def radon_mute_velocity_model(self, radon_domain, p_values, model, safety_margin=0.1, mute_multiples=True):\n",
    "        \"\"\"ÏÜçÎèÑ Î™®Îç∏ Í∏∞Î∞ò Radon Mute\n",
    "        \n",
    "        Í∞Å Ï∏µÏùò RMS ÏÜçÎèÑÎ°ú Primary/Multiple ÏòÅÏó≠ ÏûêÎèô Í≥ÑÏÇ∞\n",
    "        \"\"\"\n",
    "        muted_radon = radon_domain.copy()\n",
    "        \n",
    "        velocities = np.array(model['velocity'])\n",
    "        thicknesses = np.array(model['thickness'])\n",
    "        \n",
    "        # RMS velocity Í≥ÑÏÇ∞\n",
    "        rms_velocities = []\n",
    "        for i in range(len(velocities)):\n",
    "            times = [thicknesses[j] / velocities[j] for j in range(i + 1)]\n",
    "            numerator = sum(velocities[j]**2 * times[j] for j in range(i + 1))\n",
    "            denominator = sum(times)\n",
    "            v_rms = np.sqrt(numerator / denominator) if denominator > 0 else velocities[i]\n",
    "            rms_velocities.append(v_rms)\n",
    "        \n",
    "        v_min_rms = min(rms_velocities[1:])\n",
    "        v_max_rms = max(rms_velocities[1:])\n",
    "        \n",
    "        p_primary_min = -1.0 / v_max_rms * (1 + safety_margin)\n",
    "        p_primary_max = 1.0 / v_max_rms * (1 + safety_margin)\n",
    "        \n",
    "        water_velocity = model['velocity'][0]\n",
    "        p_multiple_threshold = 1.0 / water_velocity * (1 - safety_margin)\n",
    "        \n",
    "        print(f\"   - RMS Velocity: {v_min_rms:.1f} - {v_max_rms:.1f} m/s\")\n",
    "        print(f\"   - Primary p: [{p_primary_min*1000:.4f}, {p_primary_max*1000:.4f}] √ó 10‚Åª¬≥\")\n",
    "        print(f\"   - Multiple threshold: |p| > {p_multiple_threshold*1000:.4f} √ó 10‚Åª¬≥\")\n",
    "        \n",
    "        if mute_multiples:\n",
    "            for ip, p in enumerate(p_values):\n",
    "                if not (p_primary_min <= p <= p_primary_max):\n",
    "                    if p < p_primary_min:\n",
    "                        distance = abs(p - p_primary_min)\n",
    "                    else:\n",
    "                        distance = abs(p - p_primary_max)\n",
    "                    \n",
    "                    taper_width = abs(p_primary_max - p_primary_min) * 0.2\n",
    "                    if distance < taper_width:\n",
    "                        taper = distance / taper_width\n",
    "                        muted_radon[:, ip] *= taper\n",
    "                    else:\n",
    "                        muted_radon[:, ip] = 0\n",
    "        else:\n",
    "            for ip, p in enumerate(p_values):\n",
    "                if p_primary_min <= p <= p_primary_max:\n",
    "                    muted_radon[:, ip] = 0\n",
    "        \n",
    "        return muted_radon, (p_primary_min, p_primary_max)\n",
    "    \n",
    "    def radon_demultiple_velocity_based(self, shot_gather, offsets, model,\n",
    "                                        radon_type='linear',\n",
    "                                        p_min=-0.003, p_max=0.003, n_p=128,\n",
    "                                        damping=0.01, safety_margin=0.1,\n",
    "                                        mute_multiples=True):\n",
    "        \"\"\"ÏÜçÎèÑ Î™®Îç∏ Í∏∞Î∞ò Radon Multiple Attenuation\n",
    "        \n",
    "        Í∞úÏÑ†Ï†ê:\n",
    "        1. ÏÜçÎèÑ Î™®Îç∏Î°ú Primary/Multiple ÏòÅÏó≠ ÏûêÎèô Í≥ÑÏÇ∞\n",
    "        2. High-resolution Radon with damping\n",
    "        3. Proper amplitude scaling\n",
    "        \"\"\"\n",
    "        if radon_type == 'parabolic':\n",
    "            radon_original, param_values = self.radon_forward_parabolic(shot_gather, offsets, 0.0, 0.001, n_p)\n",
    "        else:\n",
    "            radon_original, param_values = self.radon_forward_highres(shot_gather, offsets, p_min, p_max, n_p, damping)\n",
    "        \n",
    "        radon_filtered, p_primary_bounds = self.radon_mute_velocity_model(\n",
    "            radon_original, param_values, model, safety_margin, mute_multiples\n",
    "        )\n",
    "        \n",
    "        if radon_type == 'parabolic':\n",
    "            result = self.radon_inverse_parabolic(radon_filtered, param_values, offsets, self.nt)\n",
    "        else:\n",
    "            result = self.radon_inverse_highres(radon_filtered, param_values, offsets, self.nt, damping)\n",
    "        \n",
    "        return result, radon_original, radon_filtered, param_values, p_primary_bounds\n",
    "    \n",
    "    def anomalous_amplitude_attenuation(self, shot_gather, window_size=50, threshold_factor=3.0):\n",
    "        \"\"\"Anomalous Amplitude Attenuation (Ïù¥ÏÉÅ ÏßÑÌè≠ Í∞êÏá†)\"\"\"\n",
    "        result = shot_gather.copy()\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        \n",
    "        # Í∞Å Ìä∏Î†àÏù¥Ïä§Ïóê ÎåÄÌï¥\n",
    "        for ix in range(n_traces):\n",
    "            trace = shot_gather[:, ix]\n",
    "            \n",
    "            # Ïù¥Îèô ÏúàÎèÑÏö∞Î°ú Î°úÏª¨ ÌÜµÍ≥Ñ Í≥ÑÏÇ∞\n",
    "            for it in range(0, nt, window_size//2):\n",
    "                window_start = max(0, it - window_size//2)\n",
    "                window_end = min(nt, it + window_size//2)\n",
    "                window = trace[window_start:window_end]\n",
    "                \n",
    "                # Î°úÏª¨ ÌèâÍ∑† Î∞è ÌëúÏ§ÄÌé∏Ï∞®\n",
    "                local_mean = np.mean(window)\n",
    "                local_std = np.std(window)\n",
    "                \n",
    "                # Ïù¥ÏÉÅ ÏßÑÌè≠ ÌÉêÏßÄ Î∞è Í∞êÏá†\n",
    "                for i in range(window_start, window_end):\n",
    "                    if abs(trace[i] - local_mean) > threshold_factor * local_std:\n",
    "                        # Ïù¥ÏÉÅ ÏßÑÌè≠ÏùÑ Î°úÏª¨ ÌèâÍ∑†ÏúºÎ°ú ÎåÄÏ≤¥ (Î∂ÄÎìúÎüΩÍ≤å)\n",
    "                        excess = trace[i] - local_mean\n",
    "                        attenuation = np.exp(-abs(excess) / (threshold_factor * local_std))\n",
    "                        result[i, ix] = local_mean + excess * attenuation\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def curvelet_denoise(self, shot_gather, wavelet='db4', level=None, threshold_scale=1.5, return_coeffs=False):\n",
    "        \"\"\"Curvelet Í∏∞Î∞ò ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ (Wavelet Í∑ºÏÇ¨) - ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï Í∞ÄÎä•\"\"\"\n",
    "        result = np.zeros_like(shot_gather)\n",
    "        nt, n_traces = shot_gather.shape\n",
    "        \n",
    "        # Í∞Å Ìä∏Î†àÏù¥Ïä§Ïóê Wavelet Denoising Ï†ÅÏö©\n",
    "        for ix in range(n_traces):\n",
    "            trace = shot_gather[:, ix]\n",
    "            \n",
    "            # Wavelet decomposition\n",
    "            if level is None:\n",
    "                level = pywt.dwt_max_level(len(trace), wavelet)\n",
    "            \n",
    "            coeffs = pywt.wavedec(trace, wavelet, level=level)\n",
    "            \n",
    "            # Threshold estimation (Donoho)\n",
    "            sigma = np.median(np.abs(coeffs[-1])) / 0.6745\n",
    "            threshold = threshold_scale * sigma * np.sqrt(2 * np.log(len(trace)))\n",
    "            \n",
    "            # Soft thresholding\n",
    "            coeffs_thresh = [coeffs[0]]  # approximation coefficients\n",
    "            for i in range(1, len(coeffs)):\n",
    "                coeffs_thresh.append(pywt.threshold(coeffs[i], threshold, mode='soft'))\n",
    "            \n",
    "            # Reconstruction\n",
    "            result[:, ix] = pywt.waverec(coeffs_thresh, wavelet)[:nt]\n",
    "        \n",
    "        # 2D Wavelet denoising (Î∞©Ìñ•ÏÑ± Í≥†Î†§)\n",
    "        coeffs2d_original = None\n",
    "        coeffs2d_thresh = None\n",
    "        threshold2d = 0.0  # Default value in case 2D transform fails\n",
    "        \n",
    "        try:\n",
    "            # 2D stationary wavelet transform\n",
    "            coeffs2d_original = pywt.swt2(shot_gather, wavelet, level=3)\n",
    "            \n",
    "            # Threshold\n",
    "            sigma2d = np.median(np.abs(coeffs2d_original[-1][1])) / 0.6745\n",
    "            threshold2d = threshold_scale * sigma2d * np.sqrt(2 * np.log(nt * n_traces))\n",
    "            \n",
    "            # Apply thresholding\n",
    "            coeffs2d_thresh = []\n",
    "            for c in coeffs2d_original:\n",
    "                cA = c[0]\n",
    "                cH = pywt.threshold(c[1][0], threshold2d, mode='soft')\n",
    "                cV = pywt.threshold(c[1][1], threshold2d, mode='soft')\n",
    "                cD = pywt.threshold(c[1][2], threshold2d, mode='soft')\n",
    "                coeffs2d_thresh.append((cA, (cH, cV, cD)))\n",
    "            \n",
    "            # Reconstruction\n",
    "            result = pywt.iswt2(coeffs2d_thresh, wavelet)[:nt, :n_traces]\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: 2D wavelet transform failed ({str(e)}), using 1D result\")\n",
    "        \n",
    "        if return_coeffs:\n",
    "            return result, coeffs2d_original, coeffs2d_thresh, threshold2d\n",
    "        else:\n",
    "            return result\n",
    "    \n",
    "    def plot_model(self, model: Dict):\n",
    "        \"\"\"ÏßÄÏ∏µ Î™®Îç∏ ÏãúÍ∞ÅÌôî\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 8))\n",
    "        \n",
    "        depths = model['depth']\n",
    "        velocities = model['velocity']\n",
    "        densities = model['density']\n",
    "        \n",
    "        for i in range(len(depths)):\n",
    "            depth_top = depths[i]\n",
    "            depth_bottom = depths[i] + model['thickness'][i]\n",
    "            \n",
    "            ax1.fill_between([velocities[i]-100, velocities[i]+100],\n",
    "                            depth_top, depth_bottom,\n",
    "                            alpha=0.4, label=model['name'][i] if i < 5 else None)\n",
    "            ax1.plot([velocities[i], velocities[i]], [depth_top, depth_bottom],\n",
    "                    'b-', linewidth=2.5)\n",
    "            \n",
    "            ax2.fill_between([densities[i]-50, densities[i]+50],\n",
    "                            depth_top, depth_bottom,\n",
    "                            alpha=0.4)\n",
    "            ax2.plot([densities[i], densities[i]], [depth_top, depth_bottom],\n",
    "                    'r-', linewidth=2.5)\n",
    "        \n",
    "        ax1.set_xlabel('Velocity (m/s)', fontsize=13, fontweight='bold')\n",
    "        ax1.set_ylabel('Depth (m)', fontsize=13, fontweight='bold')\n",
    "        ax1.set_title('Velocity Model', fontsize=15, fontweight='bold')\n",
    "        ax1.invert_yaxis()\n",
    "        ax1.grid(True, alpha=0.4)\n",
    "        ax1.legend(fontsize=10)\n",
    "        \n",
    "        ax2.set_xlabel('Density (kg/m¬≥)', fontsize=13, fontweight='bold')\n",
    "        ax2.set_ylabel('Depth (m)', fontsize=13, fontweight='bold')\n",
    "        ax2.set_title('Density Model', fontsize=15, fontweight='bold')\n",
    "        ax2.invert_yaxis()\n",
    "        ax2.grid(True, alpha=0.4)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_shot_gather(self, shot_gather, offsets, title: str = \"Shot Gather\", clip_percentile: float = 99):\n",
    "        \"\"\"Shot Gather ÏãúÍ∞ÅÌôî\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(14, 10))\n",
    "        vmax = np.percentile(np.abs(shot_gather), clip_percentile)\n",
    "        \n",
    "        for i, offset in enumerate(offsets):\n",
    "            trace = shot_gather[:, i]\n",
    "            trace_scaled = trace / vmax * 30\n",
    "            ax.plot(offset + trace_scaled, self.time, 'k-', linewidth=0.3)\n",
    "            ax.fill_betweenx(self.time, offset, offset + trace_scaled,\n",
    "                            where=(trace_scaled > 0), color='black', alpha=0.6)\n",
    "        \n",
    "        ax.set_xlabel('Offset (m)', fontsize=13, fontweight='bold')\n",
    "        ax.set_ylabel('Time (s)', fontsize=13, fontweight='bold')\n",
    "        ax.set_title(title, fontsize=15, fontweight='bold')\n",
    "        ax.invert_yaxis()\n",
    "        ax.grid(True, alpha=0.3, linestyle='--')\n",
    "        ax.set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_comparison_5(self, data1, data2, data3, data4, data5, offsets, titles):\n",
    "        \"\"\"5Í∞ú ÎπÑÍµê\"\"\"\n",
    "        fig, axes = plt.subplots(1, 5, figsize=(28, 10))\n",
    "        data_list = [data1, data2, data3, data4, data5]\n",
    "        vmax = np.percentile(np.abs(data1), 99)\n",
    "        \n",
    "        for ax, data, title in zip(axes, data_list, titles):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                trace = data[:, i]\n",
    "                trace_scaled = trace / vmax * 30\n",
    "                ax.plot(offset + trace_scaled, self.time, 'k-', linewidth=0.3)\n",
    "                ax.fill_betweenx(self.time, offset, offset + trace_scaled,\n",
    "                                where=(trace_scaled > 0), color='black', alpha=0.6)\n",
    "            \n",
    "            ax.set_xlabel('Offset (m)', fontsize=10, fontweight='bold')\n",
    "            ax.set_ylabel('Time (s)', fontsize=10, fontweight='bold')\n",
    "            ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "            ax.invert_yaxis()\n",
    "            ax.grid(True, alpha=0.3, linestyle='--')\n",
    "            ax.set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"‚úÖ AdvancedMarineProcessor ÌÅ¥ÎûòÏä§ Ï†ïÏùò ÏôÑÎ£å!\")\n",
    "print(\"\\n‚≠ê Í≥†Í∏â Ï≤òÎ¶¨ Í∏∞Î≤ï:\")\n",
    "print(\"  1. Water Bottom Demultiple\")\n",
    "print(\"  2. Radon Transform Demultiple\")\n",
    "print(\"  3. Anomalous Amplitude Attenuation\")\n",
    "print(\"  4. Curvelet Denoise\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step2"
   },
   "source": [
    "## üåç Step 2: ÎûúÎç§ Ìï©ÏÑ± Î™®Îç∏ ÏÉùÏÑ±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_model"
   },
   "outputs": [],
   "source": [
    "processor = AdvancedMarineProcessor(dt=0.002, nt=1500)\n",
    "print(\"‚úÖ Í≥†Í∏â ÌîÑÎ°úÏÑ∏ÏÑú Ï¥àÍ∏∞Ìôî ÏôÑÎ£å\")\n",
    "print(f\"   - ÏÉòÌîåÎßÅ Í∞ÑÍ≤©: {processor.dt*1000:.1f} ms\")\n",
    "print(f\"   - ÏãúÍ∞Ñ ÏÉòÌîå: {processor.nt}Í∞ú\")\n",
    "print(f\"   - Ï¥ù ÏãúÍ∞Ñ: {processor.time[-1]:.2f} s\")\n",
    "print()\n",
    "\n",
    "print(\"üåç ÎûúÎç§ Ìï©ÏÑ± ÏßÄÎ∞ò Î™®Îç∏ ÏÉùÏÑ± Ï§ë...\")\n",
    "model = processor.create_random_model(nlayers=6)\n",
    "print(\"‚úÖ Î™®Îç∏ ÏÉùÏÑ± ÏôÑÎ£å!\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä ÏÉùÏÑ±Îêú ÏßÄÏ∏µ Ï†ïÎ≥¥\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Layer':<15} {'Depth (m)':<12} {'Thickness (m)':<15} {'Velocity (m/s)':<15} {'Density (kg/m¬≥)'}\")\n",
    "print(\"-\"*80)\n",
    "for i in range(len(model['name'])):\n",
    "    print(f\"{model['name'][i]:<15} {model['depth'][i]:<12.1f} {model['thickness'][i]:<15.1f} \"\n",
    "          f\"{model['velocity'][i]:<15.1f} {model['density'][i]:<15.1f}\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "processor.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step3"
   },
   "source": [
    "## üéØ Step 3-6: Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ± (Clean ‚Üí Direct ‚Üí Multiples ‚Üí Noise)\n",
    "\n",
    "**Ìïú Î≤àÏóê Ïã§ÌñâÌïòÏó¨ Í∏∞Î≥∏ Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "generate_data"
   },
   "outputs": [],
   "source": [
    "print(\"üéØ Shot Gather ÏÉùÏÑ± ÌååÏù¥ÌîÑÎùºÏù∏...\")\n",
    "print()\n",
    "\n",
    "# Í∏∞Î≥∏ ÌååÎùºÎØ∏ÌÑ∞\n",
    "n_traces = 48\n",
    "offset_min = 100\n",
    "offset_max = 2400\n",
    "freq = 25.0\n",
    "\n",
    "# Step 3: Clean Shot Gather\n",
    "print(\"[1/4] Clean Shot Gather ÏÉùÏÑ±...\")\n",
    "clean_shot, offsets = processor.generate_shot_gather(model, n_traces=n_traces, \n",
    "                                                      offset_min=offset_min, \n",
    "                                                      offset_max=offset_max, freq=freq)\n",
    "print(f\"   ‚úÖ RMS: {np.sqrt(np.mean(clean_shot**2)):.6f}\")\n",
    "\n",
    "# Step 4: ÏßÅÏ†ëÌåå Ï∂îÍ∞Ä\n",
    "print(\"[2/4] ÏßÅÏ†ëÌåå Ï∂îÍ∞Ä...\")\n",
    "with_direct = processor.add_direct_wave(clean_shot, offsets, model, strength=0.3)\n",
    "print(f\"   ‚úÖ RMS: {np.sqrt(np.mean(with_direct**2)):.6f}\")\n",
    "\n",
    "# Step 5: Multiple Ï∂îÍ∞Ä\n",
    "print(\"[3/4] Multiple Ï∂îÍ∞Ä (Ìï¥Î©¥ + ÎÇ¥Î∂Ä)...\")\n",
    "with_sea_mult = processor.add_sea_surface_multiple(with_direct, model, strength=0.5)\n",
    "with_multiples = processor.add_internal_multiples(with_sea_mult, model, strength=0.3)\n",
    "print(f\"   ‚úÖ RMS: {np.sqrt(np.mean(with_multiples**2)):.6f}\")\n",
    "\n",
    "# Step 6: Ìï¥ÏÉÅ ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä\n",
    "print(\"[4/4] Ìï¥ÏÉÅ ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä...\")\n",
    "noisy_shot = processor.add_marine_noise(with_multiples, offsets, noise_level=0.10)\n",
    "print(f\"   ‚úÖ RMS: {np.sqrt(np.mean(noisy_shot**2)):.6f}\")\n",
    "print()\n",
    "\n",
    "# ÌÜµÍ≥Ñ\n",
    "noise = noisy_shot - with_multiples\n",
    "snr_initial = 20 * np.log10(np.std(with_multiples) / np.std(noise))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä Ï¥àÍ∏∞ Îç∞Ïù¥ÌÑ∞ ÌÜµÍ≥Ñ\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Signal RMS (Multiples):  {np.sqrt(np.mean(with_multiples**2)):.6f}\")\n",
    "print(f\"Noisy RMS:               {np.sqrt(np.mean(noisy_shot**2)):.6f}\")\n",
    "print(f\"SNR:                     {snr_initial:.2f} dB\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî\n",
    "print(\"üìà ÎÖ∏Ïù¥Ï¶àÍ∞Ä Ï∂îÍ∞ÄÎêú Shot Gather ÏãúÍ∞ÅÌôî...\")\n",
    "processor.plot_shot_gather(noisy_shot, offsets, \"üì¢ Noisy Shot Gather (Input)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step9"
   },
   "source": [
    "## ‚ö° Step 7: Anomalous Amplitude Attenuation\n",
    "\n",
    "**Ïù¥ ÏÖÄÏùÑ Ïã§ÌñâÌïòÎ©¥:**\n",
    "- Ïù¥Îèô ÏúàÎèÑÏö∞Î°ú Î°úÏª¨ ÌÜµÍ≥Ñ Í≥ÑÏÇ∞\n",
    "- Ïù¥ÏÉÅ ÏßÑÌè≠ ÌÉêÏßÄ (ÏûÑÍ≥ÑÍ∞í Ï¥àÍ≥º)\n",
    "- ÏßÄÏàò Í∞êÏá†Î°ú Î∂ÄÎìúÎüΩÍ≤å ÏñµÏ†ú\n",
    "- Ï¶âÏãú ÏãúÍ∞ÅÌôî"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aaa"
   },
   "outputs": [],
   "source": [
    "print(\"‚ö° Anomalous Amplitude Attenuation Ï†ÅÏö© Ï§ë...\")\n",
    "print()\n",
    "print(\"Ï≤òÎ¶¨ Î∞©Î≤ï:\")\n",
    "print(\"   - Ïù¥Îèô ÏúàÎèÑÏö∞ ÌÜµÍ≥Ñ (ÌèâÍ∑†, ÌëúÏ§ÄÌé∏Ï∞®)\")\n",
    "print(\"   - Ïù¥ÏÉÅ ÏßÑÌè≠ ÌÉêÏßÄ (> 3œÉ)\")\n",
    "print(\"   - ÏßÄÏàò Í∞êÏá† Ï†ÅÏö©\")\n",
    "print()\n",
    "\n",
    "# Anomalous Amplitude Attenuation\n",
    "after_aaa = processor.anomalous_amplitude_attenuation(noisy_shot, \n",
    "                                                       window_size=50, \n",
    "                                                       threshold_factor=3.0)\n",
    "\n",
    "print(\"‚úÖ Anomalous Amplitude Attenuation ÏôÑÎ£å!\")\n",
    "print()\n",
    "\n",
    "# ÌÜµÍ≥Ñ\n",
    "removed_anom = noisy_shot - after_aaa\n",
    "\n",
    "print(\"üìà ÌÜµÍ≥Ñ:\")\n",
    "print(f\"   - Before AAA RMS: {np.sqrt(np.mean(noisy_shot**2)):.6f}\")\n",
    "print(f\"   - After AAA RMS:  {np.sqrt(np.mean(after_aaa**2)):.6f}\")\n",
    "print(f\"   - Attenuated RMS: {np.sqrt(np.mean(removed_anom**2)):.6f}\")\n",
    "print(f\"   - Anomaly Reduction: {(np.sqrt(np.mean(removed_anom**2))/np.sqrt(np.mean(noisy_shot**2)))*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî\n",
    "print(\"üìà Anomalous Amplitude Attenuation Í≤∞Í≥º ÏãúÍ∞ÅÌôî...\")\n",
    "processor.plot_shot_gather(after_aaa, offsets, \"‚ö° After Anomalous Amplitude Attenuation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step8"
   },
   "source": [
    "## üîä Step 8: Low-cut Filter (1.5 Hz)\n",
    "\n",
    "**Ïù¥ ÏÖÄÏùÑ Ïã§ÌñâÌïòÎ©¥:**\n",
    "- High-pass (Low-cut) ÌïÑÌÑ∞ Ï†ÅÏö©\n",
    "- 1.5 Hz Ïù¥Ìïò Ï†ÄÏ£ºÌåå ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞\n",
    "- Swell noise, Ship noise Ï†ÄÏ£ºÌåå ÏÑ±Î∂Ñ Ï†úÍ±∞\n",
    "- **ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï**: `cutoff_freq`, `filter_order`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lowcut"
   },
   "outputs": [],
   "source": [
    "print(\"üîä Low-cut Filter Ï†ÅÏö© Ï§ë...\")\n",
    "print()\n",
    "print(\"Ï≤òÎ¶¨ Î∞©Î≤ï:\")\n",
    "print(\"   - Butterworth High-pass Filter\")\n",
    "print(\"   - Ï†ÄÏ£ºÌåå ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ (Swell, Ship)\")\n",
    "print(\"   - Zero-phase filtering (filtfilt)\")\n",
    "print()\n",
    "print(\"‚öôÔ∏è ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï Í∞ÄÎä•:\")\n",
    "print(\"   - cutoff_freq: Cutoff Ï£ºÌååÏàò (Í∏∞Î≥∏ 1.5 Hz)\")\n",
    "print(\"   - filter_order: ÌïÑÌÑ∞ Ï∞®Ïàò (Í∏∞Î≥∏ 5)\")\n",
    "print()\n",
    "\n",
    "# üîß Ïó¨Í∏∞ÏÑú ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï!\n",
    "cutoff_freq = 1.5  # Hz, Ïù¥ Ï£ºÌååÏàò Ïù¥ÌïòÎ•º Ï†úÍ±∞ (Ïòà: 1.0, 1.5, 2.0, 3.0)\n",
    "filter_order = 5   # ÌïÑÌÑ∞ Ï∞®Ïàò, ÎÜíÏùÑÏàòÎ°ù sharp (Ïòà: 3, 5, 7)\n",
    "\n",
    "print(f\"\\nüìå ÌòÑÏû¨ ÌååÎùºÎØ∏ÌÑ∞:\")\n",
    "print(f\"   - Cutoff Frequency: {cutoff_freq} Hz\")\n",
    "print(f\"   - Filter Order: {filter_order}\")\n",
    "print()\n",
    "\n",
    "# Low-cut Filter\n",
    "after_lowcut = processor.lowcut_filter(after_aaa, cutoff_freq=cutoff_freq, order=filter_order)\n",
    "\n",
    "print(\"‚úÖ Low-cut Filter ÏôÑÎ£å!\")\n",
    "print()\n",
    "\n",
    "# ÌÜµÍ≥Ñ\n",
    "removed_lowfreq = after_aaa - after_lowcut\n",
    "\n",
    "print(\"üìà ÌÜµÍ≥Ñ:\")\n",
    "print(f\"   - Before Lowcut RMS: {np.sqrt(np.mean(after_aaa**2)):.6f}\")\n",
    "print(f\"   - After Lowcut RMS:  {np.sqrt(np.mean(after_lowcut**2)):.6f}\")\n",
    "print(f\"   - Removed Low-freq RMS: {np.sqrt(np.mean(removed_lowfreq**2)):.6f}\")\n",
    "print(f\"   - Energy Reduction: {(np.sqrt(np.mean(removed_lowfreq**2))/np.sqrt(np.mean(after_aaa**2)))*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# Ï£ºÌååÏàò Ïä§ÌéôÌä∏Îüº ÎπÑÍµê\n",
    "print(\"üìä Ï£ºÌååÏàò Ïä§ÌéôÌä∏Îüº ÎπÑÍµê...\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Before lowcut - frequency spectrum\n",
    "trace_before = after_aaa[:, after_aaa.shape[1]//2]  # Middle trace\n",
    "fft_before = np.fft.rfft(trace_before)\n",
    "freq = np.fft.rfftfreq(len(trace_before), processor.dt)\n",
    "power_before = np.abs(fft_before)**2\n",
    "\n",
    "# After lowcut - frequency spectrum\n",
    "trace_after = after_lowcut[:, after_lowcut.shape[1]//2]\n",
    "fft_after = np.fft.rfft(trace_after)\n",
    "power_after = np.abs(fft_after)**2\n",
    "\n",
    "axes[0].semilogy(freq, power_before, \"b-\", label=\"Before Lowcut\", linewidth=1.5, alpha=0.7)\n",
    "axes[0].semilogy(freq, power_after, \"r-\", label=\"After Lowcut\", linewidth=1.5, alpha=0.7)\n",
    "axes[0].axvline(cutoff_freq, color=\"green\", linestyle=\"--\", linewidth=2, label=f\"Cutoff ({cutoff_freq} Hz)\")\n",
    "axes[0].set_xlabel(\"Frequency (Hz)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0].set_ylabel(\"Power\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0].set_title(\"Frequency Spectrum (Ï§ëÏïô Ìä∏Î†àÏù¥Ïä§)\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0].set_xlim([0, 100])\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend(fontsize=11)\n",
    "\n",
    "# Shot gather comparison\n",
    "for i, offset in enumerate(offsets):\n",
    "    trace = after_lowcut[:, i]\n",
    "    vmax = np.percentile(np.abs(after_lowcut), 99)\n",
    "    trace_scaled = trace / vmax * 30\n",
    "    axes[1].plot(offset + trace_scaled, processor.time, \"k-\", linewidth=0.3)\n",
    "    axes[1].fill_betweenx(processor.time, offset, offset + trace_scaled,\n",
    "                         where=(trace_scaled > 0), color=\"black\", alpha=0.6)\n",
    "\n",
    "axes[1].set_xlabel(\"Offset (m)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1].set_ylabel(\"Time (s)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1].set_title(\"After Low-cut Filter\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(True, alpha=0.3, linestyle=\"--\")\n",
    "axes[1].set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"üí° Ìï¥ÏÑù:\")\n",
    "print(\"   - Ï¢åÏ∏°: 1.5 Hz Ïù¥Ìïò Ï†ÄÏ£ºÌååÍ∞Ä Ï†úÍ±∞ÎêòÏóàÏùåÏùÑ ÌôïÏù∏\")\n",
    "print(\"   - Ïö∞Ï∏°: Swell noise, Ship noise Ï†ÄÏ£ºÌåå ÏÑ±Î∂Ñ Í∞êÏÜå\")\n",
    "print()\n",
    "print(\"üîß ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï Î∞©Î≤ï:\")\n",
    "print(\"   - cutoff_freq ‚Üë ‚Üí Îçî ÎßéÏùÄ Ï†ÄÏ£ºÌåå Ï†úÍ±∞ (Îã®, Ïã†Ìò∏ Ï†ÄÏ£ºÌååÎèÑ ÏÜêÏã§)\")\n",
    "print(\"   - cutoff_freq ‚Üì ‚Üí Ïã†Ìò∏ Î≥¥Ï°¥ Ïö∞ÏÑ† (Ï†ÄÏ£ºÌåå ÎÖ∏Ïù¥Ï¶à ÏûîÏ°¥)\")\n",
    "print(\"   - Í∂åÏû•Í∞í: 1.0 ~ 3.0 Hz Î≤îÏúÑ\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step10"
   },
   "source": [
    "## üåÄ Step 9: Curvelet Denoise (Ïù∏ÌÑ∞ÎûôÌã∞Î∏å)\n",
    "\n",
    "**Ïù¥ ÏÖÄÏùÑ Ïã§ÌñâÌïòÎ©¥:**\n",
    "- 1D Wavelet Î∂ÑÌï¥ (Í∞Å Ìä∏Î†àÏù¥Ïä§)\n",
    "- 2D Stationary Wavelet Transform (Î∞©Ìñ•ÏÑ± Í≥†Î†§)\n",
    "- **Wavelet Í≥ÑÏàò ÏãúÍ∞ÅÌôî** (ÏõêÎ≥∏ + Thresholding)\n",
    "- Soft thresholding\n",
    "- Wavelet Ïû¨Íµ¨ÏÑ±\n",
    "- **ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï**: `threshold_scale`, `wavelet`, `level`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "curvelet"
   },
   "outputs": [],
   "source": [
    "print(\"üåÄ Curvelet Denoise Ï†ÅÏö© Ï§ë...\")\n",
    "print()\n",
    "print(\"Ï≤òÎ¶¨ Î∞©Î≤ï:\")\n",
    "print(\"   - 1D Wavelet Î∂ÑÌï¥ (Í∞Å Ìä∏Î†àÏù¥Ïä§)\")\n",
    "print(\"   - 2D Stationary Wavelet Transform\")\n",
    "print(\"   - Soft thresholding (Donoho)\")\n",
    "print(\"   - Wavelet Ïû¨Íµ¨ÏÑ±\")\n",
    "print()\n",
    "print(\"‚öôÔ∏è ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï Í∞ÄÎä•:\")\n",
    "print(\"   - threshold_scale: Threshold Ïä§ÏºÄÏùºÎßÅ (Í∏∞Î≥∏ 1.5)\")\n",
    "print(\"   - wavelet: Wavelet Ï¢ÖÎ•ò (db4, sym4, coif2 Îì±)\")\n",
    "print(\"   - level: Î∂ÑÌï¥ Î†àÎ≤® (None=ÏûêÎèô)\")\n",
    "print()\n",
    "print(\"‚è≥ Ï≤òÎ¶¨ Ï§ë... (ÏãúÍ∞ÑÏù¥ Í±∏Î¶¥ Ïàò ÏûàÏäµÎãàÎã§)\")\n",
    "\n",
    "# üîß Ïó¨Í∏∞ÏÑú ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï!\n",
    "threshold_scale = 1.5  # ÎÇÆÏ∂îÎ©¥ Îçî ÎßéÏù¥ Ï†úÍ±∞ (Ïòà: 0.5, 1.0, 1.5, 2.0, 2.5)\n",
    "wavelet_type = 'db4'   # 'db4', 'sym4', 'coif2', 'bior2.2' Îì±\n",
    "level = None           # None=ÏûêÎèô, ÎòêÎäî Ï†ïÏàò (Ïòà: 3, 4, 5)\n",
    "\n",
    "print(f\"\\nüìå ÌòÑÏû¨ ÌååÎùºÎØ∏ÌÑ∞:\")\n",
    "print(f\"   - Threshold Scale: {threshold_scale}\")\n",
    "print(f\"   - Wavelet Type: {wavelet_type}\")\n",
    "print(f\"   - Decomposition Level: {level if level else 'Auto'}\")\n",
    "print()\n",
    "\n",
    "# Curvelet Denoise (Í≥ÑÏàò Î∞òÌôò)\n",
    "final_shot, coeffs_original, coeffs_thresh, threshold_value = processor.curvelet_denoise(\n",
    "    after_lowcut, \n",
    "    wavelet=wavelet_type, \n",
    "    level=level, \n",
    "    threshold_scale=threshold_scale,\n",
    "    return_coeffs=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Curvelet Denoise ÏôÑÎ£å!\")\n",
    "print()\n",
    "\n",
    "# ÏµúÏ¢Ö ÌÜµÍ≥Ñ\n",
    "removed_noise = after_lowcut - final_shot\n",
    "final_residual = final_shot - with_direct\n",
    "snr_final = 20 * np.log10(np.std(with_direct) / np.std(final_residual))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä ÏµúÏ¢Ö Í≤∞Í≥º\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Before Curvelet RMS:    {np.sqrt(np.mean(after_lowcut**2)):.6f}\")\n",
    "print(f\"Final RMS:              {np.sqrt(np.mean(final_shot**2)):.6f}\")\n",
    "print(f\"Removed Noise RMS:      {np.sqrt(np.mean(removed_noise**2)):.6f}\")\n",
    "print(f\"Threshold Value:        {threshold_value:.6f}\")\n",
    "print()\n",
    "print(f\"SNR (Ï¥àÍ∏∞):              {snr_initial:.2f} dB\")\n",
    "print(f\"SNR (ÏµúÏ¢Ö):              {snr_final:.2f} dB\")\n",
    "print(f\"SNR Í∞úÏÑ†:                {snr_final - snr_initial:.2f} dB  ‚¨ÜÔ∏è‚¨ÜÔ∏è‚¨ÜÔ∏è\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# üé® Wavelet Í≥ÑÏàò ÏãúÍ∞ÅÌôî\n",
    "if coeffs_original is not None and coeffs_thresh is not None:\n",
    "    print(\"üìä Wavelet Í≥ÑÏàò ÏãúÍ∞ÅÌôî (Level 3, Horizontal/Vertical/Diagonal)...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Level 3 Í≥ÑÏàò Ï∂îÏ∂ú\n",
    "    level_idx = -1  # ÎßàÏßÄÎßâ Î†àÎ≤®\n",
    "    cH_orig = coeffs_original[level_idx][1][0]  # Horizontal\n",
    "    cV_orig = coeffs_original[level_idx][1][1]  # Vertical\n",
    "    cD_orig = coeffs_original[level_idx][1][2]  # Diagonal\n",
    "    \n",
    "    cH_thresh = coeffs_thresh[level_idx][1][0]\n",
    "    cV_thresh = coeffs_thresh[level_idx][1][1]\n",
    "    cD_thresh = coeffs_thresh[level_idx][1][2]\n",
    "    \n",
    "    vmax = np.percentile(np.abs(cH_orig), 99)\n",
    "    \n",
    "    # Original coefficients\n",
    "    im1 = axes[0, 0].imshow(cH_orig, aspect='auto', cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    axes[0, 0].set_title('Original - Horizontal (cH)', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Time', fontsize=11)\n",
    "    axes[0, 0].set_xlabel('Trace', fontsize=11)\n",
    "    plt.colorbar(im1, ax=axes[0, 0])\n",
    "    \n",
    "    im2 = axes[0, 1].imshow(cV_orig, aspect='auto', cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    axes[0, 1].set_title('Original - Vertical (cV)', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Time', fontsize=11)\n",
    "    axes[0, 1].set_xlabel('Trace', fontsize=11)\n",
    "    plt.colorbar(im2, ax=axes[0, 1])\n",
    "    \n",
    "    im3 = axes[0, 2].imshow(cD_orig, aspect='auto', cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    axes[0, 2].set_title('Original - Diagonal (cD)', fontsize=12, fontweight='bold')\n",
    "    axes[0, 2].set_ylabel('Time', fontsize=11)\n",
    "    axes[0, 2].set_xlabel('Trace', fontsize=11)\n",
    "    plt.colorbar(im3, ax=axes[0, 2])\n",
    "    \n",
    "    # Thresholded coefficients\n",
    "    im4 = axes[1, 0].imshow(cH_thresh, aspect='auto', cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    axes[1, 0].set_title(f'Thresholded - Horizontal (scale={threshold_scale})', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('Time', fontsize=11)\n",
    "    axes[1, 0].set_xlabel('Trace', fontsize=11)\n",
    "    plt.colorbar(im4, ax=axes[1, 0])\n",
    "    \n",
    "    im5 = axes[1, 1].imshow(cV_thresh, aspect='auto', cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    axes[1, 1].set_title(f'Thresholded - Vertical (scale={threshold_scale})', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('Time', fontsize=11)\n",
    "    axes[1, 1].set_xlabel('Trace', fontsize=11)\n",
    "    plt.colorbar(im5, ax=axes[1, 1])\n",
    "    \n",
    "    im6 = axes[1, 2].imshow(cD_thresh, aspect='auto', cmap='seismic', vmin=-vmax, vmax=vmax)\n",
    "    axes[1, 2].set_title(f'Thresholded - Diagonal (scale={threshold_scale})', fontsize=12, fontweight='bold')\n",
    "    axes[1, 2].set_ylabel('Time', fontsize=11)\n",
    "    axes[1, 2].set_xlabel('Trace', fontsize=11)\n",
    "    plt.colorbar(im6, ax=axes[1, 2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print()\n",
    "    print(\"üí° Wavelet Í≥ÑÏàò Ìï¥ÏÑù:\")\n",
    "    print(\"   - Horizontal (cH): ÏàòÌèâ Î∞©Ìñ• Í≥†Ï£ºÌåå (Ï∏µÍ≤ΩÍ≥Ñ)\")\n",
    "    print(\"   - Vertical (cV): ÏàòÏßÅ Î∞©Ìñ• Í≥†Ï£ºÌåå (Ìä∏Î†àÏù¥Ïä§ Í∞Ñ Î≥ÄÌôî)\")\n",
    "    print(\"   - Diagonal (cD): ÎåÄÍ∞ÅÏÑ† Î∞©Ìñ• Í≥†Ï£ºÌåå (Î≥µÌï© ÎÖ∏Ïù¥Ï¶à)\")\n",
    "    print(\"   - Thresholding ÌõÑ: ÏïΩÌïú Í≥ÑÏàò Ï†úÍ±∞ ‚Üí ÎÖ∏Ïù¥Ï¶à Í∞êÏÜå\")\n",
    "    print()\n",
    "    print(\"üîß ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï Î∞©Î≤ï:\")\n",
    "    print(\"   - threshold_scale ‚Üì ‚Üí Îçî ÎßéÏùÄ ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ (Îã®, Ïã†Ìò∏ ÏÜêÏã§ Ï£ºÏùò)\")\n",
    "    print(\"   - threshold_scale ‚Üë ‚Üí Ïã†Ìò∏ Î≥¥Ï°¥ Ïö∞ÏÑ† (ÎÖ∏Ïù¥Ï¶à ÏûîÏ°¥ Í∞ÄÎä•)\")\n",
    "    print(\"   - Í∂åÏû•Í∞í: 0.5 ~ 2.5 Î≤îÏúÑÏóêÏÑú Ï°∞Ï†ï\")\n",
    "    print()\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî\n",
    "print(\"üìà ÏµúÏ¢Ö Í≤∞Í≥º ÏãúÍ∞ÅÌôî...\")\n",
    "processor.plot_shot_gather(final_shot, offsets, \"üåÄ Final: After Curvelet Denoise\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step10"
   },
   "source": [
    "## üéØ Step 10: ÏßÅÏ†ëÌåå Ï†úÍ±∞ (FK Domain Filtering) ‚≠ê Í∞úÏÑ†\n",
    "\n",
    "**Í∞úÏÑ†Îêú Î∞©Î≤ï (FK Domain):**\n",
    "- ‚úÖ FK domainÏóêÏÑú ÏßÅÏ†ëÌåå **ÏÑ†ÌÉùÏ†Å Ï†úÍ±∞**\n",
    "- ‚úÖ ÏßÅÏ†ëÌåå ÏÜçÎèÑ Ï£ºÎ≥ÄÎßå ÌïÑÌÑ∞ÎßÅ (Ïã†Ìò∏ Î≥¥Ï°¥)\n",
    "- ‚úÖ Top muteÏùò Ïã†Ìò∏ ÏÜêÏã§ Î¨∏Ï†ú Ìï¥Í≤∞\n",
    "- ‚úÖ ÏñïÏùÄ Î∞òÏÇ¨Ìåå Î≥¥Ï°¥\n",
    "- **ÌååÎùºÎØ∏ÌÑ∞**: `velocity_tolerance` (ÏßÅÏ†ëÌåå ÏÜçÎèÑ Ï£ºÎ≥Ä Î≤îÏúÑ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "direct_wave_mute"
   },
   "outputs": [],
   "source": [
    "print(\"üéØ ÏßÅÏ†ëÌåå Ï†úÍ±∞ (FK Domain Filtering) Ï†ÅÏö© Ï§ë...\")\n",
    "print()\n",
    "print(\"üìä Í∞úÏÑ†Îêú Î∞©Î≤ï (Í∏∞Ï°¥ Top Mute ‚Üí FK Domain):\")\n",
    "print(\"   ‚úÖ FK domain ÏÑ†ÌÉùÏ†Å ÌïÑÌÑ∞ÎßÅ\")\n",
    "print(\"   ‚úÖ ÏßÅÏ†ëÌåå ÏÜçÎèÑ Ï£ºÎ≥ÄÎßå Ï†úÍ±∞\")\n",
    "print(\"   ‚úÖ Ïã†Ìò∏ ÏÜêÏã§ ÏµúÏÜåÌôî\")\n",
    "print(\"   ‚úÖ ÏñïÏùÄ Î∞òÏÇ¨Ìåå Î≥¥Ï°¥\")\n",
    "print()\n",
    "print(\"‚öôÔ∏è FK Domain Ïù¥Î°†:\")\n",
    "print(\"   - t-x domain ‚Üí f-k domain (2D FFT)\")\n",
    "print(\"   - ÏÜçÎèÑ Í≥ÑÏÇ∞: v = 2œÄf/k\")\n",
    "print(\"   - ÏßÅÏ†ëÌåå ÏÜçÎèÑ (water_velocity ¬± tolerance) Ï†úÍ±∞\")\n",
    "print(\"   - Cosine taperÎ°ú Î∂ÄÎìúÎü¨Ïö¥ Ï†ÑÌôò\")\n",
    "print()\n",
    "print(\"‚öôÔ∏è ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï Í∞ÄÎä•:\")\n",
    "print(\"   - velocity_tolerance: ÏßÅÏ†ëÌåå ÏÜçÎèÑ Ï£ºÎ≥Ä Ï†úÍ±∞ Î≤îÏúÑ (m/s)\")\n",
    "print(\"     ÏûëÏùÑÏàòÎ°ù ÏÑ†ÌÉùÏ†Å (Ïòà: 50, 100, 150, 200)\")\n",
    "print()\n",
    "\n",
    "# üîß Ïó¨Í∏∞ÏÑú ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï!\n",
    "velocity_tolerance = 100  # m/s, ÏßÅÏ†ëÌåå ÏÜçÎèÑ Ï£ºÎ≥Ä Ï†úÍ±∞ Î≤îÏúÑ\n",
    "                          # ÏûëÏùÑÏàòÎ°ù ÏÑ†ÌÉùÏ†Å, ÌÅ¥ÏàòÎ°ù Îçî ÎßéÏù¥ Ï†úÍ±∞\n",
    "\n",
    "print(f\"\\nüìå ÌòÑÏû¨ ÌååÎùºÎØ∏ÌÑ∞:\")\n",
    "print(f\"   - Water Velocity: {model['velocity'][0]} m/s (from model)\")\n",
    "print(f\"   - Velocity Tolerance: ¬±{velocity_tolerance} m/s\")\n",
    "print(f\"   - Removal Range: {model['velocity'][0]-velocity_tolerance} ~ {model['velocity'][0]+velocity_tolerance} m/s\")\n",
    "print()\n",
    "\n",
    "# FK Domain Direct Wave Removal\n",
    "after_direct_mute = processor.remove_direct_wave_fk(final_shot, offsets, model, \n",
    "                                                      velocity_tolerance=velocity_tolerance)\n",
    "\n",
    "print(\"‚úÖ ÏßÅÏ†ëÌåå Ï†úÍ±∞ ÏôÑÎ£å!\")\n",
    "print()\n",
    "\n",
    "# ÌÜµÍ≥Ñ\n",
    "removed_direct = final_shot - after_direct_mute\n",
    "\n",
    "print(\"üìà ÌÜµÍ≥Ñ:\")\n",
    "print(f\"   - Before Direct Mute RMS: {np.sqrt(np.mean(final_shot**2)):.6f}\")\n",
    "print(f\"   - After Direct Mute RMS:  {np.sqrt(np.mean(after_direct_mute**2)):.6f}\")\n",
    "print(f\"   - Removed Direct Wave RMS: {np.sqrt(np.mean(removed_direct**2)):.6f}\")\n",
    "print(f\"   - Energy Reduction: {(np.sqrt(np.mean(removed_direct**2))/np.sqrt(np.mean(final_shot**2)))*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî - Before/After ÎπÑÍµê\n",
    "print(\"üìä ÏßÅÏ†ëÌåå Ï†úÍ±∞ Ï†ÑÌõÑ ÎπÑÍµê...\")\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "vmax = np.percentile(np.abs(final_shot), 99)\n",
    "\n",
    "# Before\n",
    "for i, offset in enumerate(offsets):\n",
    "    trace = final_shot[:, i]\n",
    "    trace_scaled = trace / vmax * 30\n",
    "    axes[0].plot(offset + trace_scaled, processor.time, \"k-\", linewidth=0.3)\n",
    "    axes[0].fill_betweenx(processor.time, offset, offset + trace_scaled,\n",
    "                         where=(trace_scaled > 0), color=\"black\", alpha=0.6)\n",
    "    # Mute line\n",
    "    mute_time = offset / mute_velocity\n",
    "    axes[0].plot([offset-30, offset+30], [mute_time, mute_time], \"r-\", linewidth=2, alpha=0.7)\n",
    "\n",
    "axes[0].set_xlabel(\"Offset (m)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0].set_ylabel(\"Time (s)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[0].set_title(\"Before Direct Wave Mute\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(True, alpha=0.3, linestyle=\"--\")\n",
    "axes[0].set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "\n",
    "# After\n",
    "for i, offset in enumerate(offsets):\n",
    "    trace = after_direct_mute[:, i]\n",
    "    trace_scaled = trace / vmax * 30\n",
    "    axes[1].plot(offset + trace_scaled, processor.time, \"k-\", linewidth=0.3)\n",
    "    axes[1].fill_betweenx(processor.time, offset, offset + trace_scaled,\n",
    "                         where=(trace_scaled > 0), color=\"black\", alpha=0.6)\n",
    "\n",
    "axes[1].set_xlabel(\"Offset (m)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1].set_ylabel(\"Time (s)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[1].set_title(\"After Direct Wave Mute\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].grid(True, alpha=0.3, linestyle=\"--\")\n",
    "axes[1].set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "\n",
    "# Removed\n",
    "for i, offset in enumerate(offsets):\n",
    "    trace = removed_direct[:, i]\n",
    "    trace_scaled = trace / vmax * 30\n",
    "    axes[2].plot(offset + trace_scaled, processor.time, \"k-\", linewidth=0.3)\n",
    "    axes[2].fill_betweenx(processor.time, offset, offset + trace_scaled,\n",
    "                         where=(trace_scaled > 0), color=\"black\", alpha=0.6)\n",
    "\n",
    "axes[2].set_xlabel(\"Offset (m)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[2].set_ylabel(\"Time (s)\", fontsize=12, fontweight=\"bold\")\n",
    "axes[2].set_title(\"Removed Direct Wave\", fontsize=14, fontweight=\"bold\")\n",
    "axes[2].invert_yaxis()\n",
    "axes[2].grid(True, alpha=0.3, linestyle=\"--\")\n",
    "axes[2].set_xlim([offsets[0] - 100, offsets[-1] + 100])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"üí° FK Domain Ìï¥ÏÑù:\")\n",
    "print(\"   - Ï¢åÏ∏°: ÏõêÎ≥∏ (ÏßÅÏ†ëÌåå + Î∞òÏÇ¨Ìåå)\")\n",
    "print(\"   - Ï§ëÏïô: FK ÌïÑÌÑ∞ÎßÅ ÌõÑ (ÏßÅÏ†ëÌåå ÏÑ†ÌÉùÏ†Å Ï†úÍ±∞)\")\n",
    "print(\"   - Ïö∞Ï∏°: Ï†úÍ±∞Îêú ÏßÅÏ†ëÌåå (water velocity Ï£ºÎ≥Ä)\")\n",
    "print()\n",
    "print(\"üîß ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï Î∞©Î≤ï:\")\n",
    "print(\"   - velocity_tolerance ‚Üì ‚Üí Îçî ÏÑ†ÌÉùÏ†Å (Ïã†Ìò∏ Î≥¥Ï°¥ Ïö∞ÏÑ†)\")\n",
    "print(\"   - velocity_tolerance ‚Üë ‚Üí Îçî ÎßéÏù¥ Ï†úÍ±∞ (ÏßÅÏ†ëÌåå Ï†úÍ±∞ Ïö∞ÏÑ†)\")\n",
    "print(\"   - Í∂åÏû•Í∞í: 50 ~ 200 m/s\")\n",
    "print()\n",
    "print(\"‚úÖ Í∏∞Ï°¥ Top Mute ÎåÄÎπÑ Ïû•Ï†ê:\")\n",
    "print(\"   1. Ïã†Ìò∏ ÏÜêÏã§ ÏµúÏÜåÌôî (ÏñïÏùÄ Î∞òÏÇ¨Ìåå Î≥¥Ï°¥)\")\n",
    "print(\"   2. ÏßÅÏ†ëÌåå ÏÜçÎèÑÎßå ÏÑ†ÌÉùÏ†Å Ï†úÍ±∞\")\n",
    "print(\"   3. FK domainÏóêÏÑú Ï†ïÌôïÌïú ÏÜçÎèÑ ÌïÑÌÑ∞ÎßÅ\")\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step7"
   },
   "source": [
    "## üåä Step 11: Water Bottom Demultiple\n",
    "\n",
    "**Ïù¥ ÏÖÄÏùÑ Ïã§ÌñâÌïòÎ©¥:**\n",
    "- Ìï¥Ï†ÄÎ©¥-Ìï¥Î©¥ Î©ÄÌã∞Ìîå Ï†úÍ±∞\n",
    "- 1Ï∞®, 2Ï∞®, 3Ï∞® Î©ÄÌã∞Ìîå ÏòàÏ∏° Î∞è Í∞êÏá†\n",
    "- Ï¶âÏãú ÏãúÍ∞ÅÌôî"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wb_demult"
   },
   "outputs": [],
   "source": [
    "print(\"üåä Water Bottom Demultiple Ï†ÅÏö© Ï§ë...\")\n",
    "print()\n",
    "print(\"Ï≤òÎ¶¨ Î∞©Î≤ï:\")\n",
    "print(\"   - Ìï¥Ï†ÄÎ©¥ ÏñëÎ∞©Ìñ• Ï£ºÏãú Í≥ÑÏÇ∞\")\n",
    "print(\"   - Ìï¥Ï†ÄÎ©¥-Ìï¥Î©¥ Î©ÄÌã∞Ìîå ÏòàÏ∏°\")\n",
    "print(\"   - 1Ï∞®, 2Ï∞®, 3Ï∞® Î©ÄÌã∞Ìîå Ï†úÍ±∞\")\n",
    "print()\n",
    "\n",
    "# Water Bottom Demultiple\n",
    "wb_demult_strength = 0.8\n",
    "after_wb = processor.water_bottom_demultiple(after_direct_mute, model, strength=wb_demult_strength)\n",
    "\n",
    "print(\"‚úÖ Water Bottom Demultiple ÏôÑÎ£å!\")\n",
    "print()\n",
    "\n",
    "# ÌÜµÍ≥Ñ\n",
    "removed_wb_mult = after_direct_mute - after_wb\n",
    "\n",
    "print(\"üìà ÌÜµÍ≥Ñ:\")\n",
    "print(f\"   - Before WB Demult RMS: {np.sqrt(np.mean(after_direct_mute**2)):.6f}\")\n",
    "print(f\"   - After WB Demult RMS:  {np.sqrt(np.mean(after_wb**2)):.6f}\")\n",
    "print(f\"   - Removed Multiples RMS: {np.sqrt(np.mean(removed_wb_mult**2)):.6f}\")\n",
    "print(f\"   - Reduction: {(1 - np.sqrt(np.mean(after_wb**2))/np.sqrt(np.mean(after_direct_mute**2)))*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî\n",
    "print(\"üìà Water Bottom Demultiple Í≤∞Í≥º ÏãúÍ∞ÅÌôî...\")\n",
    "processor.plot_shot_gather(after_wb, offsets, \"üåä After Water Bottom Demultiple\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step8"
   },
   "source": [
    "## üîÑ Step 12: Radon Transform Demultiple (ÏÜçÎèÑ Î™®Îç∏ Í∏∞Î∞ò) ‚≠ê ÏµúÏ¢Ö Í∞úÏÑ†\n",
    "\n",
    "**ÏµúÏ¢Ö Í∞úÏÑ† ÏÇ¨Ìï≠ (ÏÜçÎèÑ Î™®Îç∏ ÌôúÏö©):**\n",
    "- ‚úÖ **ÏÜçÎèÑ Î™®Îç∏ Í∏∞Î∞ò** Primary/Multiple ÏûêÎèô Í≥ÑÏÇ∞\n",
    "- ‚úÖ **RMS ÏÜçÎèÑ**Î°ú Î¨ºÎ¶¨Ï†Å Ï†ïÌôïÏÑ± Î≥¥Ïû•\n",
    "- ‚úÖ **High-resolution Radon** with damping (artifacts Í∞êÏÜå)\n",
    "- ‚úÖ **Amplitude scaling**ÏúºÎ°ú inverse transform Í∞úÏÑ†\n",
    "- ‚úÖ Safety marginÏúºÎ°ú Ïã†Ìò∏ Î≥¥Ï°¥\n",
    "- **ÌååÎùºÎØ∏ÌÑ∞**: `damping`, `safety_margin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "radon_demult"
   },
   "outputs": [],
   "source": [
    "print(\"üîÑ ÏÜçÎèÑ Î™®Îç∏ Í∏∞Î∞ò Radon Transform Demultiple\")\n",
    "print()\n",
    "print(\"üìä ÏµúÏ¢Ö Í∞úÏÑ† ÏõåÌÅ¨ÌîåÎ°úÏö∞:\")\n",
    "print(\"   1. Forward High-resolution Radon (damping)\")\n",
    "print(\"   2. RMS ÏÜçÎèÑ Í≥ÑÏÇ∞ (Í∞Å Ï∏µÏùò ÏÜçÎèÑ Î™®Îç∏)\")\n",
    "print(\"   3. Primary/Multiple ÏòÅÏó≠ ÏûêÎèô Í≤∞Ï†ï\")\n",
    "print(\"   4. Velocity-based Mute (Î¨ºÎ¶¨Ï†Å Ï†ïÌôïÏÑ±)\")\n",
    "print(\"   5. Inverse High-resolution Radon\")\n",
    "print()\n",
    "print(\"‚öôÔ∏è 3Í∞ÄÏßÄ ÌïµÏã¨ Í∞úÏÑ†:\")\n",
    "print(\"   1Ô∏è‚É£ ÏÜçÎèÑ Î™®Îç∏ ÌôúÏö©: RMS ÏÜçÎèÑÎ°ú Primary ÏòÅÏó≠ ÏûêÎèô Í≥ÑÏÇ∞\")\n",
    "print(\"   2Ô∏è‚É£ High-resolution: Damping + Amplitude scaling (artifacts Í∞êÏÜå)\")\n",
    "print(\"   3Ô∏è‚É£ Safety margin: Ïã†Ìò∏ Î≥¥Ï°¥ (ÏûêÎèô Ïó¨Ïú† Í≥µÍ∞Ñ)\")\n",
    "print()\n",
    "\n",
    "# üîß Ïó¨Í∏∞ÏÑú ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï!\n",
    "radon_type = 'linear'  # 'linear' ÎòêÎäî 'parabolic'\n",
    "\n",
    "# Ray parameter Î≤îÏúÑ (ÎÑìÍ≤å ÏÑ§Ï†ï)\n",
    "p_min = -0.003  # Îçî ÎÑìÏùÄ Î≤îÏúÑ\n",
    "p_max = 0.003\n",
    "n_p = 128\n",
    "\n",
    "# High-resolution ÌååÎùºÎØ∏ÌÑ∞\n",
    "damping = 0.01  # L2 regularization (0.01 ~ 0.1)\n",
    "                # ÏûëÏùÑÏàòÎ°ù high-resolution, ÌÅ¥ÏàòÎ°ù stable\n",
    "\n",
    "# ÏÜçÎèÑ Î™®Îç∏ Í∏∞Î∞ò mute ÌååÎùºÎØ∏ÌÑ∞\n",
    "safety_margin = 0.1  # Primary ÏòÅÏó≠ ÌôïÏû• ÎπÑÏú® (10%)\n",
    "                     # Ïã†Ìò∏ ÏÜêÏã§ Î∞©ÏßÄ\n",
    "\n",
    "mute_multiples = True  # True: Multiple Ï†úÍ±∞, False: Primary Ï†úÍ±∞ (Í≤ÄÏ¶ù)\n",
    "\n",
    "print(f\"üìå ÏÑ†ÌÉùÎêú ÌååÎùºÎØ∏ÌÑ∞:\")\n",
    "print(f\"   - Radon Type: {radon_type.upper()}\")\n",
    "print(f\"   - Ray Parameter Range: [{p_min:.6f}, {p_max:.6f}]\")\n",
    "print(f\"   - Number of Samples: {n_p}\")\n",
    "print(f\"   - Damping: {damping} (regularization)\")\n",
    "print(f\"   - Safety Margin: {safety_margin*100:.0f}% (signal preservation)\")\n",
    "print(f\"   - Mute Type: {'Remove Multiples' if mute_multiples else 'Remove Primary (validation)'}\")\n",
    "print()\n",
    "print(\"‚è≥ Ï≤òÎ¶¨ Ï§ë... (ÏãúÍ∞ÑÏù¥ Í±∏Î¶¥ Ïàò ÏûàÏäµÎãàÎã§)\")\n",
    "print()\n",
    "\n",
    "# üìò ÏÜçÎèÑ Î™®Îç∏ Í∏∞Î∞ò Ïù¥Î°†:\n",
    "#   RMS Velocity: V_rms = sqrt(Œ£(v_i^2 * t_i) / Œ£t_i)\n",
    "#   Primary p range: ‚âà ¬±1/V_rms_max * (1 + safety_margin)\n",
    "#   Multiple: |p| > 1/V_water (slower apparent velocity)\n",
    "# \n",
    "#   Ïû•Ï†ê:\n",
    "#   - ÏÜçÎèÑ Î™®Îç∏Î°ú Î¨ºÎ¶¨Ï†Å Ï†ïÌôïÏÑ± Î≥¥Ïû•\n",
    "#   - Í∞Å Îç∞Ïù¥ÌÑ∞ÏÖãÏóê ÎßûÏ∂§Ìòï mute\n",
    "#   - Safety marginÏúºÎ°ú Ïã†Ìò∏ Î≥¥Ï°¥\n",
    "\n",
    "# ÏÜçÎèÑ Î™®Îç∏ Í∏∞Î∞ò Radon Demultiple\n",
    "after_radon, radon_original, radon_filtered, param_values, p_primary_bounds = processor.radon_demultiple_velocity_based(\n",
    "    after_wb, offsets, model,\n",
    "    radon_type=radon_type,\n",
    "    p_min=p_min, p_max=p_max, n_p=n_p,\n",
    "    damping=damping,\n",
    "    safety_margin=safety_margin,\n",
    "    mute_multiples=mute_multiples\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Radon Transform Demultiple ÏôÑÎ£å!\")\n",
    "print()\n",
    "\n",
    "# ÌÜµÍ≥Ñ\n",
    "removed_radon_mult = after_wb - after_radon\n",
    "\n",
    "print(\"üìà ÌÜµÍ≥Ñ:\")\n",
    "print(f\"   - Before Radon RMS: {np.sqrt(np.mean(after_wb**2)):.6f}\")\n",
    "print(f\"   - After Radon RMS:  {np.sqrt(np.mean(after_radon**2)):.6f}\")\n",
    "print(f\"   - Removed Multiples RMS: {np.sqrt(np.mean(removed_radon_mult**2)):.6f}\")\n",
    "print(f\"   - Additional Reduction: {(1 - np.sqrt(np.mean(after_radon**2))/np.sqrt(np.mean(after_wb**2)))*100:.1f}%\")\n",
    "print()\n",
    "\n",
    "# üé® œÑ-p (ÎòêÎäî œÑ-q) ÎèÑÎ©îÏù∏ ÏãúÍ∞ÅÌôî (SEG Wiki Î∞©Ïãù)\n",
    "print(\"üìä Radon ÎèÑÎ©îÏù∏ ÏãúÍ∞ÅÌôî...\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "\n",
    "# ÏõêÎ≥∏ Radon ÎèÑÎ©îÏù∏\n",
    "vmax_radon = np.percentile(np.abs(radon_original), 99)\n",
    "\n",
    "if radon_type == 'linear':\n",
    "    param_label = 'Ray Parameter p (√ó10‚Åª¬≥ s/m)'\n",
    "    extent = [param_values[0]*1000, param_values[-1]*1000, processor.time[-1], processor.time[0]]\n",
    "    title_suffix = '(œÑ-p)'\n",
    "else:\n",
    "    param_label = 'Curvature q (√ó10‚Åª¬≥ s/m¬≤)'\n",
    "    extent = [param_values[0]*1000, param_values[-1]*1000, processor.time[-1], processor.time[0]]\n",
    "    title_suffix = '(œÑ-q)'\n",
    "\n",
    "im0 = axes[0,0].imshow(radon_original, aspect='auto', cmap='seismic', \n",
    "                       vmin=-vmax_radon, vmax=vmax_radon, extent=extent)\n",
    "axes[0,0].set_xlabel(param_label, fontsize=11, fontweight='bold')\n",
    "axes[0,0].set_ylabel('Intercept Time œÑ (s)', fontsize=11, fontweight='bold')\n",
    "axes[0,0].set_title(f'Original Radon Domain {title_suffix}', fontsize=13, fontweight='bold')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Primary region ÌëúÏãú (ÏÜçÎèÑ Î™®Îç∏ Í∏∞Î∞ò ÏûêÎèô Í≥ÑÏÇ∞)\n",
    "if radon_type == 'linear':\n",
    "    axes[0,0].axvline(p_primary_bounds[0]*1000, color='green', linestyle='--', linewidth=2, label=f'Primary (V-model)')\n",
    "    axes[0,0].axvline(p_primary_bounds[1]*1000, color='green', linestyle='--', linewidth=2)\n",
    "axes[0,0].legend(fontsize=9)\n",
    "plt.colorbar(im0, ax=axes[0,0])\n",
    "\n",
    "# Mute ÌõÑ Radon ÎèÑÎ©îÏù∏\n",
    "im1 = axes[0,1].imshow(radon_filtered, aspect='auto', cmap='seismic', \n",
    "                       vmin=-vmax_radon, vmax=vmax_radon, extent=extent)\n",
    "axes[0,1].set_xlabel(param_label, fontsize=11, fontweight='bold')\n",
    "axes[0,1].set_ylabel('Intercept Time œÑ (s)', fontsize=11, fontweight='bold')\n",
    "axes[0,1].set_title(f'After Mute (Mute Type: {mute_type})', fontsize=13, fontweight='bold')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "plt.colorbar(im1, ax=axes[0,1])\n",
    "\n",
    "# Ï†úÍ±∞Îêú ÏÑ±Î∂Ñ (Multiple)\n",
    "radon_removed = radon_original - radon_filtered\n",
    "im2 = axes[1,0].imshow(radon_removed, aspect='auto', cmap='seismic', \n",
    "                       vmin=-vmax_radon, vmax=vmax_radon, extent=extent)\n",
    "axes[1,0].set_xlabel(param_label, fontsize=11, fontweight='bold')\n",
    "axes[1,0].set_ylabel('Intercept Time œÑ (s)', fontsize=11, fontweight='bold')\n",
    "axes[1,0].set_title('Removed Components (Multiples)', fontsize=13, fontweight='bold')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "plt.colorbar(im2, ax=axes[1,0])\n",
    "\n",
    "# Radon domain amplitude spectrum (p ÎòêÎäî q Î∞©Ìñ•)\n",
    "radon_amp_orig = np.sum(np.abs(radon_original), axis=0)\n",
    "radon_amp_filt = np.sum(np.abs(radon_filtered), axis=0)\n",
    "axes[1,1].plot(param_values*1000, radon_amp_orig, 'b-', linewidth=2, label='Original', alpha=0.7)\n",
    "axes[1,1].plot(param_values*1000, radon_amp_filt, 'r-', linewidth=2, label='After Mute', alpha=0.7)\n",
    "\n",
    "if radon_type == 'linear':\n",
    "    axes[1,1].axvline(p_primary_bounds[0]*1000, color='green', linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    axes[1,1].axvline(p_primary_bounds[1]*1000, color='green', linestyle='--', linewidth=1.5, alpha=0.7, label='Primary (V-model)')\n",
    "    axes[1,1].axvline(0, color='black', linestyle='-', linewidth=1, alpha=0.3)\n",
    "\n",
    "axes[1,1].set_xlabel(param_label, fontsize=11, fontweight='bold')\n",
    "axes[1,1].set_ylabel('Amplitude Sum', fontsize=11, fontweight='bold')\n",
    "axes[1,1].set_title('Radon Domain Energy Distribution', fontsize=13, fontweight='bold')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "axes[1,1].legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print(\"üí° ÏÜçÎèÑ Î™®Îç∏ Í∏∞Î∞ò Radon Ìï¥ÏÑù:\")\n",
    "print(\"   - Ï¢åÏÉÅ: ÏõêÎ≥∏, Green lines = ÏÜçÎèÑ Î™®Îç∏Î°ú Í≥ÑÏÇ∞Îêú Primary ÏòÅÏó≠\")\n",
    "print(\"   - Ïö∞ÏÉÅ: Mute ÌõÑ, Multiple ÏòÅÏó≠ ÏûêÎèô Ï†úÍ±∞Îê®\")\n",
    "print(\"   - Ï¢åÌïò: Ï†úÍ±∞Îêú Multiple (Ï†ÄÏÜçÎèÑ ÏòÅÏó≠)\")\n",
    "print(\"   - Ïö∞Ìïò: Energy Î∂ÑÌè¨, Primary peak ÏûêÎèô Í∞êÏßÄ\")\n",
    "print()\n",
    "print(\"‚úÖ ÏÜçÎèÑ Î™®Îç∏ Í∏∞Î∞òÏùò Ïû•Ï†ê:\")\n",
    "print(\"   1. RMS ÏÜçÎèÑÎ°ú Primary ÏòÅÏó≠ ÏûêÎèô Í≥ÑÏÇ∞ (Î¨ºÎ¶¨Ï†Å Ï†ïÌôïÏÑ±)\")\n",
    "print(\"   2. Í∞Å Îç∞Ïù¥ÌÑ∞ÏÖãÏóê ÎßûÏ∂§Ìòï mute (ÏàòÎèô Ï°∞Ï†ï Î∂àÌïÑÏöî)\")\n",
    "print(\"   3. Safety marginÏúºÎ°ú Ïã†Ìò∏ Î≥¥Ï°¥\")\n",
    "print()\n",
    "print(\"üîß ÌååÎùºÎØ∏ÌÑ∞ Ï°∞Ï†ï Î∞©Î≤ï:\")\n",
    "print(\"   - damping ‚Üì ‚Üí high-resolution (artifacts Í∞ÄÎä•)\")\n",
    "print(\"   - damping ‚Üë ‚Üí stable (artifacts Í∞êÏÜå) ‚ú®\")\n",
    "print(\"   - safety_margin ‚Üì ‚Üí Îçî ÎßéÏùÄ multiple Ï†úÍ±∞\")\n",
    "print(\"   - safety_margin ‚Üë ‚Üí Ïã†Ìò∏ Î≥¥Ï°¥ Ïö∞ÏÑ† ‚ú®\")\n",
    "print(\"   - Í∂åÏû•: damping=0.01, safety_margin=0.1\")\n",
    "print()\n",
    "\n",
    "# ÏãúÍ∞ÅÌôî\n",
    "print(\"üìà Radon Transform Demultiple Í≤∞Í≥º ÏãúÍ∞ÅÌôî...\")\n",
    "processor.plot_shot_gather(after_radon, offsets, \"üîÑ After Radon Demultiple\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step11"
   },
   "source": [
    "## üìä Step 11: Ï†ÑÏ≤¥ ÎπÑÍµê (5Îã®Í≥Ñ)\n",
    "\n",
    "**Ï≤òÎ¶¨ ÌååÏù¥ÌîÑÎùºÏù∏ Ï†ÑÏ≤¥ ÎπÑÍµê**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "comparison"
   },
   "outputs": [],
   "source": [
    "print(\"üìä Ï†ÑÏ≤¥ Ï≤òÎ¶¨ ÌååÏù¥ÌîÑÎùºÏù∏ ÎπÑÍµê...\")\n",
    "print()\n",
    "\n",
    "titles = [\n",
    "    'Input\\n(Noisy)',\n",
    "    'AAA + Lowcut\\n+ Curvelet',\n",
    "    'Water Bottom\\nDemultiple',\n",
    "    'Radon\\nDemultiple',\n",
    "    'Final\\n(All Processing)'\n",
    "]\n",
    "\n",
    "processor.plot_comparison_5(noisy_shot, final_shot, after_wb, after_radon, after_radon, \n",
    "                           offsets, titles)\n",
    "\n",
    "print(\"‚úÖ ÎπÑÍµê ÏôÑÎ£å!\")\n",
    "print()\n",
    "print(\"üí° Ï≤òÎ¶¨ ÌååÏù¥ÌîÑÎùºÏù∏:\")\n",
    "print(\"   1Ô∏è‚É£ Input: Multiple + ÎÖ∏Ïù¥Ï¶à\")\n",
    "print(\"   2Ô∏è‚É£ AAA + Lowcut + Curvelet: ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞\")\n",
    "print(\"   3Ô∏è‚É£ WB Demult: Ìï¥Ï†ÄÎ©¥ multiple Ï†úÍ±∞\")\n",
    "print(\"   4Ô∏è‚É£ Radon: Ï∂îÍ∞Ä multiple Ï†úÍ±∞\")\n",
    "print(\"   5Ô∏è‚É£ Final: ÏµúÏ¢Ö Í≤∞Í≥º\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "step12"
   },
   "source": [
    "## üíæ Step 12: Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• Î∞è Îã§Ïö¥Î°úÎìú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save"
   },
   "outputs": [],
   "source": [
    "print(\"üíæ Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• Ï§ë...\")\n",
    "print()\n",
    "\n",
    "# Ï†ÄÏû•\n",
    "np.savez('shot_input.npz', shot_gather=noisy_shot, offsets=offsets, time=processor.time, model=model)\n",
    "print(\"‚úÖ shot_input.npz\")\n",
    "\n",
    "np.savez('shot_after_aaa.npz', shot_gather=after_aaa, offsets=offsets, time=processor.time, model=model)\n",
    "print(\"‚úÖ shot_after_aaa.npz\")\n",
    "\n",
    "np.savez('shot_after_lowcut.npz', shot_gather=after_lowcut, offsets=offsets, time=processor.time, model=model)\n",
    "print(\"‚úÖ shot_after_lowcut.npz\")\n",
    "\n",
    "np.savez('shot_after_curvelet.npz', shot_gather=final_shot, offsets=offsets, time=processor.time, model=model)\n",
    "print(\"‚úÖ shot_after_curvelet.npz\")\n",
    "\n",
    "np.savez('shot_after_wb.npz', shot_gather=after_wb, offsets=offsets, time=processor.time, model=model)\n",
    "print(\"‚úÖ shot_after_wb.npz\")\n",
    "\n",
    "np.savez('shot_final.npz', shot_gather=after_radon, offsets=offsets, time=processor.time, model=model)\n",
    "print(\"‚úÖ shot_final.npz\")\n",
    "print()\n",
    "\n",
    "# Colab Îã§Ïö¥Î°úÎìú\n",
    "try:\n",
    "    from google.colab import files\n",
    "    print(\"üì• Îã§Ïö¥Î°úÎìú ÏãúÏûë...\")\n",
    "    files.download('shot_input.npz')\n",
    "    files.download('shot_final.npz')\n",
    "    print(\"‚úÖ Ï£ºÏöî ÌååÏùº Îã§Ïö¥Î°úÎìú ÏôÑÎ£å!\")\n",
    "except:\n",
    "    print(\"‚ÑπÔ∏è Î°úÏª¨ ÌôòÍ≤Ω - ÌååÏùºÏù¥ ÌòÑÏû¨ ÎîîÎ†âÌÜ†Î¶¨Ïóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"üéâ Ï†ÑÏ≤¥ Í≥†Í∏â Ï≤òÎ¶¨ ÏõåÌÅ¨ÌîåÎ°úÏö∞ ÏôÑÎ£å!\")\n",
    "print(\"=\"*80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "final"
   },
   "source": [
    "## üéâ ÏôÑÎ£å!\n",
    "\n",
    "---\n",
    "\n",
    "### ‚≠ê Í≥†Í∏â Ï≤òÎ¶¨ Í∏∞Î≤ï ÏöîÏïΩ\n",
    "\n",
    "| Îã®Í≥Ñ | Í∏∞Î≤ï | Î™©Ï†Å | ÌäπÏßï |\n",
    "|------|------|------|------|\n",
    "| 7 | **Anomalous Amplitude Attenuation** | Ïù¥ÏÉÅ ÏßÑÌè≠ Í∞êÏá† | Î°úÏª¨ ÌÜµÍ≥Ñ Í∏∞Î∞ò |\n",
    "| 8 | **Low-cut Filter** | Ï†ÄÏ£ºÌåå Ï†úÍ±∞ | 1.5 Hz Butterworth |\n",
    "| 9 | **Curvelet Denoise** | ÏùºÎ∞ò ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ | Wavelet Î≥ÄÌôò |\n",
    "| 10 | **Water Bottom Demultiple** | Ìï¥Ï†ÄÎ©¥ multiple Ï†úÍ±∞ | ÏòàÏ∏° Î∞è Ï†ÅÏùë Í∞êÏá† |\n",
    "| 11 | **Radon Transform** | Ï∂îÍ∞Ä multiple Ï†úÍ±∞ | t-x ‚Üí œÑ-p Î≥ÄÌôò |\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Ï≤òÎ¶¨ ÏàúÏÑúÏùò Ï§ëÏöîÏÑ±\n",
    "\n",
    "**ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ Î®ºÏ†Ä ‚Üí Multiple Ï†úÍ±∞**\n",
    "\n",
    "1. üî¥ **AAA**: Ïù¥ÏÉÅ ÏßÑÌè≠ Ï†úÍ±∞ (Burst noise)\n",
    "2. üü† **Low-cut**: Ï†ÄÏ£ºÌåå ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ (Swell, Ship)\n",
    "3. üü° **Curvelet**: ÏùºÎ∞ò ÎÖ∏Ïù¥Ï¶à Ï†úÍ±∞ (White noise)\n",
    "4. üü¢ **WB Demult**: Íπ®ÎÅóÌïú Ïã†Ìò∏ÏóêÏÑú Multiple Ï†úÍ±∞\n",
    "5. üîµ **Radon**: ÏµúÏ¢Ö Multiple Ï†úÍ±∞\n",
    "\n",
    "**ÎÖ∏Ïù¥Ï¶àÍ∞Ä Íπ®ÎÅóÌï¥Ïïº Radon œÑ-p ÎèÑÎ©îÏù∏Ïù¥ Ï†ïÌôïÌï©ÎãàÎã§!**\n",
    "\n",
    "---\n",
    "\n",
    "### üìä ÏÑ±Îä• ÎπÑÍµê\n",
    "\n",
    "**Ïù¥Ï†Ñ Í∏∞Î≤ï vs Í≥†Í∏â Í∏∞Î≤ï:**\n",
    "\n",
    "- üî¥ **Ïù¥Ï†Ñ**: Multiple Î®ºÏ†Ä Ï†úÍ±∞ ‚Üí ÎÖ∏Ïù¥Ï¶àÏóê ÏùòÌïú Í∞ÑÏÑ≠\n",
    "- üü¢ **ÌòÑÏû¨**: ÎÖ∏Ïù¥Ï¶à Î®ºÏ†Ä Ï†úÍ±∞ ‚Üí Multiple Ï†ïÌôïÌûà Ï†úÍ±∞\n",
    "\n",
    "**SNR Í∞úÏÑ†:**\n",
    "- ÏùºÎ∞òÏ†ÅÏúºÎ°ú **20-30 dB** Í∞úÏÑ†\n",
    "- ÎÖ∏Ïù¥Ï¶àÏôÄ Multiple Î™®Îëê Ìö®Í≥ºÏ†ÅÏúºÎ°ú Ï†úÍ±∞\n",
    "\n",
    "---\n",
    "\n",
    "### üíæ ÏÉùÏÑ±Îêú ÌååÏùº (6Í∞ú)\n",
    "\n",
    "1. **shot_input.npz** - ÏûÖÎ†• (Multiple + ÎÖ∏Ïù¥Ï¶à)\n",
    "2. **shot_after_aaa.npz** - AAA ÌõÑ\n",
    "3. **shot_after_lowcut.npz** - Low-cut ÌõÑ\n",
    "4. **shot_after_curvelet.npz** - Curvelet ÌõÑ\n",
    "5. **shot_after_wb.npz** - WB Demult ÌõÑ\n",
    "6. **shot_final.npz** - ÏµúÏ¢Ö Í≤∞Í≥º (Radon ÌõÑ)\n",
    "\n",
    "---\n",
    "\n",
    "**Made with ‚ù§Ô∏è for Advanced Marine Seismic Processing**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}